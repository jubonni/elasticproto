{
    "meta": {
        "timestamp": "2024-11-01T03:02:52.442594",
        "size": 8261,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/downsampling.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "downsampling",
        "version": "8.15"
    },
    "doc": "[[downsampling]]\n\n/////\n[source,console]\n--------------------------------------------------\nDELETE _ilm/policy/my_policy\n--------------------------------------------------\n// TEST\n// TEARDOWN\n/////\n\n=== Downsampling a time series data stream\n\nDownsampling provides a method to reduce the footprint of your <<tsds,time\nseries data>> by storing it at reduced granularity.\n\nMetrics solutions collect large amounts of time series data that grow over time.\nAs that data ages, it becomes less relevant to the current state of the system.\nThe downsampling process rolls up documents within a fixed time interval into a\nsingle summary document. Each summary document includes statistical\nrepresentations of the original data: the `min`, `max`, `sum` and `value_count`\nfor each metric. Data stream <<time-series-dimension,time series dimensions>>\nare stored unchanged.\n\nDownsampling, in effect, lets you to trade data resolution and precision for\nstorage size. You can include it in an <<index-lifecycle-management,{ilm}\n({ilm-init})>> policy to automatically manage the volume and associated cost of\nyour metrics data at it ages.\n\nCheck the following sections to learn more:\n\n* <<how-downsampling-works>>\n* <<running-downsampling>>\n* <<querying-downsampled-indices>>\n* <<downsampling-restrictions>>\n* <<try-out-downsampling>>\n\n[discrete]\n[[how-downsampling-works]]\n=== How it works\n\nA <<time-series,time series>> is a sequence of observations taken over time for\na specific entity. The observed samples can be represented as a continuous\nfunction, where the time series dimensions remain constant and the time series\nmetrics change over time.\n\n//.Sampling a continuous function\nimage::images/data-streams/time-series-function.png[align=\"center\"]\n\nIn an Elasticsearch index, a single document is created for each timestamp,\ncontaining the immutable time series dimensions, together with the metrics names\nand the changing metrics values. For a single timestamp, several time series\ndimensions and metrics may be stored.\n\n//.Metric anatomy\nimage::images/data-streams/time-series-metric-anatomy.png[align=\"center\"]\n\nFor your most current and relevant data, the metrics series typically has a low\nsampling time interval, so it's optimized for queries that require a high data\nresolution.\n\n.Original metrics series\nimage::images/data-streams/time-series-original.png[align=\"center\"]\n\nDownsampling works on older, less frequently accessed data by replacing the\noriginal time series with both a data stream of a higher sampling interval and\nstatistical representations of that data. Where the original metrics samples may\nhave been taken, for example, every ten seconds, as the data ages you may choose\nto reduce the sample granularity to hourly or daily. You may choose to reduce\nthe granularity of `cold` archival data to monthly or less.\n\n.Downsampled metrics series\nimage::images/data-streams/time-series-downsampled.png[align=\"center\"]\n\n[discrete]\n[[running-downsampling]]\n=== Running downsampling on time series data\n\nTo downsample a time series index, use the\n<<indices-downsample-data-stream,Downsample API>> and set `fixed_interval` to\nthe level of granularity that you'd like:\n\ninclude::../indices/downsample-data-stream.asciidoc[tag=downsample-example]\n\nTo downsample time series data as part of ILM, include a\n<<ilm-downsample,Downsample action>> in your ILM policy and set `fixed_interval`\nto the level of granularity that you'd like:\n\n[source,console]\n----\nPUT _ilm/policy/my_policy\n{\n  \"policy\": {\n    \"phases\": {\n      \"warm\": {\n        \"actions\": {\n          \"downsample\" : {\n            \"fixed_interval\": \"1h\"\n          }\n        }\n      }\n    }\n  }\n}\n----\n\n[discrete]\n[[querying-downsampled-indices]]\n=== Querying downsampled indices\n\nYou can use the <<search-search,`_search`>> and <<async-search,`_async_search`>>\nendpoints to query a downsampled index. Multiple raw data and downsampled\nindices can be queried in a single request, and a single request can include\ndownsampled indices at different granularities (different bucket timespan). That\nis, you can query data streams that contain downsampled indices with multiple\ndownsampling intervals (for example, `15m`, `1h`, `1d`).\n\nThe result of a time based histogram aggregation is in a uniform bucket size and\neach downsampled index returns data ignoring the downsampling time interval. For\nexample, if you run a `date_histogram` aggregation with `\"fixed_interval\": \"1m\"`\non a downsampled index that has been downsampled at an hourly resolution\n(`\"fixed_interval\": \"1h\"`), the query returns one bucket with all of the data at\nminute 0, then 59 empty buckets, and then a bucket with data again for the next\nhour.\n\n[discrete]\n[[querying-downsampled-indices-notes]]\n==== Notes on downsample queries\n\nThere are a few things to note about querying downsampled indices:\n\n* When you run queries in {kib} and through Elastic solutions, a normal\nresponse is returned without notification that some of the queried indices are\ndownsampled.\n* For\n<<search-aggregations-bucket-datehistogram-aggregation,date histogram aggregations>>,\nonly `fixed_intervals` (and not calendar-aware intervals) are supported.\n* Timezone support comes with caveats:\n\n** Date histograms at intervals that are multiples of an hour are based on\nvalues generated at UTC. This works well for timezones that are on the hour, e.g.\n+5:00 or -3:00, but requires offsetting the reported time buckets, e.g.\n`2020-01-01T10:30:00.000` instead of `2020-03-07T10:00:00.000` for\ntimezone +5:30 (India), if downsampling aggregates values per hour. In this case,\nthe results include the field `downsampled_results_offset: true`, to indicate that\nthe time buckets are shifted. This can be avoided if a downsampling interval of 15\nminutes is used, as it allows properly calculating hourly values for the shifted\nbuckets.\n\n** Date histograms at intervals that are multiples of a day are similarly\naffected, in case downsampling aggregates values per day. In this case, the\nbeginning of each day is always calculated at UTC when generated the downsampled\nvalues, so the time buckets need to be shifted, e.g. reported as\n`2020-03-07T19:00:00.000` instead of `2020-03-07T00:00:00.000` for timezone `America/New_York`.\nThe field `downsampled_results_offset: true` is added in this case too.\n\n** Daylight savings and similar peculiarities around timezones affect\nreported results, as <<datehistogram-aggregation-time-zone,documented>>\nfor date histogram aggregation. Besides, downsampling at daily interval\nhinders tracking any information related to daylight savings changes.\n\n[discrete]\n[[downsampling-restrictions]]\n=== Restrictions and limitations\n\nThe following restrictions and limitations apply for downsampling:\n\n* Only indices in a <<tsds,time series data stream>> are supported.\n\n* Data is downsampled based on the time dimension only. All other dimensions are\ncopied to the new index without any modification.\n\n* Within a data stream, a downsampled index replaces the original index and the\noriginal index is deleted. Only one index can exist for a given time period.\n\n* A source index must be in read-only mode for the downsampling process to\nsucceed. Check the <<downsampling-manual,Run downsampling manually>> example for\ndetails.\n\n* Downsampling data for the same period many times (downsampling of a\ndownsampled index) is supported. The downsampling interval must be a multiple of\nthe interval of the downsampled index.\n\n* Downsampling is provided as an ILM action. See <<ilm-downsample,Downsample>>.\n\n* The new, downsampled index is created on the data tier of the original index\nand it inherits its settings (for example, the number of shards and replicas).\n\n* The numeric `gauge` and `counter` <<mapping-field-meta,metric types>> are\nsupported.\n\n* The downsampling configuration is extracted from the time series data stream\n<<create-tsds-index-template,index mapping>>. The only additional\nrequired setting is the downsampling `fixed_interval`.\n\n[discrete]\n[[try-out-downsampling]]\n=== Try it out\n\nTo take downsampling for a test run, try our example of\n<<downsampling-manual,running downsampling manually>>.\n\nDownsampling can easily be added to your ILM policy. To learn how, try our\n<<downsampling-ilm,Run downsampling with ILM>> example.\n"
}
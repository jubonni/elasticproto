{
    "meta": {
        "size": 9607,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-keyword-repeat-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-keyword-repeat-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-keyword-repeat-tokenfilter]]\n=== Keyword repeat token filter\n++++\n<titleabbrev>Keyword repeat</titleabbrev>\n++++\n\nOutputs a keyword version of each token in a stream. These keyword tokens are\nnot stemmed.\n\nThe `keyword_repeat` filter assigns keyword tokens a `keyword` attribute of\n`true`. Stemmer token filters, such as\n<<analysis-stemmer-tokenfilter,`stemmer`>> or\n<<analysis-porterstem-tokenfilter,`porter_stem`>>, skip tokens with a `keyword`\nattribute of `true`.\n\nYou can use the `keyword_repeat` filter with a stemmer token filter to output a\nstemmed and unstemmed version of each token in a stream.\n\n[IMPORTANT]\n====\nTo work properly, the `keyword_repeat` filter must be listed before any stemmer\ntoken filters in the <<analysis-custom-analyzer,analyzer configuration>>.\n\nStemming does not affect all tokens. This means streams could contain duplicate\ntokens in the same position, even after stemming.\n\nTo remove these duplicate tokens, add the\n<<analysis-remove-duplicates-tokenfilter,`remove_duplicates`>> filter after the\nstemmer filter in the analyzer configuration.\n====\n\nThe `keyword_repeat` filter uses Lucene's\n{lucene-analysis-docs}/miscellaneous/KeywordRepeatFilter.html[KeywordRepeatFilter].\n\n[[analysis-keyword-repeat-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the `keyword_repeat`\nfilter to output a keyword and non-keyword version of each token in \n`fox running and jumping`.\n\nTo return the `keyword` attribute for these tokens, the analyze API request also\nincludes the following arguments:\n\n* `explain`:  `true`\n* `attributes`: `keyword`\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\"\n  ],\n  \"text\": \"fox running and jumping\",\n  \"explain\": true,\n  \"attributes\": \"keyword\"\n}\n----\n\nThe API returns the following response. Note that one version of each token has\na `keyword` attribute of `true`.\n\n.**Response**\n[%collapsible]\n====\n[source,console-result]\n----\n{\n  \"detail\": {\n    \"custom_analyzer\": true,\n    \"charfilters\": [],\n    \"tokenizer\": ...,\n    \"tokenfilters\": [\n      {\n        \"name\": \"keyword_repeat\",\n        \"tokens\": [\n          {\n            \"token\": \"fox\",\n            \"start_offset\": 0,\n            \"end_offset\": 3,\n            \"type\": \"word\",\n            \"position\": 0,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"fox\",\n            \"start_offset\": 0,\n            \"end_offset\": 3,\n            \"type\": \"word\",\n            \"position\": 0,\n            \"keyword\": false\n          },\n          {\n            \"token\": \"running\",\n            \"start_offset\": 4,\n            \"end_offset\": 11,\n            \"type\": \"word\",\n            \"position\": 1,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"running\",\n            \"start_offset\": 4,\n            \"end_offset\": 11,\n            \"type\": \"word\",\n            \"position\": 1,\n            \"keyword\": false\n          },\n          {\n            \"token\": \"and\",\n            \"start_offset\": 12,\n            \"end_offset\": 15,\n            \"type\": \"word\",\n            \"position\": 2,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"and\",\n            \"start_offset\": 12,\n            \"end_offset\": 15,\n            \"type\": \"word\",\n            \"position\": 2,\n            \"keyword\": false\n          },\n          {\n            \"token\": \"jumping\",\n            \"start_offset\": 16,\n            \"end_offset\": 23,\n            \"type\": \"word\",\n            \"position\": 3,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"jumping\",\n            \"start_offset\": 16,\n            \"end_offset\": 23,\n            \"type\": \"word\",\n            \"position\": 3,\n            \"keyword\": false\n          }\n        ]\n      }\n    ]\n  }\n}\n----\n// TESTRESPONSE[s/\"tokenizer\": \\.\\.\\./\"tokenizer\": $body.detail.tokenizer/]\n====\n\nTo stem the non-keyword tokens, add the `stemmer` filter after the\n`keyword_repeat` filter in the previous analyze API request.\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\"\n  ],\n  \"text\": \"fox running and jumping\",\n  \"explain\": true,\n  \"attributes\": \"keyword\"\n}\n----\n\nThe API returns the following response. Note the following changes:\n\n* The non-keyword version of `running` was stemmed to `run`.\n* The non-keyword version of `jumping` was stemmed to `jump`.\n\n.**Response**\n[%collapsible]\n====\n[source,console-result]\n----\n{\n  \"detail\": {\n    \"custom_analyzer\": true,\n    \"charfilters\": [],\n    \"tokenizer\": ...,\n    \"tokenfilters\": [\n      {\n        \"name\": \"keyword_repeat\",\n        \"tokens\": ...\n      },\n      {\n        \"name\": \"stemmer\",\n        \"tokens\": [\n          {\n            \"token\": \"fox\",\n            \"start_offset\": 0,\n            \"end_offset\": 3,\n            \"type\": \"word\",\n            \"position\": 0,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"fox\",\n            \"start_offset\": 0,\n            \"end_offset\": 3,\n            \"type\": \"word\",\n            \"position\": 0,\n            \"keyword\": false\n          },\n          {\n            \"token\": \"running\",\n            \"start_offset\": 4,\n            \"end_offset\": 11,\n            \"type\": \"word\",\n            \"position\": 1,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"run\",\n            \"start_offset\": 4,\n            \"end_offset\": 11,\n            \"type\": \"word\",\n            \"position\": 1,\n            \"keyword\": false\n          },\n          {\n            \"token\": \"and\",\n            \"start_offset\": 12,\n            \"end_offset\": 15,\n            \"type\": \"word\",\n            \"position\": 2,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"and\",\n            \"start_offset\": 12,\n            \"end_offset\": 15,\n            \"type\": \"word\",\n            \"position\": 2,\n            \"keyword\": false\n          },\n          {\n            \"token\": \"jumping\",\n            \"start_offset\": 16,\n            \"end_offset\": 23,\n            \"type\": \"word\",\n            \"position\": 3,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"jump\",\n            \"start_offset\": 16,\n            \"end_offset\": 23,\n            \"type\": \"word\",\n            \"position\": 3,\n            \"keyword\": false\n          }\n        ]\n      }\n    ]\n  }\n}\n----\n// TESTRESPONSE[s/\"tokenizer\": \\.\\.\\./\"tokenizer\": $body.detail.tokenizer/]\n// TESTRESPONSE[s/\"tokens\": .../\"tokens\": $body.$_path/]\n====\n\nHowever, the keyword and non-keyword versions of `fox` and `and` are\nidentical and in the same respective positions.\n\nTo remove these duplicate tokens, add the `remove_duplicates` filter after\n`stemmer` in the analyze API request. \n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\",\n    \"remove_duplicates\"\n  ],\n  \"text\": \"fox running and jumping\",\n  \"explain\": true,\n  \"attributes\": \"keyword\"\n}\n----\n\nThe API returns the following response. Note that the duplicate tokens for `fox`\nand `and` have been removed.\n\n.**Response**\n[%collapsible]\n====\n[source,console-result]\n----\n{\n  \"detail\": {\n    \"custom_analyzer\": true,\n    \"charfilters\": [],\n    \"tokenizer\": ...,\n    \"tokenfilters\": [\n      {\n        \"name\": \"keyword_repeat\",\n        \"tokens\": ...\n      },\n      {\n        \"name\": \"stemmer\",\n        \"tokens\": ...\n      },\n      {\n        \"name\": \"remove_duplicates\",\n        \"tokens\": [\n          {\n            \"token\": \"fox\",\n            \"start_offset\": 0,\n            \"end_offset\": 3,\n            \"type\": \"word\",\n            \"position\": 0,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"running\",\n            \"start_offset\": 4,\n            \"end_offset\": 11,\n            \"type\": \"word\",\n            \"position\": 1,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"run\",\n            \"start_offset\": 4,\n            \"end_offset\": 11,\n            \"type\": \"word\",\n            \"position\": 1,\n            \"keyword\": false\n          },\n          {\n            \"token\": \"and\",\n            \"start_offset\": 12,\n            \"end_offset\": 15,\n            \"type\": \"word\",\n            \"position\": 2,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"jumping\",\n            \"start_offset\": 16,\n            \"end_offset\": 23,\n            \"type\": \"word\",\n            \"position\": 3,\n            \"keyword\": true\n          },\n          {\n            \"token\": \"jump\",\n            \"start_offset\": 16,\n            \"end_offset\": 23,\n            \"type\": \"word\",\n            \"position\": 3,\n            \"keyword\": false\n          }\n        ]\n      }\n    ]\n  }\n}\n----\n// TESTRESPONSE[s/\"tokenizer\": \\.\\.\\./\"tokenizer\": $body.detail.tokenizer/]\n// TESTRESPONSE[s/\"tokens\": .../\"tokens\": $body.$_path/]\n====\n\n[[analysis-keyword-repeat-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`keyword_repeat` filter to configure a new <<analysis-custom-analyzer,custom\nanalyzer>>.\n\nThis custom analyzer uses the `keyword_repeat` and `porter_stem` filters to\ncreate a stemmed and unstemmed version of each token in a stream. The\n`remove_duplicates` filter then removes any duplicate tokens from the stream.\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"keyword_repeat\",\n            \"porter_stem\",\n            \"remove_duplicates\"\n          ]\n        }\n      }\n    }\n  }\n}\n----"
}
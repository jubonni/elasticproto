{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.022067",
        "size": 30698,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/put-trained-models.html",
        "type": "documentation",
        "role": [
            "xpack",
            "child_attributes"
        ],
        "has_code": false,
        "title": "put-trained-models",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[put-trained-models]]\n= Create trained models API\n[subs=\"attributes\"]\n++++\n\n<titleabbrev>Create trained models</titleabbrev>\n\n++++\n\nCreates a trained model.\n\nWARNING: Models created in version 7.8.0 are not backwards compatible\n         with older node versions. If in a mixed cluster environment,\n         all nodes must be at least 7.8.0 to use a model stored by\n         a 7.8.0 node.\n\n\n[[ml-put-trained-models-request]]\n== {api-request-title}\n\n`PUT _ml/trained_models/<model_id>`\n\n\n[[ml-put-trained-models-prereq]]\n== {api-prereq-title}\n\nRequires the `manage_ml` cluster privilege. This privilege is included in the\n`machine_learning_admin` built-in role.\n\n\n[[ml-put-trained-models-desc]]\n== {api-description-title}\n\nThe create trained model API enables you to supply a trained model that is not\ncreated by {dfanalytics}.\n\n[[ml-put-trained-models-path-params]]\n== {api-path-parms-title}\n\n`<model_id>`::\n(Required, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=model-id]\n\n[[ml-put-trained-models-query-params]]\n== {api-query-parms-title}\n\n`defer_definition_decompression`::\n(Optional, boolean)\nIf set to `true` and a `compressed_definition` is provided, the request defers\ndefinition decompression and skips relevant validations.\nThis deferral is useful for systems or users that know a good byte size estimate for their\nmodel and know that their model is valid and likely won't fail during inference.\n\n`wait_for_completion`::\n(Optional, boolean)\nWhether to wait for all child operations such as model download\nto complete, before returning or not. Defaults to `false`.\n\n[role=\"child_attributes\"]\n[[ml-put-trained-models-request-body]]\n== {api-request-body-title}\n\n`compressed_definition`::\n(Required, string)\nThe compressed (GZipped and Base64 encoded) {infer} definition of the model.\nIf `compressed_definition` is specified, then `definition` cannot be specified.\n\n//Begin definition\n`definition`::\n(Required, object)\nThe {infer} definition for the model. If `definition` is specified, then\n`compressed_definition` cannot be specified.\n+\n.Properties of `definition`\n[%collapsible%open]\n====\n//Begin preprocessors\n`preprocessors`::\n(Optional, object)\nCollection of preprocessors. See <<ml-put-trained-models-preprocessor-example>>.\n+\n.Properties of `preprocessors`\n[%collapsible%open]\n=====\n//Begin frequency encoding\n`frequency_encoding`::\n(Required, object)\nDefines a frequency encoding for a field.\n+\n.Properties of `frequency_encoding`\n[%collapsible%open]\n======\n`feature_name`::\n(Required, string)\nThe name of the resulting feature.\n\n`field`::\n(Required, string)\nThe field name to encode.\n\n`frequency_map`::\n(Required, object map of string:double)\nObject that maps the field value to the frequency encoded value.\n\n`custom`::\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=custom-preprocessor]\n\n======\n//End frequency encoding\n\n//Begin one hot encoding\n`one_hot_encoding`::\n(Required, object)\nDefines a one hot encoding map for a field.\n+\n.Properties of `one_hot_encoding`\n[%collapsible%open]\n======\n`field`::\n(Required, string)\nThe field name to encode.\n\n`hot_map`::\n(Required, object map of strings)\nString map of \"field_value: one_hot_column_name\".\n\n`custom`::\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=custom-preprocessor]\n\n======\n//End one hot encoding\n\n//Begin target mean encoding\n`target_mean_encoding`::\n(Required, object)\nDefines a target mean encoding for a field.\n+\n.Properties of `target_mean_encoding`\n[%collapsible%open]\n======\n`default_value`:::\n(Required, double)\nThe feature value if the field value is not in the `target_map`.\n\n`feature_name`:::\n(Required, string)\nThe name of the resulting feature.\n\n`field`:::\n(Required, string)\nThe field name to encode.\n\n`target_map`:::\n(Required, object map of string:double)\nObject that maps the field value to the target mean value.\n\n`custom`::\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=custom-preprocessor]\n\n======\n//End target mean encoding\n=====\n//End preprocessors\n\n//Begin trained model\n`trained_model`::\n(Required, object)\nThe definition of the trained model.\n+\n.Properties of `trained_model`\n[%collapsible%open]\n=====\n//Begin tree\n`tree`::\n(Required, object)\nThe definition for a binary decision tree.\n+\n.Properties of `tree`\n[%collapsible%open]\n======\n`classification_labels`:::\n(Optional, string) An array of classification labels (used for\n`classification`).\n\n`feature_names`:::\n(Required, string)\nFeatures expected by the tree, in their expected order.\n\n`target_type`:::\n(Required, string)\nString indicating the model target type; `regression` or `classification`.\n\n`tree_structure`:::\n(Required, object)\nAn array of `tree_node` objects. The nodes must be in ordinal order by their\n`tree_node.node_index` value.\n======\n//End tree\n\n//Begin tree node\n`tree_node`::\n(Required, object)\nThe definition of a node in a tree.\n+\n--\nThere are two major types of nodes: leaf nodes and not-leaf nodes.\n\n* Leaf nodes only need `node_index` and `leaf_value` defined.\n* All other nodes need `split_feature`, `left_child`, `right_child`,\n  `threshold`, `decision_type`, and `default_left` defined.\n--\n+\n.Properties of `tree_node`\n[%collapsible%open]\n======\n`decision_type`::\n(Optional, string)\nIndicates the positive value (in other words, when to choose the left node)\ndecision type. Supported `lt`, `lte`, `gt`, `gte`. Defaults to `lte`.\n\n`default_left`::\n(Optional, Boolean)\nIndicates whether to default to the left when the feature is missing. Defaults\nto `true`.\n\n`leaf_value`::\n(Optional, double)\nThe leaf value of the of the node, if the value is a leaf (in other words, no\nchildren).\n\n`left_child`::\n(Optional, integer)\nThe index of the left child.\n\n`node_index`::\n(Integer)\nThe index of the current node.\n\n`right_child`::\n(Optional, integer)\nThe index of the right child.\n\n`split_feature`::\n(Optional, integer)\nThe index of the feature value in the feature array.\n\n`split_gain`::\n(Optional, double) The information gain from the split.\n\n`threshold`::\n(Optional, double)\nThe decision threshold with which to compare the feature value.\n======\n//End tree node\n\n//Begin ensemble\n`ensemble`::\n(Optional, object)\nThe definition for an ensemble model. See <<ml-put-trained-models-model-example>>.\n+\n.Properties of `ensemble`\n[%collapsible%open]\n======\n//Begin aggregate output\n`aggregate_output`::\n(Required, object)\nAn aggregated output object that defines how to aggregate the outputs of the\n`trained_models`. Supported objects are `weighted_mode`, `weighted_sum`, and\n`logistic_regression`. See <<ml-put-trained-models-aggregated-output-example>>.\n+\n.Properties of `aggregate_output`\n[%collapsible%open]\n=======\n//Begin logistic regression\n`logistic_regression`::\n(Optional, object)\nThis `aggregated_output` type works with binary classification (classification\nfor values [0, 1]). It multiplies the outputs (in the case of the `ensemble`\nmodel, the inference model values) by the supplied `weights`. The resulting\nvector is summed and passed to a\n{wikipedia}/Sigmoid_function[`sigmoid` function]. The result\nof the `sigmoid` function is considered the probability of class 1 (`P_1`),\nconsequently, the probability of class 0 is `1 - P_1`. The class with the\nhighest probability (either 0 or 1) is then returned. For more information about\nlogistic regression, see\n{wikipedia}/Logistic_regression[this wiki article].\n+\n.Properties of `logistic_regression`\n[%collapsible%open]\n========\n`weights`:::\n(Required, double)\nThe weights to multiply by the input values (the inference values of the trained\nmodels).\n========\n//End logistic regression\n\n//Begin weighted sum\n`weighted_sum`::\n(Optional, object)\nThis `aggregated_output` type works with regression. The weighted sum of the\ninput values.\n+\n.Properties of `weighted_sum`\n[%collapsible%open]\n========\n`weights`:::\n(Required, double)\nThe weights to multiply by the input values (the inference values of the trained\nmodels).\n========\n//End weighted sum\n\n//Begin weighted mode\n`weighted_mode`::\n(Optional, object)\nThis `aggregated_output` type works with regression or classification. It takes\na weighted vote of the input values. The most common input value (taking the\nweights into account) is returned.\n+\n.Properties of `weighted_mode`\n[%collapsible%open]\n========\n`weights`:::\n(Required, double)\nThe weights to multiply by the input values (the inference values of the trained\nmodels).\n========\n//End weighted mode\n\n//Begin exponent\n`exponent`::\n(Optional, object)\nThis `aggregated_output` type works with regression. It takes a weighted sum of\nthe input values and passes the result to an exponent function\n(`e^x` where `x` is the sum of the weighted values).\n+\n.Properties of `exponent`\n[%collapsible%open]\n========\n`weights`:::\n(Required, double)\nThe weights to multiply by the input values (the inference values of the trained\nmodels).\n========\n//End exponent\n=======\n//End aggregate output\n\n`classification_labels`::\n(Optional, string)\nAn array of classification labels.\n\n`feature_names`::\n(Optional, string)\nFeatures expected by the ensemble, in their expected order.\n\n`target_type`::\n(Required, string)\nString indicating the model target type; `regression` or `classification.`\n\n`trained_models`::\n(Required, object)\nAn array of `trained_model` objects. Supported trained models are `tree` and\n`ensemble`.\n======\n//End ensemble\n\n=====\n//End trained model\n\n====\n//End definition\n\n`description`::\n(Optional, string)\nA human-readable description of the {infer} trained model.\n\n`estimated_heap_memory_usage_bytes`::\n(Optional, integer) deprecated:[7.16.0,Replaced by `model_size_bytes`]\n\n`estimated_operations`::\n(Optional, integer)\nThe estimated number of operations to use the trained model during inference.\nThis property is supported only if `defer_definition_decompression` is `true` or\nthe model definition is not supplied.\n\n//Begin inference_config\n`inference_config`::\n(Required, object)\nThe default configuration for inference. This can be: `regression`,\n`classification`, `fill_mask`, `ner`, `question_answering`,\n`text_classification`, `text_embedding` or `zero_shot_classification`.\nIf `regression` or `classification`, it must match the `target_type` of the\nunderlying `definition.trained_model`. If `fill_mask`, `ner`,\n`question_answering`, `text_classification`, or `text_embedding`; the\n`model_type` must be `pytorch`.\n+\n.Properties of `inference_config`\n[%collapsible%open]\n====\n`classification`:::\n(Optional, object)\nClassification configuration for inference.\n+\n.Properties of classification inference\n[%collapsible%open]\n=====\n`num_top_classes`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-classes]\n\n`num_top_feature_importance_values`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-feature-importance-values]\n\n`prediction_field_type`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-prediction-field-type]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`top_classes_results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-top-classes-results-field]\n=====\n\n`fill_mask`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-fill-mask]\n+\n.Properties of fill_mask inference\n[%collapsible%open]\n=====\n`num_top_classes`::::\n(Optional, integer)\nNumber of top predicted tokens to return for replacing the mask token. Defaults to `0`.\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n\n`ner`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-ner]\n+\n.Properties of ner inference\n[%collapsible%open]\n=====\n`classification_labels`::::\n(Optional, string)\nAn array of classification labels. NER only supports Inside-Outside-Beginning\nlabels (IOB) and only persons, organizations, locations, and miscellaneous.\nExample: [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-MISC\",\n\"I-MISC\"]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the\nproperties of the `tokenization` object.\n=====\n\n`pass_through`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-pass-through]\n+\n.Properties of pass_through inference\n[%collapsible%open]\n=====\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n\n`question_answering`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-question-answering]\n+\n.Properties of question_answering inference\n[%collapsible%open]\n=====\n`max_answer_length`::::\n(Optional, integer)\nThe maximum amount of words in the answer. Defaults to `15`.\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRecommended to set `max_sentence_length` to `386` with `128` of `span` and set\n`truncate` to `none`.\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n\n`regression`:::\n(Optional, object)\nRegression configuration for inference.\n+\n.Properties of regression inference\n[%collapsible%open]\n=====\n`num_top_feature_importance_values`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-regression-num-top-feature-importance-values]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n=====\n\n`text_classification`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-classification]\n+\n.Properties of text_classification inference\n[%collapsible%open]\n=====\n`classification_labels`::::\n(Optional, string) An array of classification labels.\n\n`num_top_classes`::::\n(Optional, integer)\nSpecifies the number of top class predictions to return. Defaults to all classes\n(-1).\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n\n`text_embedding`:::\n(Object, optional)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-embedding]\n+\n.Properties of text_embedding inference\n[%collapsible%open]\n=====\n`embedding_size`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-embedding-size]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n\n`text_similarity`:::\n(Object, optional)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-similarity]\n+\n.Properties of text_similarity inference\n[%collapsible%open]\n=====\n`span_score_combination_function`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-similarity-span-score-func]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n\n`zero_shot_classification`:::\n(Object, optional)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification]\n+\n.Properties of zero_shot_classification inference\n[%collapsible%open]\n=====\n`classification_labels`::::\n(Required, array)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-classification-labels]\n\n`hypothesis_template`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-hypothesis-template]\n\n`labels`::::\n(Optional, array)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-labels]\n\n`multi_label`::::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-multi-label]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n====\n//End of inference_config\n\n//Begin input\n`input`::\n(Required, object)\nThe input field names for the model definition.\n+\n.Properties of `input`\n[%collapsible%open]\n====\n`field_names`:::\n(Required, string)\nAn array of input field names for the model.\n====\n//End input\n\n// Begin location\n`location`::\n(Optional, object)\nThe model definition location. If the `definition` or `compressed_definition`\nare not specified, the `location` is required.\n+\n.Properties of `location`\n[%collapsible%open]\n====\n`index`:::\n(Required, object)\nIndicates that the model definition is stored in an index. This object must be\nempty as the index for storing model definitions is configured automatically.\n====\n// End location\n\n`metadata`::\n(Optional, object)\nAn object map that contains metadata about the model.\n\n`model_size_bytes`::\n(Optional, integer)\nThe estimated memory usage in bytes to keep the trained model in memory. This\nproperty is supported only if `defer_definition_decompression` is `true` or the\nmodel definition is not supplied.\n\n`model_type`::\n(Optional, string)\nThe created model type. By default the model type is `tree_ensemble`.\nAppropriate types are:\n+\n--\n* `tree_ensemble`: The model definition is an ensemble model of decision trees.\n* `lang_ident`: A special type reserved for language identification models.\n* `pytorch`: The stored definition is a PyTorch (specifically a TorchScript) model. Currently only\nNLP models are supported. For more information, refer to {ml-docs}/ml-nlp.html[{nlp-cap}].\n--\n`platform_architecture`::\n(Optional, string)\nIf the model only works on one platform, because it is heavily\noptimized for a particular processor architecture and OS combination,\nthen this field specifies which. The format of the string must match\nthe platform identifiers used by Elasticsearch, so one of, `linux-x86_64`,\n`linux-aarch64`, `darwin-x86_64`, `darwin-aarch64`, or `windows-x86_64`.\nFor portable models (those that work independent of processor architecture or\nOS features), leave this field unset.\n\n//Begin prefix_strings\n`prefix_strings`::\n(Optional, object)\nCertain NLP models are trained in such a way that a prefix string should\nbe applied to the input text before the input is evaluated. The prefix\nmay be different depending on the intention. For asymmetric tasks such\nas infromation retrieval the prefix applied to a passage as it is indexed\ncan be different to the prefix applied when searching those passages.\n+\n--\n`prefix_strings` has 2 options, a prefix string that is always applied\nin the search context and one that is always applied when ingesting the\ndocs. Both are optional.\n--\n+\n.Properties of `prefix_strings`\n[%collapsible%open]\n====\n`search`:::\n(Optional, string)\nThe prefix string to prepend to the input text for requests\noriginating from a search query.\n\n`ingest`:::\n(Optional, string)\nThe prefix string to prepend to the input text for requests\nat ingest where the {infer} ingest processor is used.\n// TODO is there a shortcut for Inference ingest processor?\n====\n//End prefix_strings\n\n`tags`::\n(Optional, string)\nAn array of tags to organize the model.\n\n\n[[tokenization-properties]]\n=== Properties of `tokenizaton`\n\nThe `tokenization` object has the following properties.\n\n`bert`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n====\n`do_lower_case`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-do-lower-case]\n\n`max_sequence_length`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-max-sequence-length]\n\n`span`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`:::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n\n`with_special_tokens`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-with-special-tokens]\n====\n`deberta_v2`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n====\n`do_lower_case`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-do-lower-case]\n+\n--\nDefaults to `false`.\n--\n\n`max_sequence_length`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-max-sequence-length]\n\n`span`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`:::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n\n`with_special_tokens`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2-with-special-tokens]\n====\n`roberta`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n====\n`add_prefix_space`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta-add-prefix-space]\n\n`max_sequence_length`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-max-sequence-length]\n\n`span`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`:::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n\n`with_special_tokens`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta-with-special-tokens]\n====\n`mpnet`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n====\n`do_lower_case`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-do-lower-case]\n\n`max_sequence_length`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-max-sequence-length]\n\n`span`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`:::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n\n`with_special_tokens`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet-with-special-tokens]\n====\n`xlm_roberta`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n====\n`max_sequence_length`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-max-sequence-length]\n\n`span`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`:::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n\n`with_special_tokens`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta-with-special-tokens]\n====\n`bert_ja`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n====\n`do_lower_case`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-do-lower-case]\n\n`max_sequence_length`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-max-sequence-length]\n\n`span`:::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`:::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n\n`with_special_tokens`:::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja-with-special-tokens]\n====\n\n\n[[ml-put-trained-models-example]]\n== {api-examples-title}\n\n[[ml-put-trained-models-preprocessor-example]]\n=== Preprocessor examples\n\nThe example below shows a `frequency_encoding` preprocessor object:\n\n[source,js]\n----------------------------------\n{\n   \"frequency_encoding\":{\n      \"field\":\"FlightDelayType\",\n      \"feature_name\":\"FlightDelayType_frequency\",\n      \"frequency_map\":{\n         \"Carrier Delay\":0.6007414737092798,\n         \"NAS Delay\":0.6007414737092798,\n         \"Weather Delay\":0.024573576178086153,\n         \"Security Delay\":0.02476631010889467,\n         \"No Delay\":0.6007414737092798,\n         \"Late Aircraft Delay\":0.6007414737092798\n      }\n   }\n}\n----------------------------------\n//NOTCONSOLE\n\n\nThe next example shows a `one_hot_encoding` preprocessor object:\n\n[source,js]\n----------------------------------\n{\n   \"one_hot_encoding\":{\n      \"field\":\"FlightDelayType\",\n      \"hot_map\":{\n         \"Carrier Delay\":\"FlightDelayType_Carrier Delay\",\n         \"NAS Delay\":\"FlightDelayType_NAS Delay\",\n         \"No Delay\":\"FlightDelayType_No Delay\",\n         \"Late Aircraft Delay\":\"FlightDelayType_Late Aircraft Delay\"\n      }\n   }\n}\n----------------------------------\n//NOTCONSOLE\n\n\nThis example shows a `target_mean_encoding` preprocessor object:\n\n[source,js]\n----------------------------------\n{\n   \"target_mean_encoding\":{\n      \"field\":\"FlightDelayType\",\n      \"feature_name\":\"FlightDelayType_targetmean\",\n      \"target_map\":{\n         \"Carrier Delay\":39.97465788139886,\n         \"NAS Delay\":39.97465788139886,\n         \"Security Delay\":203.171206225681,\n         \"Weather Delay\":187.64705882352948,\n         \"No Delay\":39.97465788139886,\n         \"Late Aircraft Delay\":39.97465788139886\n      },\n      \"default_value\":158.17995752420433\n   }\n}\n----------------------------------\n//NOTCONSOLE\n\n\n[[ml-put-trained-models-model-example]]\n=== Model examples\n\nThe first example shows a `trained_model` object:\n\n[source,js]\n----------------------------------\n{\n   \"tree\":{\n      \"feature_names\":[\n         \"DistanceKilometers\",\n         \"FlightTimeMin\",\n         \"FlightDelayType_NAS Delay\",\n         \"Origin_targetmean\",\n         \"DestRegion_targetmean\",\n         \"DestCityName_targetmean\",\n         \"OriginAirportID_targetmean\",\n         \"OriginCityName_frequency\",\n         \"DistanceMiles\",\n         \"FlightDelayType_Late Aircraft Delay\"\n      ],\n      \"tree_structure\":[\n         {\n            \"decision_type\":\"lt\",\n            \"threshold\":9069.33437193022,\n            \"split_feature\":0,\n            \"split_gain\":4112.094574306927,\n            \"node_index\":0,\n            \"default_left\":true,\n            \"left_child\":1,\n            \"right_child\":2\n         },\n         ...\n         {\n            \"node_index\":9,\n            \"leaf_value\":-27.68987349695448\n         },\n         ...\n      ],\n      \"target_type\":\"regression\"\n   }\n}\n----------------------------------\n//NOTCONSOLE\n\n\nThe following example shows an `ensemble` model object:\n\n[source,js]\n----------------------------------\n\"ensemble\":{\n   \"feature_names\":[\n      ...\n   ],\n   \"trained_models\":[\n      {\n         \"tree\":{\n            \"feature_names\":[],\n            \"tree_structure\":[\n               {\n                  \"decision_type\":\"lte\",\n                  \"node_index\":0,\n                  \"leaf_value\":47.64069875778043,\n                  \"default_left\":false\n               }\n            ],\n            \"target_type\":\"regression\"\n         }\n      },\n      ...\n   ],\n   \"aggregate_output\":{\n      \"weighted_sum\":{\n         \"weights\":[\n            ...\n         ]\n      }\n   },\n   \"target_type\":\"regression\"\n}\n----------------------------------\n//NOTCONSOLE\n\n\n[[ml-put-trained-models-aggregated-output-example]]\n=== Aggregated output example\n\nExample of a `logistic_regression` object:\n\n[source,js]\n----------------------------------\n\"aggregate_output\" : {\n  \"logistic_regression\" : {\n    \"weights\" : [2.0, 1.0, .5, -1.0, 5.0, 1.0, 1.0]\n  }\n}\n----------------------------------\n//NOTCONSOLE\n\n\nExample of a `weighted_sum` object:\n\n[source,js]\n----------------------------------\n\"aggregate_output\" : {\n  \"weighted_sum\" : {\n    \"weights\" : [1.0, -1.0, .5, 1.0, 5.0]\n  }\n}\n----------------------------------\n//NOTCONSOLE\n\n\nExample of a `weighted_mode` object:\n\n[source,js]\n----------------------------------\n\"aggregate_output\" : {\n  \"weighted_mode\" : {\n    \"weights\" : [1.0, 1.0, 1.0, 1.0, 1.0]\n  }\n}\n----------------------------------\n//NOTCONSOLE\n\n\nExample of an `exponent` object:\n\n[source,js]\n----------------------------------\n\"aggregate_output\" : {\n  \"exponent\" : {\n    \"weights\" : [1.0, 1.0, 1.0, 1.0, 1.0]\n  }\n}\n----------------------------------\n//NOTCONSOLE\n\n\n[[ml-put-trained-models-json-schema]]\n=== Trained models JSON schema\n\nFor the full JSON schema of trained models,\nhttps://github.com/elastic/ml-json-schemas[click here].\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T03:07:10.413271",
        "size": 8890,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network-threading-model.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "modules-network-threading-model",
        "version": "8.15"
    },
    "doc": "[[modules-network-threading-model]]\n==== Networking threading model\n\nThis section describes the threading model used by the networking subsystem in\n{es}. This information isn't required to use {es}, but it may be useful to\nadvanced users who are diagnosing network problems in a cluster.\n\n{es} nodes communicate over a collection of TCP channels that together form a\ntransport connection. {es} clients communicate with the cluster over HTTP,\nwhich also uses one or more TCP channels. Each of these TCP channels is owned\nby exactly one of the `transport_worker` threads in the node. This owning\nthread is chosen when the channel is opened and remains the same for the\nlifetime of the channel.\n\nEach `transport_worker` thread has sole responsibility for sending and\nreceiving data over the channels it owns. Additionally, each http and transport\nserver socket is assigned to one of the `transport_worker` threads. That worker\nhas the responsibility of accepting new incoming connections to the server\nsocket it owns.\n\nIf a thread in {es} wants to send data over a particular channel, it passes the\ndata to the owning `transport_worker` thread for the actual transmission.\n\nNormally the `transport_worker` threads will not completely handle the messages\nthey receive. Instead, they will do a small amount of preliminary processing\nand then dispatch (hand off) the message to a different\n<<modules-threadpool,threadpool>> for the rest of their handling. For instance,\nbulk messages are dispatched to the `write` threadpool, searches are dispatched\nto one of the `search` threadpools, and requests for statistics and other\nmanagement tasks are mostly dispatched to the `management` threadpool. However\nin some cases the processing of a message is expected to be so quick that {es}\nwill do all of the processing on the `transport_worker` thread rather than\nincur the overhead of dispatching it elsewhere.\n\nBy default, there is one `transport_worker` thread per CPU. In contrast, there\nmay sometimes be tens-of-thousands of TCP channels. If data arrives on a TCP\nchannel and its owning `transport_worker` thread is busy, the data isn't\nprocessed until the thread finishes whatever it is doing. Similarly, outgoing\ndata are not sent over a channel until the owning `transport_worker` thread is\nfree. This means that we require every `transport_worker` thread to be idle\nfrequently. An idle `transport_worker` looks something like this in a stack\ndump:\n\n[source,text]\n----\n\"elasticsearch[instance-0000000004][transport_worker][T#1]\" #32 daemon prio=5 os_prio=0 cpu=9645.94ms elapsed=501.63s tid=0x00007fb83b6307f0 nid=0x1c4 runnable  [0x00007fb7b8ffe000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPoll.wait(java.base@17.0.2/Native Method)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(java.base@17.0.2/EPollSelectorImpl.java:118)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(java.base@17.0.2/SelectorImpl.java:129)\n\t- locked <0x00000000c443c518> (a sun.nio.ch.Util$2)\n\t- locked <0x00000000c38f7700> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(java.base@17.0.2/SelectorImpl.java:146)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\tat java.lang.Thread.run(java.base@17.0.2/Thread.java:833)\n----\n\nIn the <<cluster-nodes-hot-threads>> API an idle `transport_worker` thread is\nreported like this:\n\n[source,text]\n----\n   0.0% [cpu=0.0%, idle=100.0%] (500ms out of 500ms) cpu usage by thread 'elasticsearch[instance-0000000004][transport_worker][T#1]'\n     10/10 snapshots sharing following 9 elements\n       java.base@17.0.2/sun.nio.ch.EPoll.wait(Native Method)\n       java.base@17.0.2/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)\n       java.base@17.0.2/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)\n       java.base@17.0.2/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)\n       io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)\n       io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)\n       io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n       io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n       java.base@17.0.2/java.lang.Thread.run(Thread.java:833)\n----\n\nNote that `transport_worker` threads should always be in state `RUNNABLE`, even\nwhen waiting for input, because they block in the native `EPoll#wait` method. The `idle=`\ntime reports the proportion of time the thread spent waiting for input, whereas the `cpu=` time\nreports the proportion of time the thread spent processing input it has received.\n\nIf a `transport_worker` thread is not frequently idle, it may build up a\nbacklog of work. This can cause delays in processing messages on the channels\nthat it owns. It's hard to predict exactly which work will be delayed:\n\n* There are many more channels than threads. If work related to one channel is\ncausing delays to its worker thread, all other channels owned by that thread\nwill also suffer delays.\n\n* The mapping from TCP channels to worker threads is fixed but arbitrary. Each\nchannel is assigned an owning thread in a round-robin fashion when the channel\nis opened. Each worker thread is responsible for many different kinds of\nchannel.\n\n* There are many channels open between each pair of nodes. For each request,\n{es} will choose from the appropriate channels in a round-robin fashion. Some\nrequests may end up on a channel owned by a delayed worker while other\nidentical requests will be sent on a channel that's working smoothly.\n\nIf the backlog builds up too far, some messages may be delayed by many seconds.\nThe node might even <<cluster-fault-detection,fail its health checks>> and be\nremoved from the cluster. Sometimes, you can find evidence of busy\n`transport_worker` threads using the <<cluster-nodes-hot-threads>> API.\nHowever, this API itself sends network messages so may not work correctly if\nthe `transport_worker` threads are too busy. It is more reliable to use\n`jstack` to obtain stack dumps or use Java Flight Recorder to obtain a\nprofiling trace. These tools are independent of any work the JVM is performing.\n\nIt may also be possible to identify some reasons for delays from the server\nlogs. See for instance the following loggers:\n\n`org.elasticsearch.transport.InboundHandler`:: This logger reports a warning if\nprocessing an inbound message occupies a network thread for unreasonably long,\nwhich is almost certainly a bug. The warning includes some information which\ncan be used to identify the message that took unreasonably long to process.\n\n`org.elasticsearch.transport.OutboundHandler`:: This logger reports a warning\nif sending an outbound message takes longer than expected. This duration\nincludes time spent waiting for network congestion to clear, and time spent\nprocessing other work on the same network thread, so does not always indicate\nthe presence of a bug related to the outbound message specified in the log\nentry.\n\n`org.elasticsearch.common.network.ThreadWatchdog`:: This logger reports a\nwarning and a thread dump when it notices that a network thread has not made\nprogress between two consecutive checks, which is almost certainly a bug:\n+\n--\n[source,text]\n----\n[WARN ][o.e.c.n.ThreadWatchdog   ] the following threads are active but did not make progress in the preceding [5s]: [elasticsearch[instance-0000000004][transport_worker][T#1]]]\n[WARN ][o.e.c.n.ThreadWatchdog   ] hot threads dump due to active threads not making progress [part 1]: H4sIAAAAAAAA/+1aa2/bOBb93l8hYLUYFWgYvWw5AQbYpEkn6STZbJyiwAwGA1qiY8US6ZJUHvPr90qk/JJky41TtDMuUIci...\n[WARN ][o.e.c.n.ThreadWatchdog   ] hot threads dump due to active threads not making progress [part 2]: LfXL/x70a3eL8ve6Ral74ZBrp5x7HmUD9KXQz1MaXUNfFC6SeEysxSw1cNXL9JXYl3AigAE7ywbm/AZ+ll3Ox4qXJHNjVr6h...\n[WARN ][o.e.c.n.ThreadWatchdog   ] hot threads dump due to active threads not making progress (gzip compressed, base64-encoded, and split into 2 parts on preceding log lines; ...\n----\n\nTo reconstruct the thread dump, base64-decode the data and decompress it using `gzip`. For instance, on Unix-like systems:\n\n[source,sh]\n----\ncat watchdog.log | sed -e 's/.*://' | base64 --decode | gzip --decompress\n----\n\nThis mechanism can be controlled with the following settings:\n\n`network.thread.watchdog.interval`:::\n(<<static-cluster-setting,Static>>, <<time-units,time value>>)\nDefines the interval between watchdog checks. Defaults to `5s`. Set to `0` to\ndisable the network thread watchdog.\n\n`network.thread.watchdog.quiet_time`:::\n(<<static-cluster-setting,Static>>, <<time-units,time value>>)\nDefines the interval between watchdog warnings. Defaults to `10m`.\n\n--\n"
}
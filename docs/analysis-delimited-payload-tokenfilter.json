{
    "meta": {
        "timestamp": "2024-11-01T02:49:24.922068",
        "size": 7797,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-delimited-payload-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-delimited-payload-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-delimited-payload-tokenfilter]]\n=== Delimited payload token filter\n++++\n<titleabbrev>Delimited payload</titleabbrev>\n++++\n\n[WARNING]\n====\nThe older name `delimited_payload_filter` is deprecated and should not be used\nwith new indices. Use `delimited_payload` instead.\n====\n\nSeparates a token stream into tokens and payloads based on a specified\ndelimiter.\n\nFor example, you can use the `delimited_payload` filter with a `|` delimiter to\nsplit `the|1 quick|2 fox|3` into the tokens `the`, `quick`, and `fox`\nwith respective payloads of `1`, `2`, and `3`.\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/payloads/DelimitedPayloadTokenFilter.html[DelimitedPayloadTokenFilter].\n\n[NOTE]\n.Payloads\n====\nA payload is user-defined binary data associated with a token position and\nstored as base64-encoded bytes.\n\n{es} does not store token payloads by default. To store payloads, you must:\n\n* Set the <<term-vector,`term_vector`>> mapping parameter to\n  `with_positions_payloads` or `with_positions_offsets_payloads` for any field\n  storing payloads.\n* Use an index analyzer that includes the `delimited_payload` filter\n\nYou can view stored payloads using the <<docs-termvectors,term vectors API>>.\n====\n\n[[analysis-delimited-payload-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the\n`delimited_payload` filter with the default `|` delimiter to split\n`the|0 brown|10 fox|5 is|0 quick|10` into tokens and payloads.\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\"delimited_payload\"],\n  \"text\": \"the|0 brown|10 fox|5 is|0 quick|10\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ the, brown, fox, is, quick ]\n--------------------------------------------------\n\nNote that the analyze API does not return stored payloads. For an example that\nincludes returned payloads, see\n<<analysis-delimited-payload-tokenfilter-return-stored-payloads>>.\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"the\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 6,\n      \"end_offset\": 14,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 15,\n      \"end_offset\": 20,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"is\",\n      \"start_offset\": 21,\n      \"end_offset\": 25,\n      \"type\": \"word\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 26,\n      \"end_offset\": 34,\n      \"type\": \"word\",\n      \"position\": 4\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-delimited-payload-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`delimited-payload` filter to configure a new <<analysis-custom-analyzer,custom\nanalyzer>>.\n\n[source,console]\n--------------------------------------------------\nPUT delimited_payload\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_delimited_payload\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"delimited_payload\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-delimited-payload-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`delimiter`::\n(Optional, string)\nCharacter used to separate tokens from payloads. Defaults to `|`. \n\n`encoding`::\n+\n--\n(Optional, string)\nData type for the stored payload. Valid values are:\n\n`float`:::\n(Default) Float\n\n`identity`:::\nCharacters\n\n`int`:::\nInteger\n--\n\n[[analysis-delimited-payload-tokenfilter-customize]]\n==== Customize and add to an analyzer\n\nTo customize the `delimited_payload` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following <<indices-create-index,create index API>> request\nuses a custom `delimited_payload` filter to configure a new\n<<analysis-custom-analyzer,custom analyzer>>. The custom `delimited_payload`\nfilter uses the `+` delimiter to separate tokens from payloads. Payloads are\nencoded as integers.\n\n[source,console]\n--------------------------------------------------\nPUT delimited_payload_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_plus_delimited\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"plus_delimited\" ]\n        }\n      },\n      \"filter\": {\n        \"plus_delimited\": {\n          \"type\": \"delimited_payload\",\n          \"delimiter\": \"+\",\n          \"encoding\": \"int\"\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-delimited-payload-tokenfilter-return-stored-payloads]]\n==== Return stored payloads\n\nUse the <<indices-create-index,create index API>> to create an index that:\n\n* Includes a field that stores term vectors with payloads.\n* Uses a <<analysis-custom-analyzer,custom index analyzer>> with the\n  `delimited_payload` filter.\n\n[source,console]\n--------------------------------------------------\nPUT text_payloads\n{\n  \"mappings\": {\n    \"properties\": {\n      \"text\": {\n        \"type\": \"text\",\n        \"term_vector\": \"with_positions_payloads\",\n        \"analyzer\": \"payload_delimiter\"\n      }\n    }\n  },\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"payload_delimiter\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"delimited_payload\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\nAdd a document containing payloads to the index.\n\n[source,console]\n--------------------------------------------------\nPOST text_payloads/_doc/1\n{\n  \"text\": \"the|0 brown|3 fox|4 is|0 quick|10\"\n}\n--------------------------------------------------\n// TEST[continued]\n\nUse the <<docs-termvectors,term vectors API>> to return the document's tokens\nand base64-encoded payloads.\n\n[source,console]\n--------------------------------------------------\nGET text_payloads/_termvectors/1\n{\n  \"fields\": [ \"text\" ],\n  \"payloads\": true\n}\n--------------------------------------------------\n// TEST[continued]\n\nThe API returns the following response:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"_index\": \"text_payloads\",\n  \"_id\": \"1\",\n  \"_version\": 1,\n  \"found\": true,\n  \"took\": 8,\n  \"term_vectors\": {\n    \"text\": {\n      \"field_statistics\": {\n        \"sum_doc_freq\": 5,\n        \"doc_count\": 1,\n        \"sum_ttf\": 5\n      },\n      \"terms\": {\n        \"brown\": {\n          \"term_freq\": 1,\n          \"tokens\": [\n            {\n              \"position\": 1,\n              \"payload\": \"QEAAAA==\"\n            }\n          ]\n        },\n        \"fox\": {\n          \"term_freq\": 1,\n          \"tokens\": [\n            {\n              \"position\": 2,\n              \"payload\": \"QIAAAA==\"\n            }\n          ]\n        },\n        \"is\": {\n          \"term_freq\": 1,\n          \"tokens\": [\n            {\n              \"position\": 3,\n              \"payload\": \"AAAAAA==\"\n            }\n          ]\n        },\n        \"quick\": {\n          \"term_freq\": 1,\n          \"tokens\": [\n            {\n              \"position\": 4,\n              \"payload\": \"QSAAAA==\"\n            }\n          ]\n        },\n        \"the\": {\n          \"term_freq\": 1,\n          \"tokens\": [\n            {\n              \"position\": 0,\n              \"payload\": \"AAAAAA==\"\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"took\": 8/\"took\": \"$body.took\"/]\n"
}
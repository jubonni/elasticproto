{
    "meta": {
        "timestamp": "2024-11-01T02:49:24.859065",
        "size": 4313,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "delayed-allocation",
        "version": "8.15"
    },
    "doc": "[[delayed-allocation]]\n=== Delaying allocation when a node leaves\n\nWhen a node leaves the cluster for whatever reason, intentional or otherwise,\nthe master reacts by:\n\n* Promoting a replica shard to primary to replace any primaries that were on the node.\n* Allocating replica shards to replace the missing replicas (assuming there are enough nodes).\n* Rebalancing shards evenly across the remaining nodes.\n\nThese actions are intended to protect the cluster against data loss by\nensuring that every shard is fully replicated as soon as possible.\n\nEven though we throttle concurrent recoveries both at the\n<<recovery,node level>> and at the <<cluster-shard-allocation-settings,cluster level>>, this\n``shard-shuffle'' can still put a lot of extra load on the cluster which\nmay not be necessary if the missing node is likely to return soon. Imagine\nthis scenario:\n\n* Node 5 loses network connectivity.\n* The master promotes a replica shard to primary for each primary that was on Node 5.\n* The master allocates new replicas to other nodes in the cluster.\n* Each new replica makes an entire copy of the primary shard across the network.\n* More shards are moved to different nodes to rebalance the cluster.\n* Node 5 returns after a few minutes.\n* The master rebalances the cluster by allocating shards to Node 5.\n\nIf the master had just waited for a few minutes, then the missing shards could\nhave been re-allocated to Node 5 with the minimum of network traffic. This\nprocess would be even quicker for idle shards (shards not receiving indexing\nrequests) which have been automatically <<indices-flush, flushed>>.\n\nThe allocation of replica shards which become unassigned because a node has\nleft can be delayed with the `index.unassigned.node_left.delayed_timeout`\ndynamic setting, which defaults to `1m`.\n\nThis setting can be updated on a live index (or on all indices):\n\n[source,console]\n------------------------------\nPUT _all/_settings\n{\n  \"settings\": {\n    \"index.unassigned.node_left.delayed_timeout\": \"5m\"\n  }\n}\n------------------------------\n// TEST[s/^/PUT test\\n/]\n\nWith delayed allocation enabled, the above scenario changes to look like this:\n\n* Node 5 loses network connectivity.\n* The master promotes a replica shard to primary for each primary that was on Node 5.\n* The master logs a message that allocation of unassigned shards has been delayed, and for how long.\n* The cluster remains yellow because there are unassigned replica shards.\n* Node 5 returns after a few minutes, before the `timeout` expires.\n* The missing replicas are re-allocated to Node 5 (and sync-flushed shards recover almost immediately).\n\nNOTE: This setting will not affect the promotion of replicas to primaries, nor\nwill it affect the assignment of replicas that have not been assigned\npreviously. In particular, delayed allocation does not come into effect after a full cluster restart.\nAlso, in case of a master failover situation, elapsed delay time is forgotten\n(i.e. reset to the full initial delay).\n\n==== Cancellation of shard relocation\n\nIf delayed allocation times out, the master assigns the missing shards to\nanother node which will start recovery. If the missing node rejoins the\ncluster, and its shards still have the same sync-id as the primary, shard\nrelocation will be cancelled and the synced shard will be used for recovery\ninstead.\n\nFor this reason, the default `timeout` is set to just one minute: even if shard\nrelocation begins, cancelling recovery in favour of the synced shard is cheap.\n\n==== Monitoring delayed unassigned shards\n\nThe number of shards whose allocation has been delayed by this timeout setting\ncan be viewed with the <<cluster-health,cluster health API>>:\n\n[source,console]\n------------------------------\nGET _cluster/health <1>\n------------------------------\n\n<1> This request will return a `delayed_unassigned_shards` value.\n\n==== Removing a node permanently\n\nIf a node is not going to return and you would like Elasticsearch to allocate\nthe missing shards immediately, just update the timeout to zero:\n\n\n[source,console]\n------------------------------\nPUT _all/_settings\n{\n  \"settings\": {\n    \"index.unassigned.node_left.delayed_timeout\": \"0\"\n  }\n}\n------------------------------\n// TEST[s/^/PUT test\\n/]\n\nYou can reset the timeout as soon as the missing shards have started to recover.\n"
}
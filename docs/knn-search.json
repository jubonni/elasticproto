{
    "meta": {
        "timestamp": "2024-11-01T03:02:52.843600",
        "size": 38914,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "knn-search",
        "version": "8.15"
    },
    "doc": "[[knn-search]]\n== k-nearest neighbor (kNN) search\n++++\n<titleabbrev>kNN search</titleabbrev>\n++++\n\n//tag::knn-def[]\nA _k-nearest neighbor_ (kNN) search finds the _k_ nearest vectors to a query\nvector, as measured by a similarity metric.\n//end::knn-def[]\n\nCommon use cases for kNN include:\n\n* Relevance ranking based on natural language processing (NLP) algorithms\n* Product recommendations and recommendation engines\n* Similarity search for images or videos\n\n[discrete]\n[[knn-prereqs]]\n=== Prerequisites\n\n* To run a kNN search, you must be able to convert your data into meaningful\nvector values. You can\n{ml-docs}/ml-nlp-text-emb-vector-search-example.html[create these vectors using\na natural language processing (NLP) model in {es}], or generate them outside\n{es}. Vectors can be added to documents as <<dense-vector,`dense_vector`>> field\nvalues. Queries are represented as vectors with the same dimension.\n+\nDesign your vectors so that the closer a document's vector is to a query vector,\nbased on a similarity metric, the better its match.\n\n* To complete the steps in this guide, you must have the following\n<<privileges-list-indices,index privileges>>:\n\n** `create_index` or `manage` to create an index with a `dense_vector` field\n** `create`, `index`, or `write` to add data to the index you created\n** `read` to search the index\n\n[discrete]\n[[knn-methods]]\n=== kNN methods\n\n{es} supports two methods for kNN search:\n\n* <<approximate-knn,Approximate kNN>> using the `knn` search\noption or `knn` query\n\n* <<exact-knn,Exact, brute-force kNN>> using a `script_score` query with a\nvector function\n\nIn most cases, you'll want to use approximate kNN. Approximate kNN offers lower\nlatency at the cost of slower indexing and imperfect accuracy.\n\nExact, brute-force kNN guarantees accurate results but doesn't scale well with\nlarge datasets. With this approach, a `script_score` query must scan each\nmatching document to compute the vector function, which can result in slow\nsearch speeds. However, you can improve latency by using a <<query-dsl,query>>\nto limit the number of matching documents passed to the function. If you\nfilter your data to a small subset of documents, you can get good search\nperformance using this approach.\n\n[discrete]\n[[approximate-knn]]\n=== Approximate kNN\n\nWARNING: Compared to other types of search, approximate kNN search has specific\nresource requirements. In particular, all vector data must fit in the node's\npage cache for it to be efficient. Please consult the\n<<tune-knn-search, approximate kNN search tuning guide>> for important notes on\nconfiguration and sizing.\n\nTo run an approximate kNN search, use the <<search-api-knn, `knn` option>>\nto search one or more `dense_vector` fields with indexing enabled.\n\n. Explicitly map one or more `dense_vector` fields. Approximate kNN search\nrequires the following mapping options:\n+\n--\n* A `similarity` value. This value determines the similarity metric used to\nscore documents based on similarity between the query and document vector. For a\nlist of available metrics, see the <<dense-vector-similarity,`similarity`>>\nparameter documentation. The `similarity` setting defaults to `cosine`.\n\n[source,console]\n----\nPUT image-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"image-vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"similarity\": \"l2_norm\"\n      },\n      \"title-vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 5,\n        \"similarity\": \"l2_norm\"\n      },\n      \"title\": {\n        \"type\": \"text\"\n      },\n      \"file-type\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n----\n--\n\n. Index your data.\n+\n[source,console]\n----\nPOST image-index/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"image-vector\": [1, 5, -20], \"title-vector\": [12, 50, -10, 0, 1], \"title\": \"moose family\", \"file-type\": \"jpg\" }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"image-vector\": [42, 8, -15], \"title-vector\": [25, 1, 4, -12, 2], \"title\": \"alpine lake\", \"file-type\": \"png\" }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"image-vector\": [15, 11, 23], \"title-vector\": [1, 5, 25, 50, 20], \"title\": \"full moon\", \"file-type\": \"jpg\" }\n...\n----\n//TEST[continued]\n//TEST[s/\\.\\.\\.//]\n\n. Run the search using the <<search-api-knn, `knn` option>> or the\n<<query-dsl-knn-query,`knn` query>> (expert case).\n+\n[source,console]\n----\nPOST image-index/_search\n{\n  \"knn\": {\n    \"field\": \"image-vector\",\n    \"query_vector\": [-5, 9, -12],\n    \"k\": 10,\n    \"num_candidates\": 100\n  },\n  \"fields\": [ \"title\", \"file-type\" ]\n}\n----\n//TEST[continued]\n// TEST[s/\"k\": 10/\"k\": 3/]\n// TEST[s/\"num_candidates\": 100/\"num_candidates\": 3/]\n\nThe <<search-api-response-body-score,document `_score`>> is determined by\nthe similarity between the query and document vector. See\n<<dense-vector-similarity, `similarity`>> for more information on how kNN\nsearch scores are computed.\n\nNOTE: Support for approximate kNN search was added in version 8.0. Before\nthis, `dense_vector` fields did not support enabling `index` in the mapping.\nIf you created an index prior to 8.0 containing `dense_vector` fields, then to\nsupport approximate kNN search the data must be reindexed using a new field\nmapping that sets `index: true` which is the default option.\n\n[discrete]\n[[tune-approximate-knn-for-speed-accuracy]]\n==== Tune approximate kNN for speed or accuracy\n\nTo gather results, the kNN search API finds a `num_candidates` number of\napproximate nearest neighbor candidates on each shard. The search computes the\nsimilarity of these candidate vectors to the query vector, selecting the `k`\nmost similar results from each shard. The search then merges the results from\neach shard to return the global top `k` nearest neighbors.\n\nYou can increase `num_candidates` for more accurate results at the cost of\nslower search speeds. A search with a high value for `num_candidates`\nconsiders more candidates from each shard. This takes more time, but the\nsearch has a higher probability of finding the true `k` top nearest neighbors.\n\nSimilarly, you can decrease `num_candidates` for faster searches with\npotentially less accurate results.\n\n[discrete]\n[[approximate-knn-using-byte-vectors]]\n==== Approximate kNN using byte vectors\n\nThe approximate kNN search API supports `byte` value vectors in\naddition to `float` value vectors. Use the <<search-api-knn, `knn` option>>\nto search a `dense_vector` field with <<dense-vector-params, `element_type`>> set to\n`byte` and indexing enabled.\n\n. Explicitly map one or more `dense_vector` fields with\n<<dense-vector-params, `element_type`>> set to `byte` and indexing enabled.\n+\n[source,console]\n----\nPUT byte-image-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"byte-image-vector\": {\n        \"type\": \"dense_vector\",\n        \"element_type\": \"byte\",\n        \"dims\": 2\n      },\n      \"title\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n----\n// TEST[continued]\n\n. Index your data ensuring all vector values\nare integers within the range [-128, 127].\n+\n[source,console]\n----\nPOST byte-image-index/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"byte-image-vector\": [5, -20], \"title\": \"moose family\" }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"byte-image-vector\": [8, -15], \"title\": \"alpine lake\" }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"byte-image-vector\": [11, 23], \"title\": \"full moon\" }\n----\n//TEST[continued]\n\n. Run the search using the <<search-api-knn, `knn` option>>\nensuring the `query_vector` values are integers within the\nrange [-128, 127].\n+\n[source,console]\n----\nPOST byte-image-index/_search\n{\n  \"knn\": {\n    \"field\": \"byte-image-vector\",\n    \"query_vector\": [-5, 9],\n    \"k\": 10,\n    \"num_candidates\": 100\n  },\n  \"fields\": [ \"title\" ]\n}\n----\n// TEST[continued]\n// TEST[s/\"k\": 10/\"k\": 3/]\n// TEST[s/\"num_candidates\": 100/\"num_candidates\": 3/]\n\n\n_Note_: In addition to the standard byte array, one can also provide a hex-encoded string value\nfor the `query_vector` param. As an example, the search request above can also be expressed as follows,\nwhich would yield the same results\n[source,console]\n----\nPOST byte-image-index/_search\n{\n  \"knn\": {\n    \"field\": \"byte-image-vector\",\n    \"query_vector\": \"fb09\",\n    \"k\": 10,\n    \"num_candidates\": 100\n  },\n  \"fields\": [ \"title\" ]\n}\n----\n// TEST[continued]\n// TEST[s/\"k\": 10/\"k\": 3/]\n// TEST[s/\"num_candidates\": 100/\"num_candidates\": 3/]\n\n[discrete]\n[[knn-search-quantized-example]]\n==== Byte quantized kNN search\n\nIf you want to provide `float` vectors, but want the memory savings of `byte` vectors, you can use the\n<<dense-vector-quantization, quantization>> feature. Quantization allows you to provide `float` vectors, but\ninternally they are indexed as `byte` vectors. Additionally, the original `float` vectors are still retained\nin the index.\n\nNOTE: The default index type for `dense_vector` is `int8_hnsw`.\n\nTo use quantization, you can use the index type `int8_hnsw` or `int4_hnsw` object in the `dense_vector` mapping.\n\n[source,console]\n----\nPUT quantized-image-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"image-vector\": {\n        \"type\": \"dense_vector\",\n        \"element_type\": \"float\",\n        \"dims\": 2,\n        \"index\": true,\n        \"index_options\": {\n          \"type\": \"int8_hnsw\"\n        }\n      },\n      \"title\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n----\n// TEST[continued]\n\n. Index your `float` vectors.\n+\n[source,console]\n----\nPOST quantized-image-index/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"image-vector\": [0.1, -2], \"title\": \"moose family\" }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"image-vector\": [0.75, -1], \"title\": \"alpine lake\" }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"image-vector\": [1.2, 0.1], \"title\": \"full moon\" }\n----\n//TEST[continued]\n\n. Run the search using the <<search-api-knn, `knn` option>>. When searching, the `float` vector is\nautomatically quantized to a `byte` vector.\n+\n[source,console]\n----\nPOST quantized-image-index/_search\n{\n  \"knn\": {\n    \"field\": \"image-vector\",\n    \"query_vector\": [0.1, -2],\n    \"k\": 10,\n    \"num_candidates\": 100\n  },\n  \"fields\": [ \"title\" ]\n}\n----\n// TEST[continued]\n// TEST[s/\"k\": 10/\"k\": 3/]\n// TEST[s/\"num_candidates\": 100/\"num_candidates\": 3/]\n\nSince the original `float` vectors are still retained in the index, you can optionally use them for re-scoring. Meaning,\nyou can search over all the vectors quickly using the `int8_hnsw` index and then rescore only the top `k` results. This\nprovides the best of both worlds, fast search and accurate scoring.\n\n[source,console]\n----\nPOST quantized-image-index/_search\n{\n  \"knn\": {\n    \"field\": \"image-vector\",\n    \"query_vector\": [0.1, -2],\n    \"k\": 15,\n    \"num_candidates\": 100\n  },\n  \"fields\": [ \"title\" ],\n  \"rescore\": {\n    \"window_size\": 10,\n    \"query\": {\n      \"rescore_query\": {\n        \"script_score\": {\n          \"query\": {\n            \"match_all\": {}\n          },\n          \"script\": {\n            \"source\": \"cosineSimilarity(params.query_vector, 'image-vector') + 1.0\",\n            \"params\": {\n              \"query_vector\": [0.1, -2]\n            }\n          }\n        }\n      }\n    }\n  }\n}\n----\n// TEST[continued]\n// TEST[s/\"k\": 15/\"k\": 3/]\n// TEST[s/\"num_candidates\": 100/\"num_candidates\": 3/]\n\n[discrete]\n[[knn-search-filter-example]]\n==== Filtered kNN search\n\nThe kNN search API supports restricting the search using a filter. The search\nwill return the top `k` documents that also match the filter query.\n\nThe following request performs an approximate kNN search filtered by the\n`file-type` field:\n\n[source,console]\n----\nPOST image-index/_search\n{\n  \"knn\": {\n    \"field\": \"image-vector\",\n    \"query_vector\": [54, 10, -2],\n    \"k\": 5,\n    \"num_candidates\": 50,\n    \"filter\": {\n      \"term\": {\n        \"file-type\": \"png\"\n      }\n    }\n  },\n  \"fields\": [\"title\"],\n  \"_source\": false\n}\n----\n// TEST[continued]\n\nNOTE: The filter is applied **during** the approximate kNN search to ensure\nthat `k` matching documents are returned. This contrasts with a\npost-filtering approach, where the filter is applied **after** the approximate\nkNN search completes. Post-filtering has the downside that it sometimes\nreturns fewer than k results, even when there are enough matching documents.\n\n[discrete]\n[[approximate-knn-search-and-filtering]]\n==== Approximate kNN search and filtering\n\nUnlike conventional query filtering, where more restrictive filters typically lead to faster queries,\napplying filters in an approximate kNN search with an HNSW index can decrease performance.\nThis is because searching the HNSW graph requires additional exploration to obtain the `num_candidates`\nthat meet the filter criteria.\n\nTo avoid significant performance drawbacks, Lucene implements the following strategies per segment:\n\n* If the filtered document count is less than or equal to num_candidates, the search bypasses the HNSW graph and\nuses a brute force search on the filtered documents.\n\n* While exploring the HNSW graph, if the number of nodes explored exceeds the number of documents that satisfy the filter,\nthe search will stop exploring the graph and switch to a brute force search over the filtered documents.\n\n\n[discrete]\n==== Combine approximate kNN with other features\n\nYou can perform 'hybrid retrieval' by providing both the\n<<search-api-knn, `knn` option>> and a <<request-body-search-query, `query`>>:\n\n[source,console]\n----\nPOST image-index/_search\n{\n  \"query\": {\n    \"match\": {\n      \"title\": {\n        \"query\": \"mountain lake\",\n        \"boost\": 0.9\n      }\n    }\n  },\n  \"knn\": {\n    \"field\": \"image-vector\",\n    \"query_vector\": [54, 10, -2],\n    \"k\": 5,\n    \"num_candidates\": 50,\n    \"boost\": 0.1\n  },\n  \"size\": 10\n}\n----\n// TEST[continued]\n\nThis search finds the global top `k = 5` vector matches, combines them with the matches from the `match` query, and\nfinally returns the 10 top-scoring results. The `knn` and `query` matches are combined through a disjunction, as if you\ntook a boolean 'or' between them. The top `k` vector results represent the global nearest neighbors across all index\nshards.\n\nThe score of each hit is the sum of the `knn` and `query` scores. You can specify a `boost` value to give a weight to\neach score in the sum. In the example above, the scores will be calculated as\n\n```\nscore = 0.9 * match_score + 0.1 * knn_score\n```\n\nThe `knn` option can also be used with <<search-aggregations, `aggregations`>>.\nIn general, {es} computes aggregations over all documents that match the search.\nSo for approximate kNN search, aggregations are calculated on the top `k`\nnearest documents. If the search also includes a `query`, then aggregations are\ncalculated on the combined set of `knn` and `query` matches.\n\n[discrete]\n[[knn-semantic-search]]\n==== Perform semantic search\n\nkNN search enables you to perform semantic search by using a previously deployed\n{ml-docs}/ml-nlp-search-compare.html#ml-nlp-text-embedding[text embedding model].\nInstead of literal matching on search terms, semantic search retrieves results\nbased on the intent and the contextual meaning of a search query.\n\nUnder the hood, the text embedding NLP model generates a dense vector from the\ninput query string called `model_text` you provide. Then, it is searched\nagainst an index containing dense vectors created with the same text embedding\n{ml} model. The search results are semantically similar as learned by the model.\n\n[IMPORTANT]\n=====================\nTo perform semantic search:\n\n* you need an index that contains the dense vector representation of the input\ndata to search against,\n\n* you must use the same text embedding model for search that you used to create\nthe dense vectors from the input data,\n\n* the text embedding NLP model deployment must be started.\n=====================\n\nReference the deployed text embedding model or the model deployment in the\n`query_vector_builder` object and provide the search query as `model_text`:\n\n[source,js]\n----\n(...)\n{\n  \"knn\": {\n    \"field\": \"dense-vector-field\",\n    \"k\": 10,\n    \"num_candidates\": 100,\n    \"query_vector_builder\": {\n      \"text_embedding\": { <1>\n        \"model_id\": \"my-text-embedding-model\", <2>\n        \"model_text\": \"The opposite of blue\" <3>\n      }\n    }\n  }\n}\n(...)\n----\n// NOTCONSOLE\n\n<1> The {nlp} task to perform. It must be `text_embedding`.\n<2> The ID of the text embedding model to use to generate the dense vectors from\nthe query string. Use the same model that generated the embeddings from the\ninput text in the index you search against. You can use the value of the\n`deployment_id` instead in the `model_id` argument.\n<3> The query string from which the model generates the dense vector\nrepresentation.\n\nFor more information on how to deploy a trained model and use it to create text\nembeddings, refer to this\n{ml-docs}/ml-nlp-text-emb-vector-search-example.html[end-to-end example].\n\n\n[discrete]\n==== Search multiple kNN fields\n\nIn addition to 'hybrid retrieval', you can search more than one kNN vector field at a time:\n\n[source,console]\n----\nPOST image-index/_search\n{\n  \"query\": {\n    \"match\": {\n      \"title\": {\n        \"query\": \"mountain lake\",\n        \"boost\": 0.9\n      }\n    }\n  },\n  \"knn\": [ {\n    \"field\": \"image-vector\",\n    \"query_vector\": [54, 10, -2],\n    \"k\": 5,\n    \"num_candidates\": 50,\n    \"boost\": 0.1\n  },\n  {\n    \"field\": \"title-vector\",\n    \"query_vector\": [1, 20, -52, 23, 10],\n    \"k\": 10,\n    \"num_candidates\": 10,\n    \"boost\": 0.5\n  }],\n  \"size\": 10\n}\n----\n// TEST[continued]\n\nThis search finds the global top `k = 5` vector matches for `image-vector` and the global `k = 10` for the `title-vector`.\nThese top values are then combined with the matches from the `match` query and the top-10 documents are returned.\nThe multiple `knn` entries and the `query` matches are combined through a disjunction,\nas if you took a boolean 'or' between them. The top `k` vector results represent the global nearest neighbors across\nall index shards.\n\nThe scoring for a doc with the above configured boosts would be:\n\n```\nscore = 0.9 * match_score + 0.1 * knn_score_image-vector + 0.5 * knn_score_title-vector\n```\n\n[discrete]\n[[knn-similarity-search]]\n==== Search kNN with expected similarity\n\nWhile kNN is a powerful tool, it always tries to return `k` nearest neighbors. Consequently, when using `knn` with\na `filter`, you could filter out all relevant documents and only have irrelevant ones left to search. In that situation,\n`knn` will still do its best to return `k` nearest neighbors, even though those neighbors could be far away in the\nvector space.\n\nTo alleviate this worry, there is a `similarity` parameter available in the `knn` clause. This value is the required\nminimum similarity for a vector to be considered a match. The `knn` search flow with this parameter is as follows:\n\n--\n* Apply any user provided `filter` queries\n* Explore the vector space to get `k` vectors\n* Do not return any vectors that are further away than the configured `similarity`\n--\n\nNOTE: `similarity` is the true <<dense-vector-similarity, similarity>> before it has been transformed into `_score` and boost applied.\n\nFor each configured <<dense-vector-similarity, similarity>>, here is the corresponding inverted `_score` function. This is so if you are wanting to filter from a `_score` perspective, you can do this minor transformation to correctly reject irrelevant results.\n--\n* `l2_norm`: `sqrt((1 / _score) - 1)`\n* `cosine`: `(2 * _score) - 1`\n* `dot_product`: `(2 * _score) - 1`\n* `max_inner_product`:\n** `_score < 1`: `1 - (1 / _score)`\n** `_score >= 1`: `_score - 1`\n--\n\nHere is an example. In this example we search for the given `query_vector` for `k` nearest neighbors. However, with\n`filter` applied and requiring that the found vectors have at least the provided `similarity` between them.\n[source,console]\n----\nPOST image-index/_search\n{\n  \"knn\": {\n    \"field\": \"image-vector\",\n    \"query_vector\": [1, 5, -20],\n    \"k\": 5,\n    \"num_candidates\": 50,\n    \"similarity\": 36,\n    \"filter\": {\n      \"term\": {\n        \"file-type\": \"png\"\n      }\n    }\n  },\n  \"fields\": [\"title\"],\n  \"_source\": false\n}\n----\n// TEST[continued]\n\nIn our data set, the only document with the file type of `png` has a vector of `[42, 8, -15]`. The `l2_norm` distance\nbetween `[42, 8, -15]` and `[1, 5, -20]` is `41.412`, which is greater than the configured similarity of `36`. Meaning,\nthis search will return no hits.\n\n[discrete]\n[[nested-knn-search]]\n==== Nested kNN Search\n\nIt is common for text to exceed a particular model's token limit and requires chunking before building the embeddings\nfor individual chunks. When using <<nested,`nested`>> with <<dense-vector,`dense_vector`>>, you can achieve nearest\npassage retrieval without copying top-level document metadata.\n\nHere is a simple passage vectors index that stores vectors and some top-level metadata for filtering.\n\n[source,console]\n----\nPUT passage_vectors\n{\n    \"mappings\": {\n        \"properties\": {\n            \"full_text\": {\n                \"type\": \"text\"\n            },\n            \"creation_time\": {\n                \"type\": \"date\"\n            },\n            \"paragraph\": {\n                \"type\": \"nested\",\n                \"properties\": {\n                    \"vector\": {\n                        \"type\": \"dense_vector\",\n                        \"dims\": 2,\n                        \"index_options\": {\n                            \"type\": \"hnsw\"\n                        }\n                    },\n                    \"text\": {\n                        \"type\": \"text\",\n                        \"index\": false\n                    }\n                }\n            }\n        }\n    }\n}\n----\n//TEST[continued]\n\nWith the above mapping, we can index multiple passage vectors along with storing the individual passage text.\n\n[source,console]\n----\nPOST passage_vectors/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"full_text\": \"first paragraph another paragraph\", \"creation_time\": \"2019-05-04\", \"paragraph\": [ { \"vector\": [ 0.45, 45 ], \"text\": \"first paragraph\", \"paragraph_id\": \"1\" }, { \"vector\": [ 0.8, 0.6 ], \"text\": \"another paragraph\", \"paragraph_id\": \"2\" } ] }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"full_text\": \"number one paragraph number two paragraph\", \"creation_time\": \"2020-05-04\", \"paragraph\": [ { \"vector\": [ 1.2, 4.5 ], \"text\": \"number one paragraph\", \"paragraph_id\": \"1\" }, { \"vector\": [ -1, 42 ], \"text\": \"number two paragraph\", \"paragraph_id\": \"2\" } ] }\n----\n//TEST[continued]\n//TEST[s/\\.\\.\\.//]\n\nThe query will seem very similar to a typical kNN search:\n[source,console]\n----\nPOST passage_vectors/_search\n{\n    \"fields\": [\"full_text\", \"creation_time\"],\n    \"_source\": false,\n    \"knn\": {\n        \"query_vector\": [\n            0.45,\n            45\n        ],\n        \"field\": \"paragraph.vector\",\n        \"k\": 2,\n        \"num_candidates\": 2\n    }\n}\n----\n//TEST[continued]\n\nNote below that even though we have 4 total vectors, we still return two documents. kNN search over nested dense_vectors\nwill always diversify the top results over the top-level document. Meaning, `\"k\"` top-level documents will be returned,\nscored by their nearest passage vector (e.g. `\"paragraph.vector\"`).\n\n[source,console-result]\n----\n{\n    \"took\": 4,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 1,\n        \"successful\": 1,\n        \"skipped\": 0,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": {\n            \"value\": 2,\n            \"relation\": \"eq\"\n        },\n        \"max_score\": 1.0,\n        \"hits\": [\n            {\n                \"_index\": \"passage_vectors\",\n                \"_id\": \"1\",\n                \"_score\": 1.0,\n                \"fields\": {\n                    \"creation_time\": [\n                        \"2019-05-04T00:00:00.000Z\"\n                    ],\n                    \"full_text\": [\n                        \"first paragraph another paragraph\"\n                    ]\n                }\n            },\n            {\n                \"_index\": \"passage_vectors\",\n                \"_id\": \"2\",\n                \"_score\": 0.9997144,\n                \"fields\": {\n                    \"creation_time\": [\n                        \"2020-05-04T00:00:00.000Z\"\n                    ],\n                    \"full_text\": [\n                        \"number one paragraph number two paragraph\"\n                    ]\n                }\n            }\n        ]\n    }\n}\n----\n// TESTRESPONSE[s/\"took\": 4/\"took\" : \"$body.took\"/]\n\nWhat if you wanted to filter by some top-level document metadata? You can do this by adding `filter` to your\n`knn` clause.\n\n\nNOTE: `filter` will always be over the top-level document metadata. This means you cannot filter based on `nested`\n      field metadata.\n\n[source,console]\n----\nPOST passage_vectors/_search\n{\n    \"fields\": [\n        \"creation_time\",\n        \"full_text\"\n    ],\n    \"_source\": false,\n    \"knn\": {\n        \"query_vector\": [\n            0.45,\n            45\n        ],\n        \"field\": \"paragraph.vector\",\n        \"k\": 2,\n        \"num_candidates\": 2,\n        \"filter\": {\n            \"bool\": {\n                \"filter\": [\n                    {\n                        \"range\": {\n                            \"creation_time\": {\n                                \"gte\": \"2019-05-01\",\n                                \"lte\": \"2019-05-05\"\n                            }\n                        }\n                    }\n                ]\n            }\n        }\n    }\n}\n----\n//TEST[continued]\n\nNow we have filtered based on the top level `\"creation_time\"` and only one document falls within that range.\n\n[source,console-result]\n----\n{\n    \"took\": 4,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 1,\n        \"successful\": 1,\n        \"skipped\": 0,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": {\n            \"value\": 1,\n            \"relation\": \"eq\"\n        },\n        \"max_score\": 1.0,\n        \"hits\": [\n            {\n                \"_index\": \"passage_vectors\",\n                \"_id\": \"1\",\n                \"_score\": 1.0,\n                \"fields\": {\n                    \"creation_time\": [\n                        \"2019-05-04T00:00:00.000Z\"\n                    ],\n                    \"full_text\": [\n                        \"first paragraph another paragraph\"\n                    ]\n                }\n            }\n        ]\n    }\n}\n----\n// TESTRESPONSE[s/\"took\": 4/\"took\" : \"$body.took\"/]\n\n[discrete]\n[[nested-knn-search-inner-hits]]\n==== Nested kNN Search with Inner hits\n\nAdditionally, if you wanted to extract the nearest passage for a matched document, you can supply <<inner-hits, inner_hits>>\nto the `knn` clause.\n\nNOTE: When using `inner_hits` and multiple `knn` clauses, be sure to specify the <<inner-hits-options,`inner_hits.name`>>\nfield. Otherwise, a naming clash can occur and fail the search request.\n\n[source,console]\n----\nPOST passage_vectors/_search\n{\n    \"fields\": [\n        \"creation_time\",\n        \"full_text\"\n    ],\n    \"_source\": false,\n    \"knn\": {\n        \"query_vector\": [\n            0.45,\n            45\n        ],\n        \"field\": \"paragraph.vector\",\n        \"k\": 2,\n        \"num_candidates\": 2,\n        \"inner_hits\": {\n            \"_source\": false,\n            \"fields\": [\n                \"paragraph.text\"\n            ],\n            \"size\": 1\n        }\n    }\n}\n----\n//TEST[continued]\n\nNow the result will contain the nearest found paragraph when searching.\n\n[source,console-result]\n----\n{\n    \"took\": 4,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 1,\n        \"successful\": 1,\n        \"skipped\": 0,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": {\n            \"value\": 2,\n            \"relation\": \"eq\"\n        },\n        \"max_score\": 1.0,\n        \"hits\": [\n            {\n                \"_index\": \"passage_vectors\",\n                \"_id\": \"1\",\n                \"_score\": 1.0,\n                \"fields\": {\n                    \"creation_time\": [\n                        \"2019-05-04T00:00:00.000Z\"\n                    ],\n                    \"full_text\": [\n                        \"first paragraph another paragraph\"\n                    ]\n                },\n                \"inner_hits\": {\n                    \"paragraph\": {\n                        \"hits\": {\n                            \"total\": {\n                                \"value\": 2,\n                                \"relation\": \"eq\"\n                            },\n                            \"max_score\": 1.0,\n                            \"hits\": [\n                                {\n                                    \"_index\": \"passage_vectors\",\n                                    \"_id\": \"1\",\n                                    \"_nested\": {\n                                        \"field\": \"paragraph\",\n                                        \"offset\": 0\n                                    },\n                                    \"_score\": 1.0,\n                                    \"fields\": {\n                                        \"paragraph\": [\n                                            {\n                                                \"text\": [\n                                                    \"first paragraph\"\n                                                ]\n                                            }\n                                        ]\n                                    }\n                                }\n                            ]\n                        }\n                    }\n                }\n            },\n            {\n                \"_index\": \"passage_vectors\",\n                \"_id\": \"2\",\n                \"_score\": 0.9997144,\n                \"fields\": {\n                    \"creation_time\": [\n                        \"2020-05-04T00:00:00.000Z\"\n                    ],\n                    \"full_text\": [\n                        \"number one paragraph number two paragraph\"\n                    ]\n                },\n                \"inner_hits\": {\n                    \"paragraph\": {\n                        \"hits\": {\n                            \"total\": {\n                                \"value\": 2,\n                                \"relation\": \"eq\"\n                            },\n                            \"max_score\": 0.9997144,\n                            \"hits\": [\n                                {\n                                    \"_index\": \"passage_vectors\",\n                                    \"_id\": \"2\",\n                                    \"_nested\": {\n                                        \"field\": \"paragraph\",\n                                        \"offset\": 1\n                                    },\n                                    \"_score\": 0.9997144,\n                                    \"fields\": {\n                                        \"paragraph\": [\n                                            {\n                                                \"text\": [\n                                                    \"number two paragraph\"\n                                                ]\n                                            }\n                                        ]\n                                    }\n                                }\n                            ]\n                        }\n                    }\n                }\n            }\n        ]\n    }\n}\n----\n// TESTRESPONSE[s/\"took\": 4/\"took\" : \"$body.took\"/]\n\n\n[discrete]\n[[knn-indexing-considerations]]\n==== Indexing considerations\n\nFor approximate kNN search, {es} stores the dense vector values of each\nsegment as an https://arxiv.org/abs/1603.09320[HNSW graph]. Indexing vectors for\napproximate kNN search can take substantial time because of how expensive it is\nto build these graphs. You may need to increase the client request timeout for\nindex and bulk requests. The <<tune-knn-search, approximate kNN tuning guide>>\ncontains important guidance around indexing performance, and how the index\nconfiguration can affect search performance.\n\nIn addition to its search-time tuning parameters, the HNSW algorithm has\nindex-time parameters that trade off between the cost of building the graph,\nsearch speed, and accuracy. When setting up the `dense_vector` mapping, you\ncan use the <<dense-vector-index-options, `index_options`>> argument to adjust\nthese parameters:\n\n[source,console]\n----\nPUT image-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"image-vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 3,\n        \"similarity\": \"l2_norm\",\n        \"index_options\": {\n          \"type\": \"hnsw\",\n          \"m\": 32,\n          \"ef_construction\": 100\n        }\n      }\n    }\n  }\n}\n----\n\n[discrete]\n[[approximate-knn-limitations]]\n==== Limitations for approximate kNN search\n\n* When using kNN search in <<modules-cross-cluster-search,{ccs}>>, the <<ccs-min-roundtrips,`ccs_minimize_roundtrips`>>\noption is not supported.\n\n* {blank}\ninclude::{es-ref-dir}/search/knn-search.asciidoc[tag=hnsw-algorithm]\n\nNOTE: Approximate kNN search always uses the\n<<dfs-query-then-fetch,`dfs_query_then_fetch`>> search type in order to gather\nthe global top `k` matches across shards. You cannot set the\n`search_type` explicitly when running kNN search.\n\n[discrete]\n[[exact-knn]]\n=== Exact kNN\n\nTo run an exact kNN search, use a `script_score` query with a vector function.\n\n. Explicitly map one or more `dense_vector` fields. If you don't intend to use\nthe field for approximate kNN, set the `index` mapping option to `false`. This\ncan significantly improve indexing speed.\n+\n[source,console]\n----\nPUT product-index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"product-vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 5,\n        \"index\": false\n      },\n      \"price\": {\n        \"type\": \"long\"\n      }\n    }\n  }\n}\n----\n\n. Index your data.\n+\n[source,console]\n----\nPOST product-index/_bulk?refresh=true\n{ \"index\": { \"_id\": \"1\" } }\n{ \"product-vector\": [230.0, 300.33, -34.8988, 15.555, -200.0], \"price\": 1599 }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"product-vector\": [-0.5, 100.0, -13.0, 14.8, -156.0], \"price\": 799 }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"product-vector\": [0.5, 111.3, -13.0, 14.8, -156.0], \"price\": 1099 }\n...\n----\n//TEST[continued]\n//TEST[s/\\.\\.\\.//]\n\n. Use the <<search-search,search API>> to run a `script_score` query containing\na <<vector-functions,vector function>>.\n+\nTIP: To limit the number of matched documents passed to the vector function, we\nrecommend you specify a filter query in the `script_score.query` parameter. If\nneeded, you can use a <<query-dsl-match-all-query,`match_all` query>> in this\nparameter to match all documents. However, matching all documents can\nsignificantly increase search latency.\n+\n[source,console]\n----\nPOST product-index/_search\n{\n  \"query\": {\n    \"script_score\": {\n      \"query\" : {\n        \"bool\" : {\n          \"filter\" : {\n            \"range\" : {\n              \"price\" : {\n                \"gte\": 1000\n              }\n            }\n          }\n        }\n      },\n      \"script\": {\n        \"source\": \"cosineSimilarity(params.queryVector, 'product-vector') + 1.0\",\n        \"params\": {\n          \"queryVector\": [-0.5, 90.0, -10, 14.8, -156.0]\n        }\n      }\n    }\n  }\n}\n----\n//TEST[continued]\n\n[discrete]\n[[dense-vector-knn-search-reranking]]\n==== Oversampling and rescoring for quantized vectors\n\nAll forms of quantization will result in some accuracy loss and as the quantization level increases the accuracy loss will also increase.\nGenerally, we have found that:\n- `int8` requires minimal if any rescoring\n- `int4` requires some rescoring for higher accuracy and larger recall scenarios. Generally, oversampling by 1.5x-2x recovers most of the accuracy loss.\n- `bbq` requires rescoring except on exceptionally large indices or models specifically designed for quantization. We have found that between 3x-5x oversampling is generally sufficient. But for fewer dimensions or vectors that do not quantize well, higher oversampling may be required.\n\nThere are two main ways to oversample and rescore. The first is to utilize the <<rescore, rescore section>> in the `_search` request.\n\nHere is an example using the top level `knn` search with oversampling and using `rescore` to rerank the results:\n\n[source,console]\n--------------------------------------------------\nPOST /my-index/_search\n{\n  \"size\": 10, <1>\n  \"knn\": {\n    \"query_vector\": [0.04283529, 0.85670587, -0.51402352, 0],\n    \"field\": \"my_int4_vector\",\n    \"k\": 20, <2>\n    \"num_candidates\": 50\n  },\n  \"rescore\": {\n    \"window_size\": 20, <3>\n    \"query\": {\n      \"rescore_query\": {\n        \"script_score\": {\n          \"query\": {\n            \"match_all\": {}\n          },\n          \"script\": {\n            \"source\": \"(dotProduct(params.queryVector, 'my_int4_vector') + 1.0)\", <4>\n            \"params\": {\n              \"queryVector\": [0.04283529, 0.85670587, -0.51402352, 0]\n            }\n          }\n        }\n      },\n      \"query_weight\": 0, <5>\n      \"rescore_query_weight\": 1 <6>\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip: setup not provided]\n<1> The number of results to return, note its only 10 and we will oversample by 2x, gathering 20 nearest neighbors.\n<2> The number of results to return from the KNN search. This will do an approximate KNN search with 50 candidates\nper HNSW graph and use the quantized vectors, returning the 20 most similar vectors\naccording to the quantized score. Additionally, since this is the top-level `knn` object, the global top 20 results\nwill from all shards will be gathered before rescoring. Combining with `rescore`, this is oversampling by `2x`, meaning\ngathering 20 nearest neighbors according to quantized scoring and rescoring with higher fidelity float vectors.\n<3> The number of results to rescore, if you want to rescore all results, set this to the same value as `k`\n<4> The script to rescore the results. Script score will interact directly with the originally provided float32 vector.\n<5> The weight of the original query, here we simply throw away the original score\n<6> The weight of the rescore query, here we only use the rescore query\n\nThe second way is to score per shard with the <<query-dsl-knn-query, knn query>> and <<query-dsl-script-score-query, script_score query >>. Generally, this means that there will be more rescoring per shard, but this\ncan increase overall recall at the cost of compute.\n\n[source,console]\n--------------------------------------------------\nPOST /my-index/_search\n{\n  \"size\": 10, <1>\n  \"query\": {\n    \"script_score\": {\n      \"query\": {\n        \"knn\": { <2>\n          \"query_vector\": [0.04283529, 0.85670587, -0.51402352, 0],\n          \"field\": \"my_int4_vector\",\n          \"num_candidates\": 20 <3>\n        }\n      },\n      \"script\": {\n        \"source\": \"(dotProduct(params.queryVector, 'my_int4_vector') + 1.0)\", <4>\n        \"params\": {\n          \"queryVector\": [0.04283529, 0.85670587, -0.51402352, 0]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip: setup not provided]\n<1> The number of results to return\n<2> The `knn` query to perform the initial search, this is executed per-shard\n<3> The number of candidates to use for the initial approximate `knn` search. This will search using the quantized vectors\nand return the top 20 candidates per shard to then be scored\n<4> The script to score the results. Script score will interact directly with the originally provided float32 vector.\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T03:02:52.075605",
        "size": 12332,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/attachment.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "attachment",
        "version": "8.15"
    },
    "doc": "[[attachment]]\n=== Attachment processor\n++++\n<titleabbrev>Attachment</titleabbrev>\n++++\n\nThe attachment processor lets Elasticsearch extract file attachments in common formats (such as PPT, XLS, and PDF) by\nusing the Apache text extraction library https://tika.apache.org/[Tika].\n\nThe source field must be a base64 encoded binary. If you do not want to incur\nthe overhead of converting back and forth between base64, you can use the CBOR\nformat instead of JSON and specify the field as a bytes array instead of a string\nrepresentation. The processor will skip the base64 decoding then.\n\n[[using-attachment]]\n==== Using the attachment processor in a pipeline\n\n[[attachment-options]]\n.Attachment options\n[options=\"header\"]\n|======\n| Name                   | Required  | Default          | Description\n| `field`                | yes       | -                | The field to get the base64 encoded field from\n| `target_field`         | no        | attachment       | The field that will hold the attachment information\n| `indexed_chars`        | no        | 100000           | The number of chars being used for extraction to prevent huge fields. Use `-1` for no limit.\n| `indexed_chars_field`  | no        | `null`           | Field name from which you can overwrite the number of chars being used for extraction. See `indexed_chars`.\n| `properties`           | no        | all properties   |\u00a0Array of properties to select to be stored. Can be `content`, `title`, `name`, `author`, `keywords`, `date`, `content_type`, `content_length`, `language`\n| `ignore_missing`       | no        | `false`          | If `true` and `field` does not exist, the processor quietly exits without modifying the document\n| `remove_binary`        | no        | `false`          | If `true`, the binary `field` will be removed from the document\n| `resource_name`        | no        |                  | Field containing the name of the resource to decode. If specified, the processor passes this resource name to the underlying Tika library to enable https://tika.apache.org/1.24.1/detection.html#Resource_Name_Based_Detection[Resource Name Based Detection].\n|======\n\n[discrete]\n[[attachment-json-ex]]\n==== Example\n\nIf attaching files to JSON documents, you must first encode the file as a base64\nstring. On Unix-like systems, you can do this using a `base64` command:\n\n[source,shell]\n----\nbase64 -in myfile.rtf\n----\n\nThe command returns the base64-encoded string for the file. The following base64\nstring is for an `.rtf` file containing the text `Lorem ipsum dolor sit amet`:\n`e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=`.\n\nUse an attachment processor to decode the string and extract the file's\nproperties:\n\n[source,console]\n----\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"remove_binary\": false\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=attachment\n{\n  \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\"\n}\nGET my-index-000001/_doc/my_id\n----\n\nThe document's `attachment` object contains extracted properties for the file:\n\n[source,console-result]\n----\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 22,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\",\n    \"attachment\": {\n      \"content_type\": \"application/rtf\",\n      \"language\": \"ro\",\n      \"content\": \"Lorem ipsum dolor sit amet\",\n      \"content_length\": 28\n    }\n  }\n}\n----\n// TESTRESPONSE[s/\"_seq_no\": \\d+/\"_seq_no\" : $body._seq_no/ s/\"_primary_term\" : 1/\"_primary_term\" : $body._primary_term/]\n\nNOTE: Keeping the binary as a field within the document might consume a lot of resources. It is highly recommended\n      to remove that field from the document. Set `remove_binary` to `true` to automatically remove the field.\n\n[[attachment-fields]]\n==== Exported fields\n\nThe fields which might be extracted from a document are:\n\n* `content`,\n* `title`,\n* `author`,\n* `keywords`,\n* `date`,\n* `content_type`,\n* `content_length`,\n* `language`,\n* `modified`,\n* `format`,\n* `identifier`,\n* `contributor`,\n* `coverage`,\n* `modifier`,\n* `creator_tool`,\n* `publisher`,\n* `relation`,\n* `rights`,\n* `source`,\n* `type`,\n* `description`,\n* `print_date`,\n* `metadata_date`,\n* `latitude`,\n* `longitude`,\n* `altitude`,\n* `rating`,\n* `comments`\n\nTo extract only certain `attachment` fields, specify the `properties` array:\n\n[source,console]\n----\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"properties\": [ \"content\", \"title\" ],\n        \"remove_binary\": false\n      }\n    }\n  ]\n}\n----\n\nNOTE: Extracting contents from binary data is a resource intensive operation and\n      consumes a lot of resources. It is highly recommended to run pipelines\n      using this processor in a dedicated ingest node.\n\n[[attachment-cbor]]\n==== Use the attachment processor with CBOR\n\nTo avoid encoding and decoding JSON to base64, you can instead pass CBOR data to\nthe attachment processor. For example, the following request creates the\n`cbor-attachment` pipeline, which uses the attachment processor.\n\n[source,console]\n----\nPUT _ingest/pipeline/cbor-attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"remove_binary\": false\n      }\n    }\n  ]\n}\n----\n\nThe following Python script passes CBOR data to an HTTP indexing request that\nincludes the `cbor-attachment` pipeline. The HTTP request headers use a\n`content-type` of `application/cbor`.\n\nNOTE: Not all {es} clients support custom HTTP request headers.\n\n[source,python]\n----\nimport cbor2\nimport requests\n\nfile = 'my-file'\nheaders = {'content-type': 'application/cbor'}\n\nwith open(file, 'rb') as f:\n  doc = {\n    'data': f.read()\n  }\n  requests.put(\n    'http://localhost:9200/my-index-000001/_doc/my_id?pipeline=cbor-attachment',\n    data=cbor2.dumps(doc),\n    headers=headers\n  )\n----\n\n[[attachment-extracted-chars]]\n==== Limit the number of extracted chars\n\nTo prevent extracting too many chars and overload the node memory, the number of chars being used for extraction\nis limited by default to `100000`. You can change this value by setting `indexed_chars`. Use `-1` for no limit but\nensure when setting this that your node will have enough HEAP to extract the content of very big documents.\n\nYou can also define this limit per document by extracting from a given field the limit to set. If the document\nhas that field, it will overwrite the `indexed_chars` setting. To set this field, define the `indexed_chars_field`\nsetting.\n\nFor example:\n\n[source,console]\n--------------------------------------------------\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"indexed_chars\" : 11,\n        \"indexed_chars_field\" : \"max_size\",\n        \"remove_binary\": false\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=attachment\n{\n  \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\"\n}\nGET my-index-000001/_doc/my_id\n--------------------------------------------------\n\nReturns this:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id\",\n  \"_version\": 1,\n  \"_seq_no\": 35,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\",\n    \"attachment\": {\n      \"content_type\": \"application/rtf\",\n      \"language\": \"is\",\n      \"content\": \"Lorem ipsum\",\n      \"content_length\": 11\n    }\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"_seq_no\": \\d+/\"_seq_no\" : $body._seq_no/ s/\"_primary_term\" : 1/\"_primary_term\" : $body._primary_term/]\n\n\n[source,console]\n--------------------------------------------------\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information\",\n  \"processors\" : [\n    {\n      \"attachment\" : {\n        \"field\" : \"data\",\n        \"indexed_chars\" : 11,\n        \"indexed_chars_field\" : \"max_size\",\n        \"remove_binary\": false\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id_2?pipeline=attachment\n{\n  \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\",\n  \"max_size\": 5\n}\nGET my-index-000001/_doc/my_id_2\n--------------------------------------------------\n\nReturns this:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"found\": true,\n  \"_index\": \"my-index-000001\",\n  \"_id\": \"my_id_2\",\n  \"_version\": 1,\n  \"_seq_no\": 40,\n  \"_primary_term\": 1,\n  \"_source\": {\n    \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\",\n    \"max_size\": 5,\n    \"attachment\": {\n      \"content_type\": \"application/rtf\",\n      \"language\": \"sl\",\n      \"content\": \"Lorem\",\n      \"content_length\": 5\n    }\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"_seq_no\": \\d+/\"_seq_no\" : $body._seq_no/ s/\"_primary_term\" : 1/\"_primary_term\" : $body._primary_term/]\n\n\n[[attachment-with-arrays]]\n==== Using the attachment processor with arrays\n\nTo use the attachment processor within an array of attachments the\n{ref}/foreach-processor.html[foreach processor] is required. This\nenables the attachment processor to be run on the individual elements\nof the array.\n\nFor example, given the following source:\n\n[source,js]\n--------------------------------------------------\n{\n  \"attachments\" : [\n    {\n      \"filename\" : \"ipsum.txt\",\n      \"data\" : \"dGhpcyBpcwpqdXN0IHNvbWUgdGV4dAo=\"\n    },\n    {\n      \"filename\" : \"test.txt\",\n      \"data\" : \"VGhpcyBpcyBhIHRlc3QK\"\n    }\n  ]\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nIn this case, we want to process the data field in each element\nof the attachments field and insert\nthe properties into the document so the following `foreach`\nprocessor is used:\n\n[source,console]\n--------------------------------------------------\nPUT _ingest/pipeline/attachment\n{\n  \"description\" : \"Extract attachment information from arrays\",\n  \"processors\" : [\n    {\n      \"foreach\": {\n        \"field\": \"attachments\",\n        \"processor\": {\n          \"attachment\": {\n            \"target_field\": \"_ingest._value.attachment\",\n            \"field\": \"_ingest._value.data\",\n            \"remove_binary\": false\n          }\n        }\n      }\n    }\n  ]\n}\nPUT my-index-000001/_doc/my_id?pipeline=attachment\n{\n  \"attachments\" : [\n    {\n      \"filename\" : \"ipsum.txt\",\n      \"data\" : \"dGhpcyBpcwpqdXN0IHNvbWUgdGV4dAo=\"\n    },\n    {\n      \"filename\" : \"test.txt\",\n      \"data\" : \"VGhpcyBpcyBhIHRlc3QK\"\n    }\n  ]\n}\nGET my-index-000001/_doc/my_id\n--------------------------------------------------\n\nReturns this:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"_index\" : \"my-index-000001\",\n  \"_id\" : \"my_id\",\n  \"_version\" : 1,\n  \"_seq_no\" : 50,\n  \"_primary_term\" : 1,\n  \"found\" : true,\n  \"_source\" : {\n    \"attachments\" : [\n      {\n        \"filename\" : \"ipsum.txt\",\n        \"data\" : \"dGhpcyBpcwpqdXN0IHNvbWUgdGV4dAo=\",\n        \"attachment\" : {\n          \"content_type\" : \"text/plain; charset=ISO-8859-1\",\n          \"language\" : \"en\",\n          \"content\" : \"this is\\njust some text\",\n          \"content_length\" : 24\n        }\n      },\n      {\n        \"filename\" : \"test.txt\",\n        \"data\" : \"VGhpcyBpcyBhIHRlc3QK\",\n        \"attachment\" : {\n          \"content_type\" : \"text/plain; charset=ISO-8859-1\",\n          \"language\" : \"en\",\n          \"content\" : \"This is a test\",\n          \"content_length\" : 16\n        }\n      }\n    ]\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"_seq_no\" : \\d+/\"_seq_no\" : $body._seq_no/ s/\"_primary_term\" : 1/\"_primary_term\" : $body._primary_term/]\n\n\nNote that the `target_field` needs to be set, otherwise the\ndefault value is used which is a top level field `attachment`. The\nproperties on this top level field will contain the value of the\nfirst attachment only. However, by specifying the\n`target_field` on to a value on `_ingest._value` it will correctly\nassociate the properties with the correct attachment.\n"
}
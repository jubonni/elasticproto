{
    "meta": {
        "size": 10328,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-getting-started.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "esql-getting-started",
        "version": "8.15"
    },
    "doc": "[[esql-getting-started]]\n== Getting started with {esql} queries\n++++\n<titleabbrev>Getting started</titleabbrev>\n++++\n\nThis guide shows how you can use {esql} to query and aggregate your data.\n\n[TIP]\n====\nThis getting started is also available as an https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/esql/esql-getting-started.ipynb[interactive Python notebook] in the `elasticsearch-labs` GitHub repository.\n====\n\n[discrete]\n[[esql-getting-started-prerequisites]]\n=== Prerequisites\n\nTo follow along with the queries in this guide, you can either set up your own\ndeployment, or use Elastic's public {esql} demo environment.\n\ninclude::{es-ref-dir}/tab-widgets/esql/esql-getting-started-widget-sample-data.asciidoc[]\n\n[discrete]\n[[esql-getting-started-running-queries]]\n=== Run an {esql} query\n\nIn {kib}, you can use Console or Discover to run {esql} queries:\n\ninclude::{es-ref-dir}/tab-widgets/esql/esql-getting-started-widget-discover-console.asciidoc[]\n\n[discrete]\n[[esql-getting-started-first-query]]\n=== Your first {esql} query\n\nEach {esql} query starts with a <<esql-source-commands,source command>>. A\nsource command produces a table, typically with data from {es}.\n\nimage::images/esql/source-command.svg[A source command producing a table from {es},align=\"center\"]\n\nThe <<esql-from>> source command returns a table with documents from a data\nstream, index, or alias. Each row in the resulting table represents a document.\nThis query returns up to 1000 documents from the `sample_data` index:\n\n[source,esql]\n----\ninclude::{esql-specs}/docs.csv-spec[tag=gs-from]\n----\n\nEach column corresponds to a field, and can be accessed by the name of that\nfield.\n\n[TIP]\n====\n{esql} keywords are case-insensitive. The following query is identical to the\nprevious one:\n\n[source,esql]\n----\ninclude::{esql-specs}/docs.csv-spec[tag=gs-from-lowercase]\n----\n====\n\n[discrete]\n[[esql-getting-started-limit]]\n=== Processing commands\n\nA source command can be followed by one or more\n<<esql-processing-commands,processing commands>>, separated by a pipe character:\n`|`. Processing commands change an input table by adding, removing, or changing\nrows and columns. Processing commands can perform filtering, projection,\naggregation, and more.\n\nimage::images/esql/esql-limit.png[A processing command changing an input table,align=\"center\",width=\"60%\"]\n\nFor example, you can use the <<esql-limit>> command to limit the number of rows\nthat are returned, up to a maximum of 10,000 rows:\n\n[source,esql]\n----\ninclude::{esql-specs}/docs.csv-spec[tag=gs-limit]\n----\n\n[TIP]\n====\nFor readability, you can put each command on a separate line. However, you don't\nhave to. The following query is identical to the previous one:\n\n[source,esql]\n----\ninclude::{esql-specs}/docs.csv-spec[tag=gs-limit-one-line]\n----\n====\n\n[discrete]\n[[esql-getting-started-sort]]\n==== Sort a table\n\nimage::images/esql/esql-sort.png[A processing command sorting an input table,align=\"center\",width=\"60%\"]\n\nAnother processing command is the <<esql-sort>> command. By default, the rows\nreturned by `FROM` don't have a defined sort order. Use the `SORT` command to\nsort rows on one or more columns:\n\n[source,esql]\n----\ninclude::{esql-specs}/docs.csv-spec[tag=gs-sort]\n----\n\n[discrete]\n[[esql-getting-started-where]]\n==== Query the data\n\nUse the <<esql-where>> command to query the data. For example, to find all\nevents with a duration longer than 5ms:\n\n[source,esql]\n----\ninclude::{esql-specs}/where.csv-spec[tag=gs-where]\n----\n\n`WHERE` supports several <<esql-operators,operators>>. For example, you can use <<esql-like-operator>> to run a wildcard query against the `message` column:\n\n[source,esql]\n----\ninclude::{esql-specs}/where-like.csv-spec[tag=gs-like]\n----\n\n[discrete]\n[[esql-getting-started-more-commands]]\n==== More processing commands\n\nThere are many other processing commands, like <<esql-keep>> and <<esql-drop>>\nto keep or drop columns, <<esql-enrich>> to enrich a table with data from\nindices in {es}, and <<esql-dissect>> and <<esql-grok>> to process data. Refer\nto <<esql-processing-commands>> for an overview of all processing commands.\n\n[discrete]\n[[esql-getting-started-chaining]]\n=== Chain processing commands\n\nYou can chain processing commands, separated by a pipe character: `|`. Each\nprocessing command works on the output table of the previous command. The result\nof a query is the table produced by the final processing command.\n\nimage::images/esql/esql-sort-limit.png[Processing commands can be chained,align=\"center\"]\n\nThe following example first sorts the table on `@timestamp`, and next limits the\nresult set to 3 rows:\n\n[source,esql]\n----\ninclude::{esql-specs}/docs.csv-spec[tag=gs-chaining]\n----\n\nNOTE: The order of processing commands is important. First limiting the result\nset to 3 rows before sorting those 3 rows would most likely return a result that\nis different than this example, where the sorting comes before the limit.\n\n[discrete]\n[[esql-getting-started-eval]]\n=== Compute values\n\nUse the <<esql-eval>> command to append columns to a table, with calculated\nvalues. For example, the following query appends a `duration_ms` column. The\nvalues in the column are computed by dividing `event_duration` by 1,000,000. In\nother words: `event_duration` converted from nanoseconds to milliseconds.\n\n[source,esql]\n----\ninclude::{esql-specs}/eval.csv-spec[tag=gs-eval]\n----\n\n`EVAL` supports several <<esql-functions,functions>>. For example, to round a\nnumber to the closest number with the specified number of digits, use the\n<<esql-round>> function:\n\n[source,esql]\n----\ninclude::{esql-specs}/eval.csv-spec[tag=gs-round]\n----\n\n[discrete]\n[[esql-getting-started-stats]]\n=== Calculate statistics\n\n{esql} can not only be used to query your data, you can also use it to aggregate\nyour data. Use the <<esql-stats-by>> command to calculate statistics. For\nexample, the median duration:\n\n[source,esql]\n----\ninclude::{esql-specs}/stats.csv-spec[tag=gs-stats]\n----\n\nYou can calculate multiple stats with one command:\n\n[source,esql]\n----\ninclude::{esql-specs}/stats.csv-spec[tag=gs-two-stats]\n----\n\nUse `BY` to group calculated stats by one or more columns. For example, to\ncalculate the median duration per client IP:\n\n[source,esql]\n----\ninclude::{esql-specs}/stats.csv-spec[tag=gs-stats-by]\n----\n\n[discrete]\n[[esql-getting-started-access-columns]]\n=== Access columns\n\nYou can access columns by their name. If a name contains special characters,\n<<esql-identifiers,it needs to be quoted>> with backticks (+{backtick}+).\n\nAssigning an explicit name to a column created by `EVAL` or `STATS` is optional.\nIf you don't provide a name, the new column name is equal to the function\nexpression. For example:\n\n[source,esql]\n----\ninclude::{esql-specs}/eval.csv-spec[tag=gs-eval-no-column-name]\n----\n\nIn this query, `EVAL` adds a new column named `event_duration/1000000.0`.\nBecause its name contains special characters, to access this column, quote it\nwith backticks:\n\n[source,esql]\n----\ninclude::{esql-specs}/eval.csv-spec[tag=gs-eval-stats-backticks]\n----\n\n[discrete]\n[[esql-getting-started-histogram]]\n=== Create a histogram\n\nTo track statistics over time, {esql} enables you to create histograms using the\n<<esql-bucket>> function. `BUCKET` creates human-friendly bucket sizes\nand returns a value for each row that corresponds to the resulting bucket the\nrow falls into.\n\nCombine `BUCKET` with <<esql-stats-by>> to create a histogram. For example,\nto count the number of events per hour:\n\n[source,esql]\n----\ninclude::{esql-specs}/bucket.csv-spec[tag=gs-bucket-stats-by]\n----\n\nOr the median duration per hour:\n\n[source,esql]\n----\ninclude::{esql-specs}/bucket.csv-spec[tag=gs-bucket-stats-by-median]\n----\n\n[discrete]\n[[esql-getting-started-enrich]]\n=== Enrich data\n\n{esql} enables you to <<esql-enrich-data,enrich>> a table with data from indices\nin {es}, using the <<esql-enrich>> command.\n\nimage::images/esql/esql-enrich.png[align=\"center\"]\n\nBefore you can use `ENRICH`, you first need to\n<<esql-create-enrich-policy,create>> and <<esql-execute-enrich-policy,execute>>\nan <<esql-enrich-policy,enrich policy>>.\n\ninclude::{es-ref-dir}/tab-widgets/esql/esql-getting-started-widget-enrich-policy.asciidoc[]\n\nAfter creating and executing a policy, you can use it with the `ENRICH`\ncommand:\n\n[source,esql]\n----\ninclude::{esql-specs}/enrich.csv-spec[tag=gs-enrich]\n----\n\nYou can use the new `env` column that's added by the `ENRICH` command in\nsubsequent commands. For example, to calculate the median duration per\nenvironment:\n\n[source,esql]\n----\ninclude::{esql-specs}/enrich.csv-spec[tag=gs-enrich-stats-by]\n----\n\nFor more about data enrichment with {esql}, refer to <<esql-enrich-data>>.\n\n[discrete]\n[[esql-getting-started-process-data]]\n=== Process data\n\nYour data may contain unstructured strings that you want to\n<<esql-process-data-with-dissect-and-grok,structure>> to make it easier to\nanalyze the data. For example, the sample data contains log messages like:\n\n[source,txt]\n----\n\"Connected to 10.1.0.3\"\n----\n\nBy extracting the IP address from these messages, you can determine which IP has\naccepted the most client connections.\n\nTo structure unstructured strings at query time, you can use the {esql}\n<<esql-dissect>> and <<esql-grok>> commands. `DISSECT` works by breaking up a\nstring using a delimiter-based pattern. `GROK` works similarly, but uses regular\nexpressions. This makes `GROK` more powerful, but generally also slower.\n\nIn this case, no regular expressions are needed, as the `message` is\nstraightforward: \"Connected to \", followed by the server IP. To match this\nstring, you can use the following `DISSECT` command:\n\n[source,esql]\n----\ninclude::{esql-specs}/dissect.csv-spec[tag=gs-dissect]\n----\n\nThis adds a `server_ip` column to those rows that have a `message` that matches\nthis pattern. For other rows, the value of `server_ip` is `null`.\n\nYou can use the new `server_ip` column that's added by the `DISSECT` command in\nsubsequent commands. For example, to determine how many connections each server\nhas accepted:\n\n[source,esql]\n----\ninclude::{esql-specs}/dissect.csv-spec[tag=gs-dissect-stats-by]\n----\n\nFor more about data processing with {esql}, refer to\n<<esql-process-data-with-dissect-and-grok>>.\n\n[discrete]\n[[esql-getting-learn-more]]\n=== Learn more\n\nTo learn more about {esql}, refer to <<esql-language>> and <<esql-using>>.\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T02:49:25.533070",
        "size": 4004,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-length-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-length-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-length-tokenfilter]]\n=== Length token filter\n++++\n<titleabbrev>Length</titleabbrev>\n++++\n\nRemoves tokens shorter or longer than specified character lengths.\nFor example, you can use the `length` filter to exclude tokens shorter than 2\ncharacters and tokens longer than 5 characters.\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/miscellaneous/LengthFilter.html[LengthFilter].\n\n[TIP]\n====\nThe `length` filter removes entire tokens. If you'd prefer to shorten tokens to\na specific length, use the <<analysis-truncate-tokenfilter,`truncate`>> filter.\n====\n\n[[analysis-length-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the `length`\nfilter to remove tokens longer than 4 characters:\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"length\",\n      \"min\": 0,\n      \"max\": 4\n    }\n  ],\n  \"text\": \"the quick brown fox jumps over the lazy dog\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ the, fox, over, the, lazy, dog ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"the\",\n      \"start_offset\": 0,\n      \"end_offset\": 3,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 16,\n      \"end_offset\": 19,\n      \"type\": \"word\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"over\",\n      \"start_offset\": 26,\n      \"end_offset\": 30,\n      \"type\": \"word\",\n      \"position\": 5\n    },\n    {\n      \"token\": \"the\",\n      \"start_offset\": 31,\n      \"end_offset\": 34,\n      \"type\": \"word\",\n      \"position\": 6\n    },\n    {\n      \"token\": \"lazy\",\n      \"start_offset\": 35,\n      \"end_offset\": 39,\n      \"type\": \"word\",\n      \"position\": 7\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 40,\n      \"end_offset\": 43,\n      \"type\": \"word\",\n      \"position\": 8\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-length-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`length` filter to configure a new \n<<analysis-custom-analyzer,custom analyzer>>.\n\n[source,console]\n--------------------------------------------------\nPUT length_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_length\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"length\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-length-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`min`::\n(Optional, integer)\nMinimum character length of a token. Shorter tokens are excluded from the\noutput. Defaults to `0`.\n\n`max`::\n(Optional, integer)\nMaximum character length of a token. Longer tokens are excluded from the output.\nDefaults to `Integer.MAX_VALUE`, which is `2^31-1` or `2147483647`.\n\n[[analysis-length-tokenfilter-customize]]\n==== Customize\n\nTo customize the `length` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following request creates a custom `length` filter that removes\ntokens shorter than 2 characters and tokens longer than 10 characters:\n\n[source,console]\n--------------------------------------------------\nPUT length_custom_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_length_2_to_10_char\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"length_2_to_10_char\" ]\n        }\n      },\n      \"filter\": {\n        \"length_2_to_10_char\": {\n          \"type\": \"length\",\n          \"min\": 2,\n          \"max\": 10\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
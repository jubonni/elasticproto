{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.386068",
        "size": 6661,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-service-cohere.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "infer-service-cohere",
        "version": "8.15"
    },
    "doc": "[[infer-service-cohere]]\n=== Cohere {infer} service\n\nCreates an {infer} endpoint to perform an {infer} task with the `cohere` service.\n\n\n[discrete]\n[[infer-service-cohere-api-request]]\n==== {api-request-title}\n\n`PUT /_inference/<task_type>/<inference_id>`\n\n[discrete]\n[[infer-service-cohere-api-path-params]]\n==== {api-path-parms-title}\n\n`<inference_id>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=inference-id]\n\n`<task_type>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=task-type]\n+\n--\nAvailable task types:\n\n* `completion`,\n* `rerank`,\n* `text_embedding`.\n--\n\n[discrete]\n[[infer-service-cohere-api-request-body]]\n==== {api-request-body-title}\n\n`chunking_settings`::\n(Optional, object)\ninclude::inference-shared.asciidoc[tag=chunking-settings]\n\n`max_chunking_size`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-max-chunking-size]\n\n`overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-overlap]\n\n`sentence_overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-sentence-overlap]\n\n`strategy`:::\n(Optional, string)\ninclude::inference-shared.asciidoc[tag=chunking-settings-strategy]\n\n`service`::\n(Required, string)\nThe type of service supported for the specified task type. In this case, \n`cohere`.\n\n`service_settings`::\n(Required, object)\ninclude::inference-shared.asciidoc[tag=service-settings]\n+\n--\nThese settings are specific to the `cohere` service.\n--\n\n`api_key`:::\n(Required, string)\nA valid API key of your Cohere account.\nYou can find your Cohere API keys or you can create a new one\nhttps://dashboard.cohere.com/api-keys[on the API keys settings page].\n+\n--\ninclude::inference-shared.asciidoc[tag=api-key-admonition]\n--\n\n`rate_limit`:::\n(Optional, object)\nBy default, the `cohere` service sets the number of requests allowed per minute to `10000`.\nThis value is the same for all task types.\nThis helps to minimize the number of rate limit errors returned from Cohere.\nTo modify this, set the `requests_per_minute` setting of this object in your service settings:\n+\n--\ninclude::inference-shared.asciidoc[tag=request-per-minute-example]\n\nMore information about Cohere's rate limits can be found in https://docs.cohere.com/docs/going-live#production-key-specifications[Cohere's production key docs].\n--\n+\n.`service_settings` for the `completion` task type\n[%collapsible%closed]\n=====\n`model_id`::\n(Optional, string)\nThe name of the model to use for the {infer} task.\nTo review the available `completion` models, refer to the\nhttps://docs.cohere.com/docs/models#command[Cohere docs].\n=====\n+\n.`service_settings` for the `rerank` task type\n[%collapsible%closed]\n=====\n`model_id`::\n(Optional, string)\nThe name of the model to use for the {infer} task.\nTo review the available `rerank` models, refer to the\nhttps://docs.cohere.com/reference/rerank-1[Cohere docs].\n=====\n+\n.`service_settings` for the `text_embedding` task type\n[%collapsible%closed]\n=====\n`embedding_type`:::\n(Optional, string)\nSpecifies the types of embeddings you want to get back.\nDefaults to `float`.\nValid values are:\n* `byte`: use it for signed int8 embeddings (this is a synonym of `int8`).\n* `float`: use it for the default float embeddings.\n* `int8`: use it for signed int8 embeddings.\n\n`model_id`:::\n(Optional, string)\nThe name of the model to use for the {infer} task.\nTo review the available `text_embedding` models, refer to the\nhttps://docs.cohere.com/reference/embed[Cohere docs].\nThe default value for `text_embedding` is `embed-english-v2.0`.\n\n`similarity`:::\n(Optional, string)\nSimilarity measure. One of `cosine`, `dot_product`, `l2_norm`.\nDefaults based on the `embedding_type` (`float` -> `dot_product`, `int8/byte` -> `cosine`).\n=====\n\n\n\n`task_settings`::\n(Optional, object)\ninclude::inference-shared.asciidoc[tag=task-settings]\n+\n.`task_settings` for the `rerank` task type\n[%collapsible%closed]\n=====\n`return_documents`::\n(Optional, boolean)\nSpecify whether to return doc text within the results.\n\n`top_n`::\n(Optional, integer)\nThe number of most relevant documents to return, defaults to the number of the documents.\nIf this {infer} endpoint is used in a `text_similarity_reranker` retriever query and `top_n` is set, it must be greater than or equal to `rank_window_size` in the query.\n=====\n+\n.`task_settings` for the `text_embedding` task type\n[%collapsible%closed]\n=====\n`input_type`:::\n(Optional, string)\nSpecifies the type of input passed to the model.\nValid values are:\n* `classification`: use it for embeddings passed through a text classifier.\n* `clusterning`: use it for the embeddings run through a clustering algorithm.\n* `ingest`: use it for storing document embeddings in a vector database.\n* `search`: use it for storing embeddings of search queries run against a vector database to find relevant documents.\n+\nIMPORTANT: The `input_type` field is required when using embedding models `v3` and higher.\n\n`truncate`:::\n(Optional, string)\nSpecifies how the API handles inputs longer than the maximum token length.\nDefaults to `END`.\nValid values are:\n* `NONE`: when the input exceeds the maximum input token length an error is returned.\n* `START`: when the input exceeds the maximum input token length the start of the input is discarded.\n* `END`: when the input exceeds the maximum input token length the end of the input is discarded.\n=====\n\n\n[discrete]\n[[inference-example-cohere]]\n==== Cohere service examples\n\nThe following example shows how to create an {infer} endpoint called\n`cohere-embeddings` to perform a `text_embedding` task type.\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/text_embedding/cohere-embeddings\n{\n    \"service\": \"cohere\",\n    \"service_settings\": {\n        \"api_key\": \"<api_key>\",\n        \"model_id\": \"embed-english-light-v3.0\",\n        \"embedding_type\": \"byte\"\n    }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n\n\nThe following example shows how to create an {infer} endpoint called\n`cohere-rerank` to perform a `rerank` task type.\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/rerank/cohere-rerank\n{\n    \"service\": \"cohere\",\n    \"service_settings\": {\n        \"api_key\": \"<API-KEY>\",\n        \"model_id\": \"rerank-english-v3.0\"\n    },\n    \"task_settings\": {\n        \"top_n\": 10,\n        \"return_documents\": true\n    }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n\nFor more examples, also review the\nhttps://docs.cohere.com/docs/elasticsearch-and-cohere#rerank-search-results-with-cohere-and-elasticsearch[Cohere documentation]."
}
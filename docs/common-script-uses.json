{
    "meta": {
        "size": 13755,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/common-script-uses.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "common-script-uses",
        "version": "8.15"
    },
    "doc": "[[common-script-uses]]\n== Common scripting use cases\nYou can write a script to do almost anything, and sometimes, that's\nthe trouble. It's challenging to know what's possible with scripts,\nso the following examples address common uses cases where scripts are\nreally helpful.\n\n* <<scripting-field-extraction,Field extraction>>\n\n[[scripting-field-extraction]]\n=== Field extraction\nThe goal of field extraction is simple; you have fields in your data with a bunch of\ninformation, but you only want to extract pieces and parts.\n\nThere are two options at your disposal:\n\n* <<grok,Grok>> is a regular expression dialect that supports aliased\nexpressions that you can reuse. Because Grok sits on top of regular expressions\n(regex), any regular expressions are valid in grok as well.\n* <<dissect,Dissect>> extracts structured fields out of text, using\ndelimiters to define the matching pattern. Unlike grok, dissect doesn't use regular\nexpressions.\n\nLet's start with a simple example by adding the `@timestamp` and `message`\nfields to the `my-index` mapping as indexed fields. To remain flexible, use\n`wildcard` as the field type for `message`:\n\n[source,console]\n----\nPUT /my-index/\n{\n  \"mappings\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"format\": \"strict_date_optional_time||epoch_second\",\n        \"type\": \"date\"\n      },\n      \"message\": {\n        \"type\": \"wildcard\"\n      }\n    }\n  }\n}\n----\n\nAfter mapping the fields you want to retrieve, index a few records from\nyour log data into {es}. The following request uses the <<docs-bulk,bulk API>>\nto index raw log data into `my-index`. Instead of indexing all of your log\ndata, you can use a small sample to experiment with runtime fields.\n\n[source,console]\n----\nPOST /my-index/_bulk?refresh\n{\"index\":{}}\n{\"timestamp\":\"2020-04-30T14:30:17-05:00\",\"message\":\"40.135.0.0 - - [30/Apr/2020:14:30:17 -0500] \\\"GET /images/hm_bg.jpg HTTP/1.0\\\" 200 24736\"}\n{\"index\":{}}\n{\"timestamp\":\"2020-04-30T14:30:53-05:00\",\"message\":\"232.0.0.0 - - [30/Apr/2020:14:30:53 -0500] \\\"GET /images/hm_bg.jpg HTTP/1.0\\\" 200 24736\"}\n{\"index\":{}}\n{\"timestamp\":\"2020-04-30T14:31:12-05:00\",\"message\":\"26.1.0.0 - - [30/Apr/2020:14:31:12 -0500] \\\"GET /images/hm_bg.jpg HTTP/1.0\\\" 200 24736\"}\n{\"index\":{}}\n{\"timestamp\":\"2020-04-30T14:31:19-05:00\",\"message\":\"247.37.0.0 - - [30/Apr/2020:14:31:19 -0500] \\\"GET /french/splash_inet.html HTTP/1.0\\\" 200 3781\"}\n{\"index\":{}}\n{\"timestamp\":\"2020-04-30T14:31:22-05:00\",\"message\":\"247.37.0.0 - - [30/Apr/2020:14:31:22 -0500] \\\"GET /images/hm_nbg.jpg HTTP/1.0\\\" 304 0\"}\n{\"index\":{}}\n{\"timestamp\":\"2020-04-30T14:31:27-05:00\",\"message\":\"252.0.0.0 - - [30/Apr/2020:14:31:27 -0500] \\\"GET /images/hm_bg.jpg HTTP/1.0\\\" 200 24736\"}\n{\"index\":{}}\n{\"timestamp\":\"2020-04-30T14:31:28-05:00\",\"message\":\"not a valid apache log\"}\n----\n// TEST[continued]\n\n[discrete]\n[[field-extraction-ip]]\n==== Extract an IP address from a log message (Grok)\nIf you want to retrieve results that include `clientip`, you can add that\nfield as a runtime field in the mapping. The following runtime script defines a\ngrok pattern that extracts structured fields out of the `message` field. \n\nThe script matches on the `%{COMMONAPACHELOG}` log pattern, which understands\nthe structure of Apache logs. If the pattern matches (`clientip != null`), the\nscript emits the value of the matching IP address. If the pattern doesn't match,\nthe script just returns the field value without crashing.\n\n[source,console]\n----\nPUT my-index/_mappings\n{\n  \"runtime\": {\n    \"http.clientip\": {\n      \"type\": \"ip\",\n      \"script\": \"\"\"\n        String clientip=grok('%{COMMONAPACHELOG}').extract(doc[\"message\"].value)?.clientip;\n        if (clientip != null) emit(clientip); <1>\n      \"\"\"\n    }\n  }\n}\n----\n// TEST[continued]\n<1> This condition ensures that the script doesn't emit anything even if the pattern of\nthe message doesn't match.\n\nYou can define a simple query to run a search for a specific IP address and\nreturn all related fields. Use the `fields` parameter of the search API to\nretrieve the `http.clientip` runtime field.\n\n[source,console]\n----\nGET my-index/_search\n{\n  \"query\": {\n    \"match\": {\n      \"http.clientip\": \"40.135.0.0\"\n    }\n  },\n  \"fields\" : [\"http.clientip\"]\n}\n----\n// TEST[continued]\n// TEST[s/_search/_search\\?filter_path=hits/]\n\nThe response includes documents where the value for `http.clientip` matches\n`40.135.0.0`.\n\n[source,console-result]\n----\n{\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 1,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"my-index\",\n        \"_id\" : \"Rq-ex3gBA_A0V6dYGLQ7\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"timestamp\" : \"2020-04-30T14:30:17-05:00\",\n          \"message\" : \"40.135.0.0 - - [30/Apr/2020:14:30:17 -0500] \\\"GET /images/hm_bg.jpg HTTP/1.0\\\" 200 24736\"\n        },\n        \"fields\" : {\n          \"http.clientip\" : [\n            \"40.135.0.0\"\n          ]\n        }\n      }\n    ]\n  }\n}\n----\n// TESTRESPONSE[s/\"_id\" : \"Rq-ex3gBA_A0V6dYGLQ7\"/\"_id\": $body.hits.hits.0._id/]\n\n[discrete]\n[[field-extraction-parse]]\n==== Parse a string to extract part of a field (Dissect)\nInstead of matching on a log pattern like in the <<field-extraction-ip,previous example>>, you can just define a dissect pattern to include the parts of the string\nthat you want to discard.\n\nFor example, the log data at the start of this section includes a `message`\nfield. This field contains several pieces of data:\n\n[source,js]\n----\n\"message\" : \"247.37.0.0 - - [30/Apr/2020:14:31:22 -0500] \\\"GET /images/hm_nbg.jpg HTTP/1.0\\\" 304 0\"\n----\n// NOTCONSOLE\n\nYou can define a dissect pattern in a runtime field to extract the https://developer.mozilla.org/en-US/docs/Web/HTTP/Status[HTTP response code], which is\n`304` in the previous example.\n\n[source,console]\n----\nPUT my-index/_mappings\n{\n  \"runtime\": {\n    \"http.response\": {\n      \"type\": \"long\",\n      \"script\": \"\"\"\n        String response=dissect('%{clientip} %{ident} %{auth} [%{@timestamp}] \"%{verb} %{request} HTTP/%{httpversion}\" %{response} %{size}').extract(doc[\"message\"].value)?.response;\n        if (response != null) emit(Integer.parseInt(response));\n      \"\"\"\n    }\n  }\n}\n----\n// TEST[continued]\n\nYou can then run a query to retrieve a specific HTTP response using the\n`http.response` runtime field:\n\n[source,console]\n----\nGET my-index/_search\n{\n  \"query\": {\n    \"match\": {\n      \"http.response\": \"304\"\n    }\n  },\n  \"fields\" : [\"http.response\"]\n}\n----\n// TEST[continued]\n// TEST[s/_search/_search\\?filter_path=hits/]\n\nThe response includes a single document where the HTTP response is `304`:\n\n[source,console-result]\n----\n{\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 1,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"my-index\",\n        \"_id\" : \"Sq-ex3gBA_A0V6dYGLQ7\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"timestamp\" : \"2020-04-30T14:31:22-05:00\",\n          \"message\" : \"247.37.0.0 - - [30/Apr/2020:14:31:22 -0500] \\\"GET /images/hm_nbg.jpg HTTP/1.0\\\" 304 0\"\n        },\n        \"fields\" : {\n          \"http.response\" : [\n            304\n          ]\n        }\n      }\n    ]\n  }\n}\n----\n// TESTRESPONSE[s/\"_id\" : \"Sq-ex3gBA_A0V6dYGLQ7\"/\"_id\": $body.hits.hits.0._id/]\n\n[discrete]\n[[field-extraction-split]]\n==== Split values in a field by a separator (Dissect)\nLet's say you want to extract part of a field like in the previous example, but you\nwant to split on specific values. You can use a dissect pattern to extract only the\ninformation that you want, and also return that data in a specific format.\n\nFor example, let's say you have a bunch of garbage collection (gc) log data from {es}\nin this format:\n\n[source,txt]\n----\n[2021-04-27T16:16:34.699+0000][82460][gc,heap,exit]   class space    used 266K, capacity 384K, committed 384K, reserved 1048576K\n----\n// NOTCONSOLE\n\nYou only want to extract the `used`, `capacity`, and `committed` data, along with\nthe associated values. Let's index some a few documents containing log data to use as\nan example:\n\n[source,console]\n----\nPOST /my-index/_bulk?refresh\n{\"index\":{}}\n{\"gc\": \"[2021-04-27T16:16:34.699+0000][82460][gc,heap,exit]   class space    used 266K, capacity 384K, committed 384K, reserved 1048576K\"}\n{\"index\":{}}\n{\"gc\": \"[2021-03-24T20:27:24.184+0000][90239][gc,heap,exit]   class space    used 15255K, capacity 16726K, committed 16844K, reserved 1048576K\"}\n{\"index\":{}}\n{\"gc\": \"[2021-03-24T20:27:24.184+0000][90239][gc,heap,exit]  Metaspace       used 115409K, capacity 119541K, committed 120248K, reserved 1153024K\"}\n{\"index\":{}}\n{\"gc\": \"[2021-04-19T15:03:21.735+0000][84408][gc,heap,exit]   class space    used 14503K, capacity 15894K, committed 15948K, reserved 1048576K\"}\n{\"index\":{}}\n{\"gc\": \"[2021-04-19T15:03:21.735+0000][84408][gc,heap,exit]  Metaspace       used 107719K, capacity 111775K, committed 112724K, reserved 1146880K\"}\n{\"index\":{}}\n{\"gc\": \"[2021-04-27T16:16:34.699+0000][82460][gc,heap,exit]  class space  used 266K, capacity 367K, committed 384K, reserved 1048576K\"}\n----\n\nLooking at the data again, there's a timestamp, some other data that you're not\ninterested in, and then the `used`, `capacity`, and `committed` data:\n\n[source,txt]\n----\n[2021-04-27T16:16:34.699+0000][82460][gc,heap,exit]   class space    used 266K, capacity 384K, committed 384K, reserved 1048576K\n----\n\nYou can assign variables to each part of the data in the `gc` field, and then return\nonly the parts that you want. Anything in curly braces `{}` is considered a variable.\nFor example, the variables `[%{@timestamp}][%{code}][%{desc}]` will match the first\nthree chunks of data, all of which are in square brackets `[]`.\n\n[source,txt]\n----\n[%{@timestamp}][%{code}][%{desc}]  %{ident} used %{usize}, capacity %{csize}, committed %{comsize}, reserved %{rsize}\n----\n\nYour dissect pattern can include the terms `used`, `capacity`, and `committed` instead\nof using variables, because you want to return those terms exactly. You also assign\nvariables to the values you want to return, such as `%{usize}`, `%{csize}`, and \n`%{comsize}`. The separator in the log data is a comma, so your dissect pattern also\nneeds to use that separator.\n\nNow that you have a dissect pattern, you can include it in a Painless script as part\nof a runtime field. The script uses your dissect pattern to split apart the `gc`\nfield, and then returns exactly the information that you want as defined by the\n`emit` method. Because dissect uses simple syntax, you just need to tell it exactly\nwhat you want. \n\nThe following pattern tells dissect to return the term `used`, a blank space, the value\nfrom `gc.usize`, and a comma. This pattern repeats for the other data that you\nwant to retrieve. While this pattern might not be as useful in production, it provides\na lot of flexibility to experiment with and manipulate your data. In a production\nsetting, you might just want to use `emit(gc.usize)` and then aggregate on that value\nor use it in computations. \n\n[source,painless]\n----\nemit(\"used\" + ' ' + gc.usize + ', ' + \"capacity\" + ' ' + gc.csize + ', ' + \"committed\" + ' ' + gc.comsize)\n----\n\nPutting it all together, you can create a runtime field named `gc_size` in a search\nrequest. Using the <<search-fields-param,`fields` option>>, you can retrieve all values\nfor the `gc_size` runtime field. This query also includes a bucket aggregation to group\nyour data.\n\n[source,console]\n----\nGET my-index/_search\n{\n  \"runtime_mappings\": {\n    \"gc_size\": {\n      \"type\": \"keyword\",\n      \"script\": \"\"\"\n        Map gc=dissect('[%{@timestamp}][%{code}][%{desc}]  %{ident} used %{usize}, capacity %{csize}, committed %{comsize}, reserved %{rsize}').extract(doc[\"gc.keyword\"].value);\n        if (gc != null) emit(\"used\" + ' ' + gc.usize + ', ' + \"capacity\" + ' ' + gc.csize + ', ' + \"committed\" + ' ' + gc.comsize);\n      \"\"\"\n    }\n  },\n  \"size\": 1, \n  \"aggs\": {\n    \"sizes\": {\n      \"terms\": {\n        \"field\": \"gc_size\",\n        \"size\": 10\n      }\n    }\n  }, \n  \"fields\" : [\"gc_size\"]\n}\n----\n// TEST[continued]\n\nThe response includes the data from the `gc_size` field, formatted exactly as you\ndefined it in the dissect pattern!\n\n[source,console-result]\n----\n{\n  \"took\" : 2,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 6,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"my-index\",\n        \"_id\" : \"GXx3H3kBKGE42WRNlddJ\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"gc\" : \"[2021-04-27T16:16:34.699+0000][82460][gc,heap,exit]   class space    used 266K, capacity 384K, committed 384K, reserved 1048576K\"\n        },\n        \"fields\" : {\n          \"gc_size\" : [\n            \"used 266K, capacity 384K, committed 384K\"\n          ]\n        }\n      }\n    ]\n  },\n  \"aggregations\" : {\n    \"sizes\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 0,\n      \"buckets\" : [\n        {\n          \"key\" : \"used 107719K, capacity 111775K, committed 112724K\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : \"used 115409K, capacity 119541K, committed 120248K\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : \"used 14503K, capacity 15894K, committed 15948K\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : \"used 15255K, capacity 16726K, committed 16844K\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : \"used 266K, capacity 367K, committed 384K\",\n          \"doc_count\" : 1\n        },\n        {\n          \"key\" : \"used 266K, capacity 384K, committed 384K\",\n          \"doc_count\" : 1\n        }\n      ]\n    }\n  }\n}\n----\n// TESTRESPONSE[s/\"took\" : 2/\"took\": \"$body.took\"/]\n// TESTRESPONSE[s/\"_id\" : \"GXx3H3kBKGE42WRNlddJ\"/\"_id\": $body.hits.hits.0._id/]\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T02:49:25.456066",
        "size": 21098,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/inference-processor.html",
        "type": "documentation",
        "role": [
            "xpack"
        ],
        "has_code": true,
        "title": "inference-processor",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[inference-processor]]\n=== {infer-cap} processor\n++++\n<titleabbrev>{infer-cap}</titleabbrev>\n++++\n\n\nUses a pre-trained {dfanalytics} model or a model deployed for natural\nlanguage processing tasks to infer against the data that is being\ningested in the pipeline.\n\n\n[[inference-options]]\n.{infer-cap} Options\n[options=\"header\"]\n|======\n| Name                                  | Required  | Default                                    | Description\n| `model_id` .                          | yes       | -                                          | (String) An inference ID, a model deployment ID, a trained model ID or an alias.\n| `input_output`                        | no        | -                                          | (List) Input fields for {infer} and output (destination) fields for the {infer} results. This option is incompatible with the `target_field` and `field_map` options.\n| `target_field`                        | no        | `ml.inference.<processor_tag>`             | (String) Field added to incoming documents to contain results objects.\n| `field_map`                           | no        | If defined the model's default field map   | (Object) Maps the document field names to the known field names of the model. This mapping takes precedence over any default mappings provided in the model configuration.\n| `inference_config`                    | no        | The default settings defined in the model  | (Object) Contains the inference type and its options.\n| `ignore_missing`                      | no        | `false`                                    | (Boolean) If `true` and any of the input fields defined in `input_ouput` are missing then those missing fields are quietly ignored, otherwise a missing field causes a failure. Only applies when using `input_output` configurations to explicitly list the input fields.\ninclude::common-options.asciidoc[]\n|======\n\n[IMPORTANT]\n==================================================\n* You cannot use the `input_output` field with the `target_field` and \n`field_map` fields. For NLP models, use the `input_output` option. For \n{dfanalytics} models, use the `target_field` and `field_map` option.\n* Each {infer} input field must be single strings, not arrays of strings.\n* The `input_field` is processed as is and ignores any <<mapping,index mapping>>'s <<analysis,analyzers>> at time of {infer} run.\n==================================================\n\n[discrete]\n[[inference-input-output-example]]\n==== Configuring input and output fields\n\nSelect the `content` field for inference and write the result to \n`content_embedding`.\n\nIMPORTANT: If the specified `output_field` already exists in the ingest document, it won't be overwritten.\nThe {infer} results will be appended to the existing fields within `output_field`, which could lead to duplicate fields and potential errors.\nTo avoid this, use an unique `output_field` field name that does not clash with any existing fields.\n\n\n[source,js]\n--------------------------------------------------\n{\n  \"inference\": {\n    \"model_id\": \"model_deployment_for_inference\",\n    \"input_output\": [\n        {\n            \"input_field\": \"content\",\n            \"output_field\": \"content_embedding\"\n        }\n    ]\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\n==== Configuring multiple inputs\n\nThe `content` and `title` fields will be read from the incoming document and \nsent to the model for the inference. The inference output is written to \n`content_embedding` and `title_embedding` respectively.\n\n[source,js]\n--------------------------------------------------\n{\n  \"inference\": {\n    \"model_id\": \"model_deployment_for_inference\",\n    \"input_output\": [\n        {\n            \"input_field\": \"content\",\n            \"output_field\": \"content_embedding\"\n        },\n        {\n            \"input_field\": \"title\",\n            \"output_field\": \"title_embedding\"\n        }\n    ]\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nSelecting the input fields with `input_output` is incompatible with\nthe `target_field` and `field_map` options.\n\n{dfanalytics-cap} models must use the `target_field` to specify the root \nlocation results are written to and optionally a `field_map` to map field names \nin the input document to the model input fields.\n\n[source,js]\n--------------------------------------------------\n{\n  \"inference\": {\n    \"model_id\": \"model_deployment_for_inference\",\n    \"target_field\": \"FlightDelayMin_prediction_infer\",\n    \"field_map\": {\n      \"your_field\": \"my_field\"\n    },\n    \"inference_config\": { \"regression\": {} }\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\n\n[discrete]\n[[inference-processor-classification-opt]]\n==== {classification-cap} configuration options\n\nClassification configuration for inference.\n\n`num_top_classes`::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-classes]\n\n`num_top_feature_importance_values`::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-feature-importance-values]\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n`top_classes_results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-top-classes-results-field]\n\n`prediction_field_type`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-prediction-field-type]\n\n[discrete]\n[[inference-processor-fill-mask-opt]]\n==== Fill mask configuration options\n\n`num_top_classes`::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-classes]\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n`tokenization`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n=====\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n=====\n\n[discrete]\n[[inference-processor-ner-opt]]\n==== NER configuration options\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n`tokenization`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n=====\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n=====\n\n[discrete]\n[[inference-processor-regression-opt]]\n==== {regression-cap} configuration options\n\nRegression configuration for inference.\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n`num_top_feature_importance_values`::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-regression-num-top-feature-importance-values]\n\n[discrete]\n[[inference-processor-text-classification-opt]]\n==== Text classification configuration options\n\n`classification_labels`::\n(Optional, string) An array of classification labels.\n\n`num_top_classes`::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-classes]\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n`tokenization`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n=====\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n\n\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n=====\n\n[discrete]\n[[inference-processor-text-embedding-opt]]\n==== Text embedding configuration options\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n`tokenization`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n=====\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n=====\n\n\n[discrete]\n[[inference-processor-text-expansion-opt]]\n==== Text expansion configuration options\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n\n`tokenization`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n=====\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n=====\n\n[discrete]\n[[inference-processor-text-similarity-opt]]\n==== Text similarity configuration options\n\n`text_similarity`:::\n(Object, optional)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-similarity]\n+\n.Properties of text_similarity inference\n[%collapsible%open]\n=====\n`span_score_combination_function`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-similarity-span-score-func]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRefer to <<tokenization-properties>> to review the properties of the\n`tokenization` object.\n=====\n\n\n[discrete]\n[[inference-processor-zero-shot-opt]]\n==== Zero shot classification configuration options\n\n`labels`::\n(Optional, array)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-labels]\n\n`multi_label`::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-multi-label]\n\n`results_field`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field-processor]\n\n`tokenization`::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n=====\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n=====\n\n[discrete]\n[[inference-processor-config-example]]\n==== {infer-cap} processor examples\n\n[source,js]\n--------------------------------------------------\n\"inference\":{\n  \"model_id\": \"my_model_id\",\n  \"field_map\": {\n    \"original_fieldname\": \"expected_fieldname\"\n  },\n  \"inference_config\": {\n    \"regression\": {\n      \"results_field\": \"my_regression\"\n    }\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nThis configuration specifies a `regression` inference and the results are\nwritten to the `my_regression` field contained in the `target_field` results\nobject. The `field_map` configuration maps the field `original_fieldname` from\nthe source document to the field expected by the model.\n\n\n[source,js]\n--------------------------------------------------\n\"inference\":{\n  \"model_id\":\"my_model_id\"\n  \"inference_config\": {\n    \"classification\": {\n      \"num_top_classes\": 2,\n      \"results_field\": \"prediction\",\n      \"top_classes_results_field\": \"probabilities\"\n    }\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nThis configuration specifies a `classification` inference. The number of\ncategories for which the predicted probabilities are reported is 2\n(`num_top_classes`). The result is written to the `prediction` field and the top\nclasses to the `probabilities` field. Both fields are contained in the\n`target_field` results object.\n\nFor an example that uses {nlp} trained models, refer to\n{ml-docs}/ml-nlp-inference.html[Add NLP inference to ingest pipelines].\n\n[discrete]\n[[inference-processor-feature-importance]]\n==== {feat-imp-cap} object mapping\n\nTo get the full benefit of aggregating and searching for\n{ml-docs}/ml-feature-importance.html[{feat-imp}], update your index mapping of\nthe {feat-imp} result field as you can see below:\n\n[source,js]\n--------------------------------------------------\n\"ml.inference.feature_importance\": {\n  \"type\": \"nested\",\n  \"dynamic\": true,\n  \"properties\": {\n    \"feature_name\": {\n      \"type\": \"keyword\"\n    },\n    \"importance\": {\n      \"type\": \"double\"\n    }\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nThe mapping field name for {feat-imp} (in the example above, it is\n`ml.inference.feature_importance`) is compounded as follows:\n\n`<ml.inference.target_field>`.`<inference.tag>`.`feature_importance`\n\n* `<ml.inference.target_field>`: defaults to `ml.inference`.\n* `<inference.tag>`: if is not provided in the processor definition, then it is\nnot part of the field path.\n\nFor example, if you provide a tag `foo` in the definition as you can see below:\n\n[source,js]\n--------------------------------------------------\n{\n  \"tag\": \"foo\",\n  ...\n}\n--------------------------------------------------\n// NOTCONSOLE\n\n\nThen, the {feat-imp} value is written to the\n`ml.inference.foo.feature_importance` field.\n\nYou can also specify the target field as follows:\n\n[source,js]\n--------------------------------------------------\n{\n  \"tag\": \"foo\",\n  \"target_field\": \"my_field\"\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nIn this case, {feat-imp} is exposed in the\n`my_field.foo.feature_importance` field.\n"
}
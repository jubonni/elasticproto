{
    "meta": {
        "size": 33207,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-trained-model.html",
        "type": "documentation",
        "role": [
            "xpack"
        ],
        "has_code": true,
        "title": "infer-trained-model",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[infer-trained-model]]\n= Infer trained model API\n[subs=\"attributes\"]\n++++\n<titleabbrev>Infer trained model</titleabbrev>\n++++\n\nEvaluates a trained model. The model may be any supervised model either trained\nby {dfanalytics} or imported.\n\nNOTE: For model deployments with caching enabled, results may be returned\ndirectly from the {infer} cache.\n\n[[infer-trained-model-request]]\n== {api-request-title}\n\n`POST _ml/trained_models/<model_id>/_infer`\n`POST _ml/trained_models/<deployment_id>/_infer`\n\n////\n[[infer-trained-model-prereq]]\n== {api-prereq-title}\n\n////\n////\n[[infer-trained-model-desc]]\n== {api-description-title}\n\n////\n\n[[infer-trained-model-path-params]]\n== {api-path-parms-title}\n\n`<model_id>`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=model-id-or-alias]\nIf you specify the `model_id` in the API call, and the model has multiple \ndeployments, a random deployment will be used. If the `model_id` matches the ID \nof one of the deployments, that deployment will be used.\n\n`<deployment_id>`::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=deployment-id]\n\n[[infer-trained-model-query-params]]\n== {api-query-parms-title}\n\n`timeout`::\n(Optional, time)\nControls the amount of time to wait for {infer} results. Defaults to 10 seconds.\n\n[[infer-trained-model-request-body]]\n== {api-request-body-title}\n\n`docs`::\n(Required, array)\nAn array of objects to pass to the model for inference. The objects should\ncontain the fields matching your configured trained model input. Typically for\nNLP models, the field name is `text_field`. Each {infer} input field specified \nin this property must be single strings not arrays of strings.\n\n//Begin inference_config\n`inference_config`::\n(Optional, object)\nThe default configuration for inference. This can be: `regression`,\n`classification`, `fill_mask`, `ner`, `question_answering`,\n`text_classification`, `text_embedding` or `zero_shot_classification`.\nIf `regression` or `classification`, it must match the `target_type` of the\nunderlying `definition.trained_model`. If `fill_mask`, `ner`,\n`question_answering`, `text_classification`, or `text_embedding`; the\n`model_type` must be `pytorch`. If not specified, the `inference_config`\nfrom when the model was created is used.\n+\n.Properties of `inference_config`\n[%collapsible%open]\n====\n`classification`:::\n(Optional, object)\nClassification configuration for inference.\n+\n.Properties of classification inference\n[%collapsible%open]\n=====\n`num_top_classes`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-classes]\n\n`num_top_feature_importance_values`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-num-top-feature-importance-values]\n\n`prediction_field_type`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-prediction-field-type]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`top_classes_results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-classification-top-classes-results-field]\n=====\n\n`fill_mask`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-fill-mask]\n+\n.Properties of fill_mask inference\n[%collapsible%open]\n=====\n`num_top_classes`::::\n(Optional, integer)\nNumber of top predicted tokens to return for replacing the mask token. Defaults\nto `0`.\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n======\n=====\n\n`ner`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-ner]\n+\n.Properties of ner inference\n[%collapsible%open]\n=====\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n======\n=====\n\n`pass_through`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-pass-through]\n+\n.Properties of pass_through inference\n[%collapsible%open]\n=====\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n======\n=====\n\n`question_answering`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-question-answering]\n+\n.Properties of question_answering inference\n[%collapsible%open]\n=====\n`max_answer_length`::::\n(Optional, integer)\nThe maximum amount of words in the answer. Defaults to `15`.\n\n`num_top_classes`::::\n(Optional, integer)\nThe number the top found answers to return. Defaults to `0`, meaning only the\nbest found answer is returned.\n\n`question`::::\n(Required, string)\nThe question to use when extracting an answer\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\nRecommended to set `max_sequence_length` to `386` with `128` of `span` and set\n`truncate` to `none`.\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n======\n=====\n\n`regression`:::\n(Optional, object)\nRegression configuration for inference.\n+\n.Properties of regression inference\n[%collapsible%open]\n=====\n`num_top_feature_importance_values`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-regression-num-top-feature-importance-values]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n=====\n\n`text_classification`:::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-classification]\n+\n.Properties of text_classification inference\n[%collapsible%open]\n=====\n`classification_labels`::::\n(Optional, string) An array of classification labels.\n\n`num_top_classes`::::\n(Optional, integer)\nSpecifies the number of top class predictions to return. Defaults to all classes\n(-1).\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n======\n=====\n`text_embedding`:::\n(Object, optional)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-embedding]\n+\n.Properties of text_embedding inference\n[%collapsible%open]\n=====\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n======\n=====\n`text_similarity`:::\n(Object, optional)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-similarity]\n+\n.Properties of text_similarity inference\n[%collapsible%open]\n=====\n`span_score_combination_function`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-similarity-span-score-func]\n\n`text`::::\n(Required, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-text-similarity-text]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`with_special_tokens`::::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-with-special-tokens]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`with_special_tokens`::::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-with-special-tokens]\n=======\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`span`::::\n(Optional, integer)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-span]\n\n`with_special_tokens`::::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja-with-special-tokens]\n=======\n======\n=====\n`zero_shot_classification`:::\n(Object, optional)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification]\n+\n.Properties of zero_shot_classification inference\n[%collapsible%open]\n=====\n`labels`::::\n(Optional, array)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-labels]\n\n`multi_label`::::\n(Optional, boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-zero-shot-classification-multi-label]\n\n`results_field`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-results-field]\n\n`tokenization`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization]\n+\n.Properties of tokenization\n[%collapsible%open]\n======\n`bert`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert]\n+\n.Properties of bert\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`deberta_v2`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-deberta-v2]\n+\n.Properties of deberta_v2\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate-deberta-v2]\n=======\n`roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-roberta]\n+\n.Properties of roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`mpnet`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-mpnet]\n+\n.Properties of mpnet\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`xlm_roberta`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-xlm-roberta]\n+\n.Properties of xlm_roberta\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n`bert_ja`::::\n(Optional, object)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-bert-ja]\n+\n.Properties of bert_ja\n[%collapsible%open]\n=======\n`truncate`::::\n(Optional, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=inference-config-nlp-tokenization-truncate]\n=======\n======\n=====\n====\n//End of inference_config\n\n////\n[[infer-trained-model-results]]\n== {api-response-body-title}\n////\n////\n[[ml-get-trained-models-response-codes]]\n== {api-response-codes-title}\n\n////\n\n[[infer-trained-model-example]]\n== {api-examples-title}\n\nThe response depends on the kind of model.\n\nFor example, for {lang-ident} the response is the predicted language and the\nscore:\n\n[source,console]\n--------------------------------------------------\nPOST _ml/trained_models/lang_ident_model_1/_infer\n{\n  \"docs\":[{\"text\": \"The fool doth think he is wise, but the wise man knows himself to be a fool.\"}]\n}\n--------------------------------------------------\n// TEST[skip:TBD]\n\nHere are the results predicting english with a high probability.\n\n[source,console-result]\n----\n{\n  \"inference_results\": [\n    {\n      \"predicted_value\": \"en\",\n      \"prediction_probability\": 0.9999658805366392,\n      \"prediction_score\": 0.9999658805366392\n    }\n  ]\n}\n----\n// NOTCONSOLE\n\n\nWhen it is a text classification model, the response is the score and predicted\nclassification.\n\nFor example:\n\n[source,console]\n--------------------------------------------------\nPOST _ml/trained_models/model2/_infer\n{\n\t\"docs\": [{\"text_field\": \"The movie was awesome!!\"}]\n}\n--------------------------------------------------\n// TEST[skip:TBD]\n\nThe API returns the predicted label and the confidence.\n\n[source,console-result]\n----\n{\n  \"inference_results\": [{\n    \"predicted_value\" : \"POSITIVE\",\n    \"prediction_probability\" : 0.9998667964092964\n  }]\n}\n----\n// NOTCONSOLE\n\nFor named entity recognition (NER) models, the response contains the annotated\ntext output and the recognized entities.\n\n[source,console]\n--------------------------------------------------\nPOST _ml/trained_models/model2/_infer\n{\n\t\"docs\": [{\"text_field\": \"Hi my name is Josh and I live in Berlin\"}]\n}\n--------------------------------------------------\n// TEST[skip:TBD]\n\nThe API returns in this case:\n\n[source,console-result]\n----\n{\n  \"inference_results\": [{\n    \"predicted_value\" : \"Hi my name is [Josh](PER&Josh) and I live in [Berlin](LOC&Berlin)\",\n    \"entities\" : [\n      {\n        \"entity\" : \"Josh\",\n        \"class_name\" : \"PER\",\n        \"class_probability\" : 0.9977303419824,\n        \"start_pos\" : 14,\n        \"end_pos\" : 18\n      },\n      {\n        \"entity\" : \"Berlin\",\n        \"class_name\" : \"LOC\",\n        \"class_probability\" : 0.9992474323902818,\n        \"start_pos\" : 33,\n        \"end_pos\" : 39\n      }\n    ]\n  }]\n}\n----\n// NOTCONSOLE\n\nZero-shot classification models require extra configuration defining the class\nlabels. These labels are passed in the zero-shot inference config.\n\n[source,console]\n--------------------------------------------------\nPOST _ml/trained_models/model2/_infer\n{\n  \"docs\": [\n    {\n      \"text_field\": \"This is a very happy person\"\n    }\n  ],\n  \"inference_config\": {\n    \"zero_shot_classification\": {\n      \"labels\": [\n        \"glad\",\n        \"sad\",\n        \"bad\",\n        \"rad\"\n      ],\n      \"multi_label\": false\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip:TBD]\n\nThe API returns the predicted label and the confidence, as well as the top\nclasses:\n\n[source,console-result]\n----\n{\n  \"inference_results\": [{\n    \"predicted_value\" : \"glad\",\n    \"top_classes\" : [\n      {\n        \"class_name\" : \"glad\",\n        \"class_probability\" : 0.8061155063386439,\n        \"class_score\" : 0.8061155063386439\n      },\n      {\n        \"class_name\" : \"rad\",\n        \"class_probability\" : 0.18218006158387956,\n        \"class_score\" : 0.18218006158387956\n      },\n      {\n        \"class_name\" : \"bad\",\n        \"class_probability\" : 0.006325615787634201,\n        \"class_score\" : 0.006325615787634201\n      },\n      {\n        \"class_name\" : \"sad\",\n        \"class_probability\" : 0.0053788162898424545,\n        \"class_score\" : 0.0053788162898424545\n      }\n    ],\n    \"prediction_probability\" : 0.8061155063386439\n  }]\n}\n----\n// NOTCONSOLE\n\nQuestion answering models require extra configuration defining the question to\nanswer.\n\n[source,console]\n--------------------------------------------------\nPOST _ml/trained_models/model2/_infer\n{\n  \"docs\": [\n    {\n      \"text_field\": \"<long text to extract answer>\"\n    }\n  ],\n  \"inference_config\": {\n    \"question_answering\": {\n      \"question\": \"<question to be answered>\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip:TBD]\n\nThe API returns a response similar to the following:\n\n[source,console-result]\n----\n{\n    \"predicted_value\": <string subsection of the text that is the answer>,\n    \"start_offset\": <character offset in document to start>,\n    \"end_offset\": <character offset end of the answer,\n    \"prediction_probability\": <prediction score>\n}\n----\n// NOTCONSOLE\n\nText similarity models require at least two sequences of text to compare. It's\npossible to provide multiple strings of text to compare to another text\nsequence:\n\n[source,console]\n--------------------------------------------------\nPOST _ml/trained_models/cross-encoder__ms-marco-tinybert-l-2-v2/_infer\n{\n  \"docs\":[{ \"text_field\": \"Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\"}, {\"text_field\": \"New York City is famous for the Metropolitan Museum of Art.\"}],\n  \"inference_config\": {\n    \"text_similarity\": {\n      \"text\": \"How many people live in Berlin?\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip:TBD]\n\nThe response contains the prediction for every string that is compared to the\ntext provided in the `text_similarity`.`text` field:\n\n[source,console-result]\n----\n{\n  \"inference_results\": [\n    {\n      \"predicted_value\": 7.235751628875732\n    },\n    {\n      \"predicted_value\": -11.562295913696289\n    }\n  ]\n}\n----\n// NOTCONSOLE\n\n\nThe tokenization truncate option can be overridden when calling the API:\n\n[source,console]\n--------------------------------------------------\nPOST _ml/trained_models/model2/_infer\n{\n  \"docs\": [{\"text_field\": \"The Amazon rainforest covers most of the Amazon basin in South America\"}],\n  \"inference_config\": {\n    \"ner\": {\n      \"tokenization\": {\n        \"bert\": {\n          \"truncate\": \"first\"\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip:TBD]\n\nWhen the input has been truncated due to the limit imposed by the model's\n`max_sequence_length` the `is_truncated` field appears in the response.\n\n[source,console-result]\n----\n{\n  \"inference_results\": [{\n    \"predicted_value\" : \"The [Amazon](LOC&Amazon) rainforest covers most of the [Amazon](LOC&Amazon) basin in [South America](LOC&South+America)\",\n    \"entities\" : [\n      {\n        \"entity\" : \"Amazon\",\n        \"class_name\" : \"LOC\",\n        \"class_probability\" : 0.9505460915724254,\n        \"start_pos\" : 4,\n        \"end_pos\" : 10\n      },\n      {\n        \"entity\" : \"Amazon\",\n        \"class_name\" : \"LOC\",\n        \"class_probability\" : 0.9969992804311777,\n        \"start_pos\" : 41,\n        \"end_pos\" : 47\n      }\n    ],\n    \"is_truncated\" : true\n  }]\n}\n----\n// NOTCONSOLE\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T02:49:24.668065",
        "size": 8230,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/es-monitoring-collectors.html",
        "type": "documentation",
        "role": [
            "xpack"
        ],
        "has_code": false,
        "title": "es-monitoring-collectors",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[es-monitoring-collectors]]\n== Collectors\n\ninclude::production.asciidoc[tag=monitoring-rec]\n\nCollectors, as their name implies, collect things. Each collector runs once for\neach collection interval to obtain data from the public APIs in {es} and {xpack}\nthat it chooses to monitor. When the data collection is finished, the data is\nhanded in bulk to the <<es-monitoring-exporters,exporters>> to be sent to the\nmonitoring clusters. Regardless of the number of exporters, each collector only\nruns once per collection interval.\n\nThere is only one collector per data type gathered. In other words, for any\nmonitoring document that is created, it comes from a single collector rather\nthan being merged from multiple collectors. The {es} {monitor-features}\ncurrently have a few collectors because the goal is to minimize overlap between\nthem for optimal performance.\n\nEach collector can create zero or more monitoring documents. For example,\nthe `index_stats` collector collects all index statistics at the same time to\navoid many unnecessary calls.\n\n[options=\"header\"]\n|=======================\n| Collector       | Data Types | Description\n| Cluster Stats   | `cluster_stats`\n| Gathers details about the cluster state, including parts of the actual cluster\nstate (for example `GET /_cluster/state`) and statistics about it (for example,\n`GET /_cluster/stats`). This produces a single document type. In versions prior\nto X-Pack 5.5, this was actually three separate collectors that resulted in\nthree separate types: `cluster_stats`, `cluster_state`, and `cluster_info`. In\n5.5 and later, all three are combined into `cluster_stats`. This only runs on\nthe _elected_ master node and the data collected (`cluster_stats`) largely\ncontrols the UI. When this data is not present, it indicates either a\nmisconfiguration on the elected master node, timeouts related to the collection\nof the data, or issues with storing the data. Only a single document is produced\nper collection.\n| Index Stats     | `indices_stats`, `index_stats`\n| Gathers details about the indices in the cluster, both in summary and\nindividually. This creates many documents that represent parts of the index\nstatistics output (for example, `GET /_stats`). This information only needs to\nbe collected once, so it is collected on the _elected_ master node. The most\ncommon failure for this collector relates to an extreme number of indices -- and\ntherefore time to gather them -- resulting in timeouts. One summary\n`indices_stats` document is produced per collection and one `index_stats`\ndocument is produced per index, per collection.\n| Index Recovery  | `index_recovery`\n| Gathers details about index recovery in the cluster. Index recovery represents\nthe assignment of _shards_ at the cluster level. If an index is not recovered,\nit is not usable. This also corresponds to shard restoration via snapshots. This\ninformation only needs to be collected once, so it is collected on the _elected_\nmaster node. The most common failure for this collector relates to an extreme\nnumber of shards -- and therefore time to gather them -- resulting in timeouts.\nThis creates a single document that contains all recoveries by default, which\ncan be quite large, but it gives the most accurate picture of recovery in the\nproduction cluster.\n| Shards          | `shards`\n| Gathers details about all _allocated_ shards for all indices, particularly\nincluding what node the shard is allocated to. This information only needs to be\ncollected once, so it is collected on the _elected_ master node. The collector\nuses the local cluster state to get the routing table without any network\ntimeout issues unlike most other collectors. Each shard is represented by a\nseparate monitoring document.\n| Jobs            | `job_stats`\n| Gathers details about all machine learning job statistics (for example, `GET\n/_ml/anomaly_detectors/_stats`). This information only needs to be collected\nonce, so it is collected on the _elected_ master node. However, for the master\nnode to be able to perform the collection, the master node must have\n`xpack.ml.enabled` set to true (default) and a license level that supports {ml}.\n| Node Stats      | `node_stats`\n| Gathers details about the running node, such as memory utilization and CPU\nusage (for example, `GET /_nodes/_local/stats`). This runs on _every_ node with\n{monitor-features} enabled. One common failure results in the timeout of the node\nstats request due to too many segment files. As a result, the collector spends\ntoo much time waiting for the file system stats to be calculated until it\nfinally times out. A single `node_stats` document is created per collection.\nThis is collected per node to help to discover issues with nodes communicating\nwith each other, but not with the monitoring cluster (for example, intermittent\nnetwork issues or memory pressure).\n|=======================\n\nThe {es} {monitor-features} use a single threaded scheduler to run the\ncollection of {es} monitoring data by all of the appropriate collectors on each\nnode. This scheduler is managed locally by each node and its interval is\ncontrolled by specifying the `xpack.monitoring.collection.interval`, which\ndefaults to 10 seconds (`10s`), at either the node or cluster level.\n\nFundamentally, each collector works on the same principle. Per collection\ninterval, each collector is checked to see whether it should run and then the\nappropriate collectors run. The failure of an individual collector does not\nimpact any other collector.\n\nOnce collection has completed, all of the monitoring data is passed to the\nexporters to route the monitoring data to the monitoring clusters.\n\nIf gaps exist in the monitoring charts in {kib}, it is typically because either\na collector failed or the monitoring cluster did not receive the data (for\nexample, it was being restarted). In the event that a collector fails, a logged\nerror should exist on the node that attempted to perform the collection.\n\nNOTE: Collection is currently done serially, rather than in parallel, to avoid\n      extra overhead on the elected master node. The downside to this approach\n      is that collectors might observe a different version of the cluster state\n      within the same collection period. In practice, this does not make a\n      significant difference and running the collectors in parallel would not\n      prevent such a possibility.\n\nFor more information about the configuration options for the collectors, see\n<<monitoring-collection-settings>>.\n\n[discrete]\n[[es-monitoring-stack]]\n==== Collecting data from across the Elastic Stack\n\n{es} {monitor-features} also receive monitoring data from other parts of the\nElastic Stack. In this way, it serves as an unscheduled monitoring data\ncollector for the stack.\n\nBy default, data collection is disabled. {es} monitoring data is not\ncollected and all monitoring data from other sources such as {kib}, Beats, and\nLogstash is ignored. You must set `xpack.monitoring.collection.enabled` to `true`\nto enable the collection of monitoring data. See <<monitoring-settings>>.\n\nOnce data is received, it is forwarded to the exporters\nto be routed to the monitoring cluster like all monitoring data.\n\nWARNING: Because this stack-level \"collector\" lives outside of the collection\ninterval of {es} {monitor-features}, it is not impacted by the\n`xpack.monitoring.collection.interval` setting. Therefore, data is passed to the\nexporters whenever it is received. This behavior can result in indices for {kib},\nLogstash, or Beats being created somewhat unexpectedly.\n\nWhile the monitoring data is collected and processed, some production cluster\nmetadata is added to incoming documents. This metadata enables {kib} to link the\nmonitoring data to the appropriate cluster. If this linkage is unimportant to\nthe infrastructure that you're monitoring, it might be simpler to configure\nLogstash and Beats to report monitoring data directly to the monitoring cluster.\nThis scenario also prevents the production cluster from adding extra overhead\nrelated to monitoring data, which can be very useful when there are a large\nnumber of Logstash nodes or Beats.\n\nFor more information about typical monitoring architectures, see\n<<how-monitoring-works>>.\n"
}
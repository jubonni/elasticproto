{
    "meta": {
        "timestamp": "2024-11-01T02:49:24.990081",
        "size": 4771,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-elision-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-elision-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-elision-tokenfilter]]\n=== Elision token filter\n++++\n<titleabbrev>Elision</titleabbrev>\n++++\n\nRemoves specified {wikipedia}/Elision[elisions] from\nthe beginning of tokens. For example, you can use this filter to change\n`l'avion` to `avion`.\n\nWhen not customized, the filter removes the following French elisions by default:\n\n`l'`, `m'`, `t'`, `qu'`, `n'`, `s'`, `j'`, `d'`, `c'`, `jusqu'`, `quoiqu'`,\n`lorsqu'`, `puisqu'`\n\nCustomized versions of this filter are included in several of {es}'s built-in\n<<analysis-lang-analyzer,language analyzers>>:\n\n* <<catalan-analyzer, Catalan analyzer>>\n* <<french-analyzer, French analyzer>>\n* <<irish-analyzer, Irish analyzer>>\n* <<italian-analyzer, Italian analyzer>>\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/util/ElisionFilter.html[ElisionFilter].\n\n[[analysis-elision-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the `elision`\nfilter to remove `j'` from `j\u2019examine pr\u00e8s du wharf`:\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"elision\"],\n  \"text\" : \"j\u2019examine pr\u00e8s du wharf\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ examine, pr\u00e8s, du, wharf ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"examine\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 9,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"pr\u00e8s\",\n      \"start_offset\" : 10,\n      \"end_offset\" : 14,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"du\",\n      \"start_offset\" : 15,\n      \"end_offset\" : 17,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"wharf\",\n      \"start_offset\" : 18,\n      \"end_offset\" : 23,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 3\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-elision-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`elision` filter to configure a new \n<<analysis-custom-analyzer,custom analyzer>>.\n\n[source,console]\n--------------------------------------------------\nPUT /elision_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_elision\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"elision\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-elision-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n[[analysis-elision-tokenfilter-articles]]\n`articles`::\n+\n--\n(Required+++*+++, array of string)\nList of elisions to remove.\n\nTo be removed, the elision must be at the beginning of a token and be\nimmediately followed by an apostrophe. Both the elision and apostrophe are\nremoved.\n\nFor custom `elision` filters, either this parameter or `articles_path` must be\nspecified.\n--\n\n`articles_path`::\n+\n--\n(Required+++*+++, string)\nPath to a file that contains a list of elisions to remove.\n\nThis path must be absolute or relative to the `config` location, and the file\nmust be UTF-8 encoded. Each elision in the file must be separated by a line\nbreak.\n\nTo be removed, the elision must be at the beginning of a token and be\nimmediately followed by an apostrophe. Both the elision and apostrophe are\nremoved.\n\nFor custom `elision` filters, either this parameter or `articles` must be\nspecified.\n--\n\n`articles_case`::\n(Optional, Boolean)\nIf `true`, elision matching is case insensitive. If `false`, elision matching is\ncase sensitive. Defaults to `false`.\n\n[[analysis-elision-tokenfilter-customize]]\n==== Customize\n\nTo customize the `elision` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following request creates a custom case-insensitive `elision`\nfilter that removes the `l'`, `m'`, `t'`, `qu'`, `n'`, `s'`,\nand `j'` elisions:\n\n[source,console]\n--------------------------------------------------\nPUT /elision_case_insensitive_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"elision_case_insensitive\" ]\n        }\n      },\n      \"filter\": {\n        \"elision_case_insensitive\": {\n          \"type\": \"elision\",\n          \"articles\": [ \"l\", \"m\", \"t\", \"qu\", \"n\", \"s\", \"j\" ],\n          \"articles_case\": true\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
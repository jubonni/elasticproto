{
    "meta": {
        "timestamp": "2024-11-01T03:07:09.063280",
        "size": 21637,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete-by-query.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "docs-delete-by-query",
        "version": "8.15"
    },
    "doc": "[[docs-delete-by-query]]\n=== Delete by query API\n++++\n<titleabbrev>Delete by query</titleabbrev>\n++++\n\nDeletes documents that match the specified query.\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001/_delete_by_query\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"elkbee\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index_big]\n\n////\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"took\" : 147,\n  \"timed_out\": false,\n  \"deleted\": 119,\n  \"batches\": 1,\n  \"version_conflicts\": 0,\n  \"noops\": 0,\n  \"retries\": {\n    \"bulk\": 0,\n    \"search\": 0\n  },\n  \"throttled_millis\": 0,\n  \"requests_per_second\": -1.0,\n  \"throttled_until_millis\": 0,\n  \"total\": 119,\n  \"failures\" : [ ]\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"took\" : 147/\"took\" : \"$body.took\"/]\n////\n\n[[docs-delete-by-query-api-request]]\n==== {api-request-title}\n\n`POST /<target>/_delete_by_query`\n\n[[docs-delete-by-query-api-prereqs]]\n==== {api-prereq-title}\n\n* If the {es} {security-features} are enabled, you must have the following\n<<privileges-list-indices,index privileges>> for the target data stream, index,\nor alias:\n\n** `read`\n** `delete` or `write`\n\n[[docs-delete-by-query-api-desc]]\n==== {api-description-title}\n\nYou can specify the query criteria in the request URI or the request body\nusing the same syntax as the  <<search-search,Search API>>.\n\nWhen you submit a delete by query request, {es} gets a snapshot of the data stream or index\nwhen it begins processing the request and deletes matching documents using\n`internal` versioning. If a document changes between the time that the\nsnapshot is taken and the delete operation is processed, it results in a version\nconflict and the delete operation fails.\n\nNOTE: Documents with a version equal to 0 cannot be deleted using delete by\nquery because `internal` versioning does not support 0 as a valid\nversion number.\n\nWhile processing a delete by query request, {es} performs multiple search\nrequests sequentially to find all of the matching documents to delete. A bulk\ndelete request is performed for each batch of matching documents. If a\nsearch or bulk request is rejected, the requests are retried up to 10 times, with\nexponential back off. If the maximum retry limit is reached, processing halts\nand all failed requests are returned in the response. Any delete requests that\ncompleted successfully still stick, they are not rolled back.\n\nYou can opt to count version conflicts instead of halting and returning by\nsetting `conflicts` to `proceed`. Note that if you opt to count version conflicts\nthe operation could attempt to delete more documents from the source\nthan `max_docs` until it has successfully deleted `max_docs` documents, or it has gone through\nevery document in the source query.\n\n===== Refreshing shards\n\nSpecifying the `refresh` parameter refreshes all shards involved in the delete\nby query once the request completes. This is different than the delete API's\n`refresh` parameter, which causes just the shard that received the delete\nrequest to be refreshed. Unlike the delete API, it does not support\n`wait_for`.\n\n[[docs-delete-by-query-task-api]]\n===== Running delete by query asynchronously\n\nIf the request contains `wait_for_completion=false`, {es}\nperforms some preflight checks, launches the request, and returns a\n<<tasks,`task`>> you can use to cancel or get the status of the task. {es} creates a\nrecord of this task as a document at `.tasks/task/${taskId}`. When you are\ndone with a task, you should delete the task document so {es} can reclaim the\nspace.\n\n===== Waiting for active shards\n\n`wait_for_active_shards` controls how many copies of a shard must be active\nbefore proceeding with the request. See <<index-wait-for-active-shards>>\nfor details. `timeout` controls how long each write request waits for unavailable\nshards to become available. Both work exactly the way they work in the\n<<docs-bulk,Bulk API>>. Delete by query uses scrolled searches, so you can also\nspecify the `scroll` parameter to control how long it keeps the search context\nalive, for example `?scroll=10m`. The default is 5 minutes.\n\n[[docs-delete-by-query-throttle]]\n===== Throttling delete requests\n\nTo control the rate at which delete by query issues batches of delete operations,\nyou can set `requests_per_second` to any positive decimal number. This pads each\nbatch with a wait time to throttle the rate. Set `requests_per_second` to `-1`\nto disable throttling.\n\nThrottling uses a wait time between batches so that the internal scroll requests\ncan be given a timeout that takes the request padding into account. The padding\ntime is the difference between the batch size divided by the\n`requests_per_second` and the time spent writing. By default the batch size is\n`1000`, so if `requests_per_second` is set to `500`:\n\n[source,txt]\n--------------------------------------------------\ntarget_time = 1000 / 500 per second = 2 seconds\nwait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds\n--------------------------------------------------\n\nSince the batch is issued as a single `_bulk` request, large batch sizes\ncause {es} to create many requests and wait before starting the next set.\nThis is \"bursty\" instead of \"smooth\".\n\n[[docs-delete-by-query-slice]]\n===== Slicing\n\nDelete by query supports <<slice-scroll, sliced scroll>> to parallelize the\ndelete process. This can improve efficiency and provide a\nconvenient way to break the request down into smaller parts.\n\nSetting `slices` to `auto` chooses a reasonable number for most data streams and indices.\nIf you're slicing manually or otherwise tuning automatic slicing, keep in mind\nthat:\n\n* Query performance is most efficient when the number of `slices` is equal to\nthe number of shards in the index or backing index. If that number is large (for example,\n500), choose a lower number as too many `slices` hurts performance. Setting\n`slices` higher than the number of shards generally does not improve efficiency\nand adds overhead.\n\n* Delete performance scales linearly across available resources with the\nnumber of slices.\n\nWhether query or delete performance dominates the runtime depends on the\ndocuments being reindexed and cluster resources.\n\n[[docs-delete-by-query-api-path-params]]\n==== {api-path-parms-title}\n\n`<target>`::\n(Optional, string) Comma-separated list of data streams, indices, and aliases to\nsearch. Supports wildcards (`*`). To search all data streams or indices, omit\nthis parameter or use `* or `_all`.\n\n[[docs-delete-by-query-api-query-params]]\n==== {api-query-parms-title}\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=allow-no-indices]\n+\nDefaults to `true`.\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=analyzer]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=analyze_wildcard]\n\n`conflicts`::\n  (Optional, string) What to do if delete by query hits version conflicts:\n  `abort` or `proceed`. Defaults to `abort`.\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=default_operator]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=df]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=expand-wildcards]\n+\nDefaults to `open`.\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=index-ignore-unavailable]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=lenient]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=max_docs]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=preference]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=search-q]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=request_cache]\n\n`refresh`::\n(Optional, Boolean) If `true`, {es} refreshes all shards involved in the\ndelete by query after the request completes. Defaults to `false`.\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=requests_per_second]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=routing]\n\n`scroll`::\n(Optional, <<time-units,time value>>)\nPeriod to retain the <<scroll-search-context,search context>> for scrolling. See\n<<scroll-search-results>>.\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=scroll_size]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=search_type]\n\n`search_timeout`::\n(Optional, <<time-units, time units>>)\nExplicit timeout for each search request.\nDefaults to no timeout.\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=slices]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=sort]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=stats]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=terminate_after]\n\n`timeout`::\n(Optional, <<time-units, time units>>)\nPeriod each deletion request <<index-wait-for-active-shards,waits for active\nshards>>. Defaults to `1m` (one minute).\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=version]\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=wait_for_active_shards]\n\n[[docs-delete-by-query-api-request-body]]\n==== {api-request-body-title}\n\n`query`::\n  (Optional, <<query-dsl,query object>>) Specifies the documents to delete\n  using the  <<query-dsl,Query DSL>>.\n\n\n[[docs-delete-by-query-api-response-body]]\n==== Response body\n\n//////////////////////////\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001/_delete_by_query\n{\n  \"query\": { <1>\n    \"match\": {\n      \"user.id\": \"elkbee\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index_big]\n\n//////////////////////////\n\nThe JSON response looks like this:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"took\" : 147,\n  \"timed_out\": false,\n  \"total\": 119,\n  \"deleted\": 119,\n  \"batches\": 1,\n  \"version_conflicts\": 0,\n  \"noops\": 0,\n  \"retries\": {\n    \"bulk\": 0,\n    \"search\": 0\n  },\n  \"throttled_millis\": 0,\n  \"requests_per_second\": -1.0,\n  \"throttled_until_millis\": 0,\n  \"failures\" : [ ]\n}\n--------------------------------------------------\n// TESTRESPONSE[s/: [0-9]+/: $body.$_path/]\n\n`took`::\n\nThe number of milliseconds from start to end of the whole operation.\n\n`timed_out`::\n\nThis flag is set to `true` if any of the requests executed during the\ndelete by query execution has timed out.\n\n`total`::\n\nThe number of documents that were successfully processed.\n\n`deleted`::\n\nThe number of documents that were successfully deleted.\n\n`batches`::\n\nThe number of scroll responses pulled back by the delete by query.\n\n`version_conflicts`::\n\nThe number of version conflicts that the delete by query hit.\n\n`noops`::\n\nThis field is always equal to zero for delete by query. It only exists\nso that delete by query, update by query, and reindex APIs return responses\n with the same structure.\n\n`retries`::\n\nThe number of retries attempted by delete by query. `bulk` is the number\nof bulk actions retried, and `search` is the number of search actions retried.\n\n`throttled_millis`::\n\nNumber of milliseconds the request slept to conform to `requests_per_second`.\n\n`requests_per_second`::\n\nThe number of requests per second effectively executed during the delete by query.\n\n`throttled_until_millis`::\n\nThis field should always be equal to zero in a `_delete_by_query` response. It only\nhas meaning when using the <<tasks, Task API>>, where it\nindicates the next time (in milliseconds since epoch) a throttled request will be\nexecuted again in order to conform to `requests_per_second`.\n\n`failures`::\n\nArray of failures if there were any unrecoverable errors during the process. If\nthis is non-empty then the request aborted because of those failures.\nDelete by query is implemented using batches, and any failure causes the entire\nprocess to abort but all failures in the current batch are collected into the\narray. You can use the `conflicts` option to prevent reindex from aborting on\nversion conflicts.\n\n[[docs-delete-by-query-api-example]]\n==== {api-examples-title}\n\nDelete all documents from the `my-index-000001` data stream or index:\n\n[source,console]\n--------------------------------------------------\nPOST my-index-000001/_delete_by_query?conflicts=proceed\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\nDelete documents from multiple data streams or indices:\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001,my-index-000002/_delete_by_query\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n--------------------------------------------------\n// TEST[s/^/PUT my-index-000001\\nPUT my-index-000002\\n/]\n\nLimit the delete by query operation to shards that a particular routing\nvalue:\n\n[source,console]\n--------------------------------------------------\nPOST my-index-000001/_delete_by_query?routing=1\n{\n  \"query\": {\n    \"range\" : {\n        \"age\" : {\n           \"gte\" : 10\n        }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\nBy default `_delete_by_query` uses scroll batches of 1000. You can change the\nbatch size with the `scroll_size` URL parameter:\n\n[source,console]\n--------------------------------------------------\nPOST my-index-000001/_delete_by_query?scroll_size=5000\n{\n  \"query\": {\n    \"term\": {\n      \"user.id\": \"kimchy\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\nDelete a document using a unique attribute:\n\n[source,console]\n--------------------------------------------------\nPOST my-index-000001/_delete_by_query\n{\n  \"query\": {\n    \"term\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"max_docs\": 1\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\n[discrete]\n[[docs-delete-by-query-manual-slice]]\n===== Slice manually\n\nSlice a delete by query manually by providing a slice id and total number of\nslices:\n\n[source,console]\n----------------------------------------------------------------\nPOST my-index-000001/_delete_by_query\n{\n  \"slice\": {\n    \"id\": 0,\n    \"max\": 2\n  },\n  \"query\": {\n    \"range\": {\n      \"http.response.bytes\": {\n        \"lt\": 2000000\n      }\n    }\n  }\n}\nPOST my-index-000001/_delete_by_query\n{\n  \"slice\": {\n    \"id\": 1,\n    \"max\": 2\n  },\n  \"query\": {\n    \"range\": {\n      \"http.response.bytes\": {\n        \"lt\": 2000000\n      }\n    }\n  }\n}\n----------------------------------------------------------------\n// TEST[setup:my_index_big]\n\nWhich you can verify works with:\n\n[source,console]\n----------------------------------------------------------------\nGET _refresh\nPOST my-index-000001/_search?size=0&filter_path=hits.total\n{\n  \"query\": {\n    \"range\": {\n      \"http.response.bytes\": {\n        \"lt\": 2000000\n      }\n    }\n  }\n}\n----------------------------------------------------------------\n// TEST[continued]\n\nWhich results in a sensible `total` like this one:\n\n[source,console-result]\n----------------------------------------------------------------\n{\n  \"hits\": {\n    \"total\" : {\n        \"value\": 0,\n        \"relation\": \"eq\"\n    }\n  }\n}\n----------------------------------------------------------------\n\n[discrete]\n[[docs-delete-by-query-automatic-slice]]\n===== Use automatic slicing\n\nYou can also let delete-by-query automatically parallelize using\n<<slice-scroll, sliced scroll>> to slice on `_id`. Use `slices` to specify\nthe number of slices to use:\n\n[source,console]\n----------------------------------------------------------------\nPOST my-index-000001/_delete_by_query?refresh&slices=5\n{\n  \"query\": {\n    \"range\": {\n      \"http.response.bytes\": {\n        \"lt\": 2000000\n      }\n    }\n  }\n}\n----------------------------------------------------------------\n// TEST[setup:my_index_big]\n\nWhich you also can verify works with:\n\n[source,console]\n----------------------------------------------------------------\nPOST my-index-000001/_search?size=0&filter_path=hits.total\n{\n  \"query\": {\n    \"range\": {\n      \"http.response.bytes\": {\n        \"lt\": 2000000\n      }\n    }\n  }\n}\n----------------------------------------------------------------\n// TEST[continued]\n\nWhich results in a sensible `total` like this one:\n\n[source,console-result]\n----------------------------------------------------------------\n{\n  \"hits\": {\n    \"total\" : {\n        \"value\": 0,\n        \"relation\": \"eq\"\n    }\n  }\n}\n----------------------------------------------------------------\n\nSetting `slices` to `auto` will let {es} choose the number of slices\nto use. This setting will use one slice per shard, up to a certain limit. If\nthere are multiple source data streams or indices, it will choose the number of slices based\non the index or backing index with the smallest number of shards.\n\nAdding `slices` to `_delete_by_query` just automates the manual process used in\nthe section above, creating sub-requests which means it has some quirks:\n\n* You can see these requests in the\n<<tasks,Tasks APIs>>. These sub-requests are \"child\"\ntasks of the task for the request with `slices`.\n* Fetching the status of the task for the request with `slices` only contains\nthe status of completed slices.\n* These sub-requests are individually addressable for things like cancellation\nand rethrottling.\n* Rethrottling the request with `slices` will rethrottle the unfinished\nsub-request proportionally.\n* Canceling the request with `slices` will cancel each sub-request.\n* Due to the nature of `slices` each sub-request won't get a perfectly even\nportion of the documents. All documents will be addressed, but some slices may\nbe larger than others. Expect larger slices to have a more even distribution.\n* Parameters like `requests_per_second` and `max_docs` on a request with\n`slices` are distributed proportionally to each sub-request. Combine that with\nthe point above about distribution being uneven and you should conclude that\nusing `max_docs` with `slices` might not result in exactly `max_docs` documents\nbeing deleted.\n* Each sub-request gets a slightly different snapshot of the source data stream or index\nthough these are all taken at approximately the same time.\n\n[discrete]\n[[docs-delete-by-query-rethrottle]]\n===== Change throttling for a request\n\nThe value of `requests_per_second` can be changed on a running delete by query\nusing the `_rethrottle` API. Rethrottling that speeds up the\nquery takes effect immediately but rethrotting that slows down the query\ntakes effect after completing the current batch to prevent scroll\ntimeouts.\n\n[source,console]\n--------------------------------------------------\nPOST _delete_by_query/r1A2WoRbTwKZ516z6NEs5A:36619/_rethrottle?requests_per_second=-1\n--------------------------------------------------\n\nUse the <<tasks,tasks API>> to get the task ID. Set `requests_per_second`\nto any positive decimal value or `-1` to disable throttling.\n\n===== Get the status of a delete by query operation\n\nUse the <<tasks,tasks API>> to get the status of a delete by query\noperation:\n\n\n[source,console]\n--------------------------------------------------\nGET _tasks?detailed=true&actions=*/delete/byquery\n--------------------------------------------------\n// TEST[skip:No tasks to retrieve]\n\nThe response looks like:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"nodes\" : {\n    \"r1A2WoRbTwKZ516z6NEs5A\" : {\n      \"name\" : \"r1A2WoR\",\n      \"transport_address\" : \"127.0.0.1:9300\",\n      \"host\" : \"127.0.0.1\",\n      \"ip\" : \"127.0.0.1:9300\",\n      \"attributes\" : {\n        \"testattr\" : \"test\",\n        \"portsfile\" : \"true\"\n      },\n      \"tasks\" : {\n        \"r1A2WoRbTwKZ516z6NEs5A:36619\" : {\n          \"node\" : \"r1A2WoRbTwKZ516z6NEs5A\",\n          \"id\" : 36619,\n          \"type\" : \"transport\",\n          \"action\" : \"indices:data/write/delete/byquery\",\n          \"status\" : {    <1>\n            \"total\" : 6154,\n            \"updated\" : 0,\n            \"created\" : 0,\n            \"deleted\" : 3500,\n            \"batches\" : 36,\n            \"version_conflicts\" : 0,\n            \"noops\" : 0,\n            \"retries\": 0,\n            \"throttled_millis\": 0\n          },\n          \"description\" : \"\"\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n<1> This object contains the actual status. It is just like the response JSON\nwith the important addition of the `total` field. `total` is the total number\nof operations that the reindex expects to perform. You can estimate the\nprogress by adding the `updated`, `created`, and `deleted` fields. The request\nwill finish when their sum is equal to the `total` field.\n\nWith the task id you can look up the task directly:\n\n[source,console]\n--------------------------------------------------\nGET /_tasks/r1A2WoRbTwKZ516z6NEs5A:36619\n--------------------------------------------------\n// TEST[catch:missing]\n\nThe advantage of this API is that it integrates with `wait_for_completion=false`\nto transparently return the status of completed tasks. If the task is completed\nand `wait_for_completion=false` was set on it then it'll come back with\n`results` or an `error` field. The cost of this feature is the document that\n`wait_for_completion=false` creates at `.tasks/task/${taskId}`. It is up to\nyou to delete that document.\n\n\n[discrete]\n[[docs-delete-by-query-cancel-task-api]]\n===== Cancel a delete by query operation\n\nAny delete by query can be canceled using the <<tasks,task cancel API>>:\n\n[source,console]\n--------------------------------------------------\nPOST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel\n--------------------------------------------------\n\nThe task ID can be found using the <<tasks,tasks API>>.\n\nCancellation should happen quickly but might take a few seconds. The task status\nAPI above will continue to list the delete by query task until this task checks that it\nhas been cancelled and terminates itself.\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T02:49:24.973065",
        "size": 4996,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-downsample-data-stream.html",
        "type": "documentation",
        "role": [
            "xpack",
            "child_attributes"
        ],
        "has_code": false,
        "title": "indices-downsample-data-stream",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[indices-downsample-data-stream]]\n=== Downsample index API\n++++\n<titleabbrev>Downsample</titleabbrev>\n++++\n\nAggregates a time series (TSDS) index and stores\npre-computed statistical summaries (`min`, `max`, `sum`, `value_count` and\n`avg`) for each metric field grouped by a configured time interval. For example,\na TSDS index that contains metrics sampled every 10 seconds can be downsampled\nto an hourly index. All documents within an hour interval are summarized and\nstored as a single document in the downsample index.\n\n// tag::downsample-example[]\n////\n[source,console]\n----\nPUT /my-time-series-index\n{\n    \"settings\": {\n        \"index\": {\n            \"mode\": \"time_series\",\n            \"time_series\": {\n                \"start_time\": \"2022-06-10T00:00:00Z\",\n                \"end_time\": \"2022-06-30T23:59:59Z\"\n            },\n            \"routing_path\": [\n                \"test.namespace\"\n            ],\n            \"number_of_replicas\": 0,\n            \"number_of_shards\": 2\n        }\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"@timestamp\": {\n                \"type\": \"date\"\n            },\n            \"metric\": {\n                \"type\": \"long\",\n                \"time_series_metric\": \"gauge\"\n            },\n            \"dimension\": {\n                \"type\": \"keyword\",\n                \"time_series_dimension\": true\n            }\n        }\n    }\n}\n\nPUT /my-time-series-index/_block/write\n\n----\n// TEST\n////\n\n[source,console]\n----\nPOST /my-time-series-index/_downsample/my-downsampled-time-series-index\n{\n    \"fixed_interval\": \"1d\"\n}\n----\n// TEST[continued]\n\n////\n[source,console]\n----\nDELETE /my-time-series-index*\nDELETE _data_stream/*\nDELETE _index_template/*\n----\n// TEST[continued]\n////\n// end::downsample-example[]\n\n[[downsample-api-request]]\n==== {api-request-title}\n\n`POST /<source-index>/_downsample/<output-downsampled-index>`\n\n[[downsample-api-prereqs]]\n==== {api-prereq-title}\n\n* Only indices in a <<tsds,time series data stream>> are supported.\n\n* If the {es} {security-features} are enabled, you must have the `all`\nor `manage` <<privileges-list-indices,index privilege>> for the data stream.\n\n* Neither <<field-and-document-access-control,field nor document level security>> can be defined on the source index.\n\n* The source index must be read only (`index.blocks.write: true`).\n\n[[downsample-api-path-params]]\n==== {api-path-parms-title}\n\n`<source-index>`::\n(Optional, string) Name of the time series index to downsample.\n\n`<output-downsampled_index>`::\n+\n--\n(Required, string) Name of the index to create. \n\ninclude::{es-ref-dir}/indices/create-index.asciidoc[tag=index-name-reqs]\n--\n\n[role=\"child_attributes\"]\n[[downsample-api-query-parms]]\n==== {api-query-parms-title}\n\n`fixed_interval`:: (Required, <<time-units,time units>>) The interval at which\nto aggregate the original time series index. For example, `60m` produces a\ndocument for each 60 minute (hourly) interval. This follows standard time\nformatting syntax as used elsewhere in {es}.\n+\nNOTE: Smaller, more granular intervals take up proportionally more space.\n\n[[downsample-api-process]]\n==== The downsampling process\n\nThe downsampling operation traverses the source TSDS index and performs the\nfollowing steps:\n\n. Creates a new document for each value of the `_tsid` field and each\n`@timestamp` value, rounded to the `fixed_interval` defined in the downsample\nconfiguration.\n. For each new document, copies all <<time-series-dimension,time\nseries dimensions>> from the source index to the target index. Dimensions in a\nTSDS are constant, so this is done only once per bucket.\n. For each <<time-series-metric,time series metric>> field, computes aggregations\nfor all documents in the bucket. Depending on the metric type of each metric\nfield a different set of pre-aggregated results is stored:\n\n** `gauge`: The `min`, `max`, `sum`, and `value_count` are stored; `value_count`\nis stored as type `aggregate_metric_double`.\n** `counter`: The `last_value` is stored.\n. For all other fields, the most recent value is copied to the target index.\n\n[[downsample-api-mappings]]\n==== Source and target index field mappings\n\nFields in the target, downsampled index are created based on fields in the\noriginal source index, as follows:\n\n. All fields mapped with the `time-series-dimension` parameter are created in\nthe target downsample index with the same mapping as in the source index.\n. All fields mapped with the `time_series_metric` parameter are created\nin the target downsample index with the same mapping as in the source\nindex. An exception is that for fields mapped as `time_series_metric: gauge`\nthe field type is changed to `aggregate_metric_double`.\n. All other fields that are neither dimensions nor metrics (that is, label\nfields), are created in the target downsample index with the same mapping\nthat they had in the source index.\n\nCheck the <<downsampling,Downsampling>> documentation for an overview and\nexamples of running downsampling manually and as part of an ILM policy.\n"
}
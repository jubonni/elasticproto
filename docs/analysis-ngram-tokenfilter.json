{
    "meta": {
        "timestamp": "2024-11-01T02:49:25.771066",
        "size": 5242,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-ngram-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-ngram-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-ngram-tokenfilter]]\n=== N-gram token filter\n++++\n<titleabbrev>N-gram</titleabbrev>\n++++\n\nForms {wikipedia}/N-gram[n-grams] of specified lengths from\na token.\n\nFor example, you can use the `ngram` token filter to change `fox` to\n`[ f, fo, o, ox, x ]`.\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/ngram/NGramTokenFilter.html[NGramTokenFilter].\n\n[NOTE]\n====\nThe `ngram` filter is similar to the\n<<analysis-edgengram-tokenfilter,`edge_ngram` token filter>>. However, the\n`edge_ngram` only outputs n-grams that start at the beginning of a token.\n====\n\n[[analysis-ngram-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the `ngram`\nfilter to convert `Quick fox` to 1-character and 2-character n-grams:\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [ \"ngram\" ],\n  \"text\": \"Quick fox\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ Q, Qu, u, ui, i, ic, c, ck, k, f, fo, o, ox, x ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"Q\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"Qu\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"u\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"ui\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"i\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"ic\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"c\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"ck\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"k\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 5,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"f\",\n      \"start_offset\" : 6,\n      \"end_offset\" : 9,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"fo\",\n      \"start_offset\" : 6,\n      \"end_offset\" : 9,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"o\",\n      \"start_offset\" : 6,\n      \"end_offset\" : 9,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"ox\",\n      \"start_offset\" : 6,\n      \"end_offset\" : 9,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"x\",\n      \"start_offset\" : 6,\n      \"end_offset\" : 9,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-ngram-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the `ngram`\nfilter to configure a new <<analysis-custom-analyzer,custom analyzer>>.\n\n[source,console]\n--------------------------------------------------\nPUT ngram_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_ngram\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"ngram\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-ngram-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`max_gram`::\n(Optional, integer)\nMaximum length of characters in a gram. Defaults to `2`.\n\n`min_gram`::\n(Optional, integer)\nMinimum length of characters in a gram. Defaults to `1`.\n\n`preserve_original`::\n(Optional, Boolean)\nEmits original token when set to `true`. Defaults to `false`.\n\nYou can use the <<index-max-ngram-diff,`index.max_ngram_diff`>> index-level\nsetting to control the maximum allowed difference between the `max_gram` and\n`min_gram` values.\n\n[[analysis-ngram-tokenfilter-customize]]\n==== Customize\n\nTo customize the `ngram` filter, duplicate it to create the basis for a new\ncustom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following request creates a custom `ngram` filter that forms\nn-grams between 3-5 characters. The request also increases the\n`index.max_ngram_diff` setting to `2`.\n\n[source,console]\n--------------------------------------------------\nPUT ngram_custom_example\n{\n  \"settings\": {\n    \"index\": {\n      \"max_ngram_diff\": 2\n    },\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"3_5_grams\" ]\n        }\n      },\n      \"filter\": {\n        \"3_5_grams\": {\n          \"type\": \"ngram\",\n          \"min_gram\": 3,\n          \"max_gram\": 5\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
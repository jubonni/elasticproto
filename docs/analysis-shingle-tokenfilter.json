{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.430066",
        "size": 11091,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-shingle-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-shingle-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-shingle-tokenfilter]]\n=== Shingle token filter\n++++\n<titleabbrev>Shingle</titleabbrev>\n++++\n\nAdd shingles, or word {wikipedia}/N-gram[n-grams], to a token\nstream by concatenating adjacent tokens. By default, the `shingle` token filter\noutputs two-word shingles and unigrams.\n\nFor example, many tokenizers convert `the lazy dog` to `[ the, lazy, dog ]`. You\ncan use the `shingle` filter to add two-word shingles to this stream:\n`[ the, the lazy, lazy, lazy dog, dog ]`.\n\nTIP: Shingles are often used to help speed up phrase queries, such as\n<<query-dsl-match-query-phrase,`match_phrase`>>. Rather than creating shingles\nusing the `shingles` filter, we recommend you use the\n<<index-phrases,`index-phrases`>> mapping parameter on the appropriate\n<<text,text>> field instead.\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/shingle/ShingleFilter.html[ShingleFilter].\n\n[[analysis-shingle-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the `shingle`\nfilter to add two-word shingles to the token stream for `quick brown fox jumps`:\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [ \"shingle\" ],\n  \"text\": \"quick brown fox jumps\"\n}\n----\n\nThe filter produces the following tokens:\n\n[source,text]\n----\n[ quick, quick brown, brown, brown fox, fox, fox jumps, jumps ]\n----\n\n////\n[source,console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"quick brown\",\n      \"start_offset\": 0,\n      \"end_offset\": 11,\n      \"type\": \"shingle\",\n      \"position\": 0,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 6,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown fox\",\n      \"start_offset\": 6,\n      \"end_offset\": 15,\n      \"type\": \"shingle\",\n      \"position\": 1,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 12,\n      \"end_offset\": 15,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"fox jumps\",\n      \"start_offset\": 12,\n      \"end_offset\": 21,\n      \"type\": \"shingle\",\n      \"position\": 2,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"jumps\",\n      \"start_offset\": 16,\n      \"end_offset\": 21,\n      \"type\": \"word\",\n      \"position\": 3\n    }\n  ]\n}\n----\n////\n\nTo produce shingles of 2-3 words, add the following arguments to the analyze API\nrequest:\n\n* `min_shingle_size`: `2`\n* `max_shingle_size`: `3`\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"shingle\",\n      \"min_shingle_size\": 2,\n      \"max_shingle_size\": 3\n    }\n  ],\n  \"text\": \"quick brown fox jumps\"\n}\n----\n\nThe filter produces the following tokens:\n\n[source,text]\n----\n[ quick, quick brown, quick brown fox, brown, brown fox, brown fox jumps, fox, fox jumps, jumps ]\n----\n\n////\n[source, console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"quick brown\",\n      \"start_offset\": 0,\n      \"end_offset\": 11,\n      \"type\": \"shingle\",\n      \"position\": 0,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"quick brown fox\",\n      \"start_offset\": 0,\n      \"end_offset\": 15,\n      \"type\": \"shingle\",\n      \"position\": 0,\n      \"positionLength\": 3\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 6,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown fox\",\n      \"start_offset\": 6,\n      \"end_offset\": 15,\n      \"type\": \"shingle\",\n      \"position\": 1,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"brown fox jumps\",\n      \"start_offset\": 6,\n      \"end_offset\": 21,\n      \"type\": \"shingle\",\n      \"position\": 1,\n      \"positionLength\": 3\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 12,\n      \"end_offset\": 15,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"fox jumps\",\n      \"start_offset\": 12,\n      \"end_offset\": 21,\n      \"type\": \"shingle\",\n      \"position\": 2,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"jumps\",\n      \"start_offset\": 16,\n      \"end_offset\": 21,\n      \"type\": \"word\",\n      \"position\": 3\n    }\n  ]\n}\n----\n////\n\nTo only include shingles in the output, add an `output_unigrams` argument of\n`false` to the request.\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"shingle\",\n      \"min_shingle_size\": 2,\n      \"max_shingle_size\": 3,\n      \"output_unigrams\": false\n    }\n  ],\n  \"text\": \"quick brown fox jumps\"\n}\n----\n\nThe filter produces the following tokens:\n\n[source,text]\n----\n[ quick brown, quick brown fox, brown fox, brown fox jumps, fox jumps ]\n----\n\n////\n[source, console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick brown\",\n      \"start_offset\": 0,\n      \"end_offset\": 11,\n      \"type\": \"shingle\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"quick brown fox\",\n      \"start_offset\": 0,\n      \"end_offset\": 15,\n      \"type\": \"shingle\",\n      \"position\": 0,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"brown fox\",\n      \"start_offset\": 6,\n      \"end_offset\": 15,\n      \"type\": \"shingle\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown fox jumps\",\n      \"start_offset\": 6,\n      \"end_offset\": 21,\n      \"type\": \"shingle\",\n      \"position\": 1,\n      \"positionLength\": 2\n    },\n    {\n      \"token\": \"fox jumps\",\n      \"start_offset\": 12,\n      \"end_offset\": 21,\n      \"type\": \"shingle\",\n      \"position\": 2\n    }\n  ]\n}\n----\n////\n\n[[analysis-shingle-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`shingle` filter to configure a new <<analysis-custom-analyzer,custom\nanalyzer>>.\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_shingle\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"shingle\" ]\n        }\n      }\n    }\n  }\n}\n----\n\n[[analysis-shingle-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`max_shingle_size`::\n(Optional, integer)\nMaximum number of tokens to concatenate when creating shingles. Defaults to `2`.\n+\nNOTE: This value cannot be lower than the `min_shingle_size` argument, which\ndefaults to `2`. The difference between this value and the `min_shingle_size`\nargument cannot exceed the <<index-max-shingle-diff,`index.max_shingle_diff`>>\nindex-level setting, which defaults to `3`.\n\n`min_shingle_size`::\n(Optional, integer)\nMinimum number of tokens to concatenate when creating shingles. Defaults to `2`.\n+\nNOTE: This value cannot exceed the `max_shingle_size` argument, which defaults\nto `2`. The difference between the `max_shingle_size` argument and this value\ncannot exceed the <<index-max-shingle-diff,`index.max_shingle_diff`>>\nindex-level setting, which defaults to `3`.\n\n`output_unigrams`::\n(Optional, Boolean)\nIf `true`, the output includes the original input tokens. If `false`, the output\nonly includes shingles; the original input tokens are removed. Defaults to\n`true`.\n\n`output_unigrams_if_no_shingles`::\nIf `true`, the output includes the original input tokens only if no shingles are\nproduced; if shingles are produced, the output only includes shingles. Defaults\nto `false`.\n+\nIMPORTANT: If both this and the `output_unigrams` parameter are `true`, only the\n`output_unigrams` argument is used.\n\n`token_separator`::\n(Optional, string)\nSeparator used to concatenate adjacent tokens to form a shingle. Defaults to a\nspace (`\" \"`).\n\n`filler_token`::\n+\n--\n(Optional, string)\nString used in shingles as a replacement for empty positions that do not contain\na token. This filler token is only used in shingles, not original unigrams.\nDefaults to an underscore (`_`).\n\nSome token filters, such as the `stop` filter, create empty positions when\nremoving stop words with a position increment greater than one.\n\n.*Example*\n[%collapsible]\n====\nIn the following <<indices-analyze,analyze API>> request, the `stop` filter\nremoves the stop word `a` from `fox jumps a lazy dog`, creating an empty\nposition. The subsequent `shingle` filter replaces this empty position with a\nplus sign (`+`) in shingles.\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"stop\",\n      \"stopwords\": [ \"a\" ]\n    },\n    {\n      \"type\": \"shingle\",\n      \"filler_token\": \"+\"\n    }\n  ],\n  \"text\": \"fox jumps a lazy dog\"\n}\n----\n\nThe filter produces the following tokens:\n\n[source,text]\n----\n[ fox, fox jumps, jumps, jumps +, + lazy, lazy, lazy dog, dog ]\n----\n\n////\n[source, console-result]\n----\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"fox\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 3,\n      \"type\" : \"word\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"fox jumps\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 9,\n      \"type\" : \"shingle\",\n      \"position\" : 0,\n      \"positionLength\" : 2\n    },\n    {\n      \"token\" : \"jumps\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 9,\n      \"type\" : \"word\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"jumps +\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 12,\n      \"type\" : \"shingle\",\n      \"position\" : 1,\n      \"positionLength\" : 2\n    },\n    {\n      \"token\" : \"+ lazy\",\n      \"start_offset\" : 12,\n      \"end_offset\" : 16,\n      \"type\" : \"shingle\",\n      \"position\" : 2,\n      \"positionLength\" : 2\n    },\n    {\n      \"token\" : \"lazy\",\n      \"start_offset\" : 12,\n      \"end_offset\" : 16,\n      \"type\" : \"word\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"lazy dog\",\n      \"start_offset\" : 12,\n      \"end_offset\" : 20,\n      \"type\" : \"shingle\",\n      \"position\" : 3,\n      \"positionLength\" : 2\n    },\n    {\n      \"token\" : \"dog\",\n      \"start_offset\" : 17,\n      \"end_offset\" : 20,\n      \"type\" : \"word\",\n      \"position\" : 4\n    }\n  ]\n}\n----\n////\n====\n--\n\n[[analysis-shingle-tokenfilter-customize]]\n==== Customize\n\nTo customize the `shingle` filter, duplicate it to create the basis for a new\ncustom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following <<indices-create-index,create index API>> request\nuses a custom `shingle` filter, `my_shingle_filter`, to configure a new\n<<analysis-custom-analyzer,custom analyzer>>.\n\nThe `my_shingle_filter` filter uses a `min_shingle_size` of `2` and a\n`max_shingle_size` of `5`, meaning it produces shingles of 2-5 words.\nThe filter also includes a `output_unigrams` argument of `false`, meaning that\nonly shingles are included in the output.\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"en\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"my_shingle_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_shingle_filter\": {\n          \"type\": \"shingle\",\n          \"min_shingle_size\": 2,\n          \"max_shingle_size\": 5,\n          \"output_unigrams\": false\n        }\n      }\n    }\n  }\n}\n----\n"
}
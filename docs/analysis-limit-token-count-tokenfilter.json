{
    "meta": {
        "size": 3662,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-limit-token-count-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-limit-token-count-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-limit-token-count-tokenfilter]]\n=== Limit token count token filter\n++++\n<titleabbrev>Limit token count</titleabbrev>\n++++\n\nLimits the number of output tokens. The `limit` filter is commonly used to limit\nthe size of document field values based on token count.\n\nBy default, the `limit` filter keeps only the first token in a stream. For\nexample, the filter can change the token stream `[ one, two, three ]` to \n`[ one ]`.\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/miscellaneous/LimitTokenCountFilter.html[LimitTokenCountFilter].\n\n[TIP]\n====\n If you want to limit the size of field values based on\n_character length_, use the <<ignore-above,`ignore_above`>> mapping parameter.\n====\n\n[[analysis-limit-token-count-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`max_token_count`::\n(Optional, integer)\nMaximum number of tokens to keep. Once this limit is reached, any remaining\ntokens are excluded from the output. Defaults to `1`.\n\n`consume_all_tokens`::\n(Optional, Boolean)\nIf `true`, the `limit` filter exhausts the token stream, even if the\n`max_token_count` has already been reached. Defaults to `false`.\n\n[[analysis-limit-token-count-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the `limit`\nfilter to keep only the first two tokens in `quick fox jumps over lazy dog`:\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n    \"filter\": [\n    {\n      \"type\": \"limit\",\n      \"max_token_count\": 2\n    }\n  ],\n  \"text\": \"quick fox jumps over lazy dog\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ quick, fox ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 6,\n      \"end_offset\": 9,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-limit-token-count-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`limit` filter to configure a new \n<<analysis-custom-analyzer,custom analyzer>>.\n\n[source,console]\n--------------------------------------------------\nPUT limit_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_one_token_limit\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"limit\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-limit-token-count-tokenfilter-customize]]\n==== Customize\n\nTo customize the `limit` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following request creates a custom `limit` filter that keeps\nonly the first five tokens of a stream:\n\n[source,console]\n--------------------------------------------------\nPUT custom_limit_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_five_token_limit\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"five_token_limit\" ]\n        }\n      },\n      \"filter\": {\n        \"five_token_limit\": {\n          \"type\": \"limit\",\n          \"max_token_count\": 5\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
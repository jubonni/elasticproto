{
    "meta": {
        "size": 4631,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-capture-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-pattern-capture-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-pattern-capture-tokenfilter]]\n=== Pattern capture token filter\n++++\n<titleabbrev>Pattern capture</titleabbrev>\n++++\n\nThe `pattern_capture` token filter, unlike the `pattern` tokenizer,\nemits a token for every capture group in the regular expression.\nPatterns are not anchored to the beginning and end of the string, so\neach pattern can match multiple times, and matches are allowed to\noverlap.\n\n[WARNING]\n.Beware of Pathological Regular Expressions\n========================================\n\nThe pattern capture token filter uses\nhttps://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html[Java Regular Expressions].\n\nA badly written regular expression could run very slowly or even throw a\nStackOverflowError and cause the node it is running on to exit suddenly.\n\nRead more about https://www.regular-expressions.info/catastrophic.html[pathological regular expressions and how to avoid them].\n\n========================================\n\nFor instance a pattern like :\n\n[source,text]\n--------------------------------------------------\n\"(([a-z]+)(\\d*))\"\n--------------------------------------------------\n\nwhen matched against:\n\n[source,text]\n--------------------------------------------------\n\"abc123def456\"\n--------------------------------------------------\n\nwould produce the tokens: [ `abc123`, `abc`, `123`, `def456`, `def`,\n`456` ]\n\nIf `preserve_original` is set to `true` (the default) then it would also\nemit the original token: `abc123def456`.\n\nThis is particularly useful for indexing text like camel-case code, eg\n`stripHTML` where a user may search for `\"strip html\"` or `\"striphtml\"`:\n\n[source,console]\n--------------------------------------------------\nPUT test\n{\n   \"settings\" : {\n      \"analysis\" : {\n         \"filter\" : {\n            \"code\" : {\n               \"type\" : \"pattern_capture\",\n               \"preserve_original\" : true,\n               \"patterns\" : [\n                  \"(\\\\p{Ll}+|\\\\p{Lu}\\\\p{Ll}+|\\\\p{Lu}+)\",\n                  \"(\\\\d+)\"\n               ]\n            }\n         },\n         \"analyzer\" : {\n            \"code\" : {\n               \"tokenizer\" : \"pattern\",\n               \"filter\" : [ \"code\", \"lowercase\" ]\n            }\n         }\n      }\n   }\n}\n--------------------------------------------------\n\nWhen used to analyze the text\n\n[source,java]\n--------------------------------------------------\nimport static org.apache.commons.lang.StringEscapeUtils.escapeHtml\n--------------------------------------------------\n\nthis emits the tokens: [ `import`, `static`, `org`, `apache`, `commons`,\n`lang`, `stringescapeutils`, `string`, `escape`, `utils`, `escapehtml`,\n`escape`, `html` ]\n\nAnother example is analyzing email addresses:\n\n[source,console]\n--------------------------------------------------\nPUT test\n{\n   \"settings\" : {\n      \"analysis\" : {\n         \"filter\" : {\n            \"email\" : {\n               \"type\" : \"pattern_capture\",\n               \"preserve_original\" : true,\n               \"patterns\" : [\n                  \"([^@]+)\",\n                  \"(\\\\p{L}+)\",\n                  \"(\\\\d+)\",\n                  \"@(.+)\"\n               ]\n            }\n         },\n         \"analyzer\" : {\n            \"email\" : {\n               \"tokenizer\" : \"uax_url_email\",\n               \"filter\" : [ \"email\", \"lowercase\",  \"unique\" ]\n            }\n         }\n      }\n   }\n}\n--------------------------------------------------\n\nWhen the above analyzer is used on an email address like:\n\n[source,text]\n--------------------------------------------------\njohn-smith_123@foo-bar.com\n--------------------------------------------------\n\nit would produce the following tokens:\n\n    john-smith_123@foo-bar.com, john-smith_123,\n    john, smith, 123, foo-bar.com, foo, bar, com\n\nMultiple patterns are required to allow overlapping captures, but also\nmeans that patterns are less dense and easier to understand.\n\n*Note:* All tokens are emitted in the same position, and with the same\ncharacter offsets. This means, for example, that a `match` query for\n`john-smith_123@foo-bar.com` that uses this analyzer will return documents\ncontaining any of these tokens, even when using the `and` operator.\nAlso, when combined with highlighting, the whole original token will \nbe highlighted, not just the matching subset. For instance, querying \nthe above email address for `\"smith\"` would highlight:\n\n[source,html]\n--------------------------------------------------\n  <em>john-smith_123@foo-bar.com</em>\n--------------------------------------------------\n\nnot:\n\n[source,html]\n--------------------------------------------------\n  john-<em>smith</em>_123@foo-bar.com\n--------------------------------------------------\n"
}
{
    "meta": {
        "size": 19546,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/percolator.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "percolator",
        "version": "8.15"
    },
    "doc": "[[percolator]]\n=== Percolator field type\n++++\n<titleabbrev>Percolator</titleabbrev>\n++++\n\nThe `percolator` field type parses a json structure into a native query and\nstores that query, so that the <<query-dsl-percolate-query,percolate query>>\ncan use it to match provided documents.\n\nAny field that contains a json object can be configured to be a percolator\nfield. The percolator field type has no settings. Just configuring the `percolator`\nfield type is sufficient to instruct Elasticsearch to treat a field as a\nquery.\n\nIf the following mapping configures the `percolator` field type for the\n`query` field:\n\n[source,console]\n--------------------------------------------------\nPUT my-index-000001\n{\n  \"mappings\": {\n    \"properties\": {\n      \"query\": {\n        \"type\": \"percolator\"\n      },\n      \"field\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TESTSETUP\n\nThen you can index a query:\n\n[source,console]\n--------------------------------------------------\nPUT my-index-000001/_doc/match_value\n{\n  \"query\": {\n    \"match\": {\n      \"field\": \"value\"\n    }\n  }\n}\n--------------------------------------------------\n\n[IMPORTANT]\n=====================================\n\nFields referred to in a percolator query must *already* exist in the mapping\nassociated with the index used for percolation. In order to make sure these fields exist,\nadd or update a mapping via the <<indices-create-index,create index>> or <<indices-put-mapping,update mapping>> APIs.\n\n=====================================\n\n[discrete]\n==== Reindexing your percolator queries\n\nReindexing percolator queries is sometimes required to benefit from improvements made to the `percolator` field type in\nnew releases.\n\nReindexing percolator queries can be reindexed by using the <<docs-reindex,reindex api>>.\nLets take a look at the following index with a percolator field type:\n\n[source,console]\n--------------------------------------------------\nPUT index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"query\" : {\n        \"type\" : \"percolator\"\n      },\n      \"body\" : {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPOST _aliases\n{\n  \"actions\": [\n    {\n      \"add\": {\n        \"index\": \"index\",\n        \"alias\": \"queries\" <1>\n      }\n    }\n  ]\n}\n\nPUT queries/_doc/1?refresh\n{\n  \"query\" : {\n    \"match\" : {\n      \"body\" : \"quick brown fox\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n<1> It is always recommended to define an alias for your index, so that in case of a reindex systems / applications\n    don't need to be changed to know that the percolator queries are now in a different index.\n\nLets say you're going to upgrade to a new major version and in order for the new Elasticsearch version to still be able\nto read your queries you need to reindex your queries into a new index on the current Elasticsearch version:\n\n[source,console]\n--------------------------------------------------\nPUT new_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"query\" : {\n        \"type\" : \"percolator\"\n      },\n      \"body\" : {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\n\nPOST /_reindex?refresh\n{\n  \"source\": {\n    \"index\": \"index\"\n  },\n  \"dest\": {\n    \"index\": \"new_index\"\n  }\n}\n\nPOST _aliases\n{\n  \"actions\": [ <1>\n    {\n      \"remove\": {\n        \"index\" : \"index\",\n        \"alias\": \"queries\"\n      }\n    },\n    {\n      \"add\": {\n        \"index\": \"new_index\",\n        \"alias\": \"queries\"\n      }\n    }\n  ]\n}\n--------------------------------------------------\n// TEST[continued]\n\n<1> If you have an alias don't forget to point it to the new index.\n\nExecuting the `percolate` query via the `queries` alias:\n\n[source,console]\n--------------------------------------------------\nGET /queries/_search\n{\n  \"query\": {\n    \"percolate\" : {\n      \"field\" : \"query\",\n      \"document\" : {\n        \"body\" : \"fox jumps over the lazy dog\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\nnow returns matches from the new index:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"took\": 3,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\" : 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\" : {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 0.13076457,\n    \"hits\": [\n      {\n        \"_index\": \"new_index\", <1>\n        \"_id\": \"1\",\n        \"_score\": 0.13076457,\n        \"_source\": {\n          \"query\": {\n            \"match\": {\n              \"body\": \"quick brown fox\"\n            }\n          }\n        },\n        \"fields\" : {\n          \"_percolator_document_slot\" : [0]\n        }\n      }\n    ]\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"took\": 3,/\"took\": \"$body.took\",/]\n\n<1> Percolator query hit is now being presented from the new index.\n\n[discrete]\n==== Optimizing query time text analysis\n\nWhen the percolator verifies a percolator candidate match it is going to parse, perform query time text analysis and actually run\nthe percolator query on the document being percolated. This is done for each candidate match and every time the `percolate` query executes.\nIf your query time text analysis is relatively expensive part of query parsing then text analysis can become the\ndominating factor time is being spent on when percolating. This query parsing overhead can become noticeable when the\npercolator ends up verifying many candidate percolator query matches.\n\nTo avoid the most expensive part of text analysis at percolate time. One can choose to do the expensive part of text analysis\nwhen indexing the percolator query. This requires using two different analyzers. The first analyzer actually performs\ntext analysis that needs be performed (expensive part). The second analyzer (usually whitespace) just splits the generated tokens\nthat the first analyzer has produced. Then before indexing a percolator query, the analyze api should be used to analyze the query\ntext with the more expensive analyzer. The result of the analyze api, the tokens, should be used to substitute the original query\ntext in the percolator query. It is important that the query should now be configured to override the analyzer from the mapping and\njust the second analyzer. Most text based queries support an `analyzer` option (`match`, `query_string`, `simple_query_string`).\nUsing this approach the expensive text analysis is performed once instead of many times.\n\nLets demonstrate this workflow via a simplified example.\n\nLets say we want to index the following percolator query:\n\n[source,js]\n--------------------------------------------------\n{\n  \"query\" : {\n    \"match\" : {\n      \"body\" : {\n        \"query\" : \"missing bicycles\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nwith these settings and mapping:\n\n[source,console]\n--------------------------------------------------\nPUT /test_index\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\" : {\n          \"tokenizer\": \"standard\",\n          \"filter\" : [\"lowercase\", \"porter_stem\"]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"query\" : {\n        \"type\": \"percolator\"\n      },\n      \"body\" : {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\" <1>\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n<1> For the purpose of this example, this analyzer is considered expensive.\n\nFirst we need to use the analyze api to perform the text analysis prior to indexing:\n\n[source,console]\n--------------------------------------------------\nPOST /test_index/_analyze\n{\n  \"analyzer\" : \"my_analyzer\",\n  \"text\" : \"missing bicycles\"\n}\n--------------------------------------------------\n// TEST[continued]\n\nThis results the following response:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"miss\",\n      \"start_offset\": 0,\n      \"end_offset\": 7,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"bicycl\",\n      \"start_offset\": 8,\n      \"end_offset\": 16,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    }\n  ]\n}\n--------------------------------------------------\n\nAll the tokens in the returned order need to replace the query text in the percolator query:\n\n[source,console]\n--------------------------------------------------\nPUT /test_index/_doc/1?refresh\n{\n  \"query\" : {\n    \"match\" : {\n      \"body\" : {\n        \"query\" : \"miss bicycl\",\n        \"analyzer\" : \"whitespace\" <1>\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n<1> It is important to select a whitespace analyzer here, otherwise the analyzer defined in the mapping will be used,\nwhich defeats the point of using this workflow. Note that `whitespace` is a built-in analyzer, if a different analyzer\nneeds to be used, it needs to be configured first in the index's settings.\n\nThe analyze api prior to the indexing the percolator flow should be done for each percolator query.\n\nAt percolate time nothing changes and the `percolate` query can be defined normally:\n\n[source,console]\n--------------------------------------------------\nGET /test_index/_search\n{\n  \"query\": {\n    \"percolate\" : {\n      \"field\" : \"query\",\n      \"document\" : {\n        \"body\" : \"Bycicles are missing\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\nThis results in a response like this:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"took\": 6,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\" : 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\" : {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 0.13076457,\n    \"hits\": [\n      {\n        \"_index\": \"test_index\",\n        \"_id\": \"1\",\n        \"_score\": 0.13076457,\n        \"_source\": {\n          \"query\": {\n            \"match\": {\n              \"body\": {\n                \"query\": \"miss bicycl\",\n                \"analyzer\": \"whitespace\"\n              }\n            }\n          }\n        },\n        \"fields\" : {\n          \"_percolator_document_slot\" : [0]\n        }\n      }\n    ]\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"took\": 6,/\"took\": \"$body.took\",/]\n\n[discrete]\n==== Optimizing wildcard queries.\n\nWildcard queries are more expensive than other queries for the percolator,\nespecially if the wildcard expressions are large.\n\nIn the case of `wildcard` queries with prefix wildcard expressions or just the `prefix` query,\nthe `edge_ngram` token filter can be used to replace these queries with regular `term`\nquery on a field where the `edge_ngram` token filter is configured.\n\nCreating an index with custom analysis settings:\n\n[source,console]\n--------------------------------------------------\nPUT my_queries1\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"wildcard_prefix\": { <1>\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"wildcard_edge_ngram\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"wildcard_edge_ngram\": { <2>\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 1,\n          \"max_gram\": 32\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"query\": {\n        \"type\": \"percolator\"\n      },\n      \"my_field\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"prefix\": { <3>\n            \"type\": \"text\",\n            \"analyzer\": \"wildcard_prefix\",\n            \"search_analyzer\": \"standard\"\n          }\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n<1> The analyzer that generates the prefix tokens to be used at index time only.\n<2> Increase the `min_gram` and decrease `max_gram` settings based on your prefix search needs.\n<3> This multifield should be used to do the prefix search\n    with a `term` or `match` query instead of a `prefix` or `wildcard` query.\n\n\nThen instead of indexing the following query:\n\n[source,js]\n--------------------------------------------------\n{\n  \"query\": {\n    \"wildcard\": {\n      \"my_field\": \"abc*\"\n    }\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nthis query below should be indexed:\n\n[source,console]\n--------------------------------------------------\nPUT /my_queries1/_doc/1?refresh\n{\n  \"query\": {\n    \"term\": {\n      \"my_field.prefix\": \"abc\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\nThis way can handle the second query more efficiently than the first query.\n\nThe following search request will match with the previously indexed\npercolator query:\n\n[source,console]\n--------------------------------------------------\nGET /my_queries1/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"document\": {\n        \"my_field\": \"abcd\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"took\": 6,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 1,\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\" : {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 0.18864399,\n    \"hits\": [\n      {\n        \"_index\": \"my_queries1\",\n        \"_id\": \"1\",\n        \"_score\": 0.18864399,\n        \"_source\": {\n          \"query\": {\n            \"term\": {\n              \"my_field.prefix\": \"abc\"\n            }\n          }\n        },\n        \"fields\": {\n          \"_percolator_document_slot\": [\n            0\n          ]\n        }\n      }\n    ]\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"took\": 6,/\"took\": \"$body.took\",/]\n\nThe same technique can also be used to speed up suffix\nwildcard searches. By using the `reverse` token filter\nbefore the `edge_ngram` token filter.\n\n[source,console]\n--------------------------------------------------\nPUT my_queries2\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"wildcard_suffix\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"reverse\",\n            \"wildcard_edge_ngram\"\n          ]\n        },\n        \"wildcard_suffix_search_time\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"reverse\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"wildcard_edge_ngram\": {\n          \"type\": \"edge_ngram\",\n          \"min_gram\": 1,\n          \"max_gram\": 32\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"query\": {\n        \"type\": \"percolator\"\n      },\n      \"my_field\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"suffix\": {\n            \"type\": \"text\",\n            \"analyzer\": \"wildcard_suffix\",\n            \"search_analyzer\": \"wildcard_suffix_search_time\" <1>\n          }\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n<1> A custom analyzer is needed at search time too, because otherwise\n    the query terms are not being reversed and would otherwise not match\n    with the reserved suffix tokens.\n\nThen instead of indexing the following query:\n\n[source,js]\n--------------------------------------------------\n{\n  \"query\": {\n    \"wildcard\": {\n      \"my_field\": \"*xyz\"\n    }\n  }\n}\n--------------------------------------------------\n// NOTCONSOLE\n\nthe following query below should be indexed:\n\n[source,console]\n--------------------------------------------------\nPUT /my_queries2/_doc/2?refresh\n{\n  \"query\": {\n    \"match\": { <1>\n      \"my_field.suffix\": \"xyz\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n<1> The `match` query should be used instead of the `term` query,\n    because text analysis needs to reverse the query terms.\n\nThe following search request will match with the previously indexed\npercolator query:\n\n[source,console]\n--------------------------------------------------\nGET /my_queries2/_search\n{\n  \"query\": {\n    \"percolate\": {\n      \"field\": \"query\",\n      \"document\": {\n        \"my_field\": \"wxyz\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[continued]\n\n[discrete]\n==== Dedicated Percolator Index\n\nPercolate queries can be added to any index. Instead of adding percolate queries to the index the data resides in,\nthese queries can also be added to a dedicated index. The advantage of this is that this dedicated percolator index\ncan have its own index settings (For example the number of primary and replica shards). If you choose to have a dedicated\npercolate index, you need to make sure that the mappings from the normal index are also available on the percolate index.\nOtherwise percolate queries can be parsed incorrectly.\n\n[discrete]\n==== Forcing Unmapped Fields to be Handled as Strings\n\nIn certain cases it is unknown what kind of percolator queries do get registered, and if no field mapping exists for fields\nthat are referred by percolator queries then adding a percolator query fails. This means the mapping needs to be updated\nto have the field with the appropriate settings, and then the percolator query can be added. But sometimes it is sufficient\nif all unmapped fields are handled as if these were default text fields. In those cases one can configure the\n`index.percolator.map_unmapped_fields_as_text` setting to `true` (default to `false`) and then if a field referred in\na percolator query does not exist, it will be handled as a default text field so that adding the percolator query doesn't\nfail.\n\n[discrete]\n==== Limitations\n\n[discrete]\n[[parent-child]]\n===== Parent/child\n\nBecause the `percolate` query is processing one document at a time, it doesn't support queries and filters that run\nagainst child documents such as `has_child` and `has_parent`.\n\n[discrete]\n===== Fetching queries\n\nThere are a number of queries that fetch data via a get call during query parsing. For example the `terms` query when\nusing terms lookup, `template` query when using indexed scripts and `geo_shape` when using pre-indexed shapes. When these\nqueries are indexed by the `percolator` field type then the get call is executed once. So each time the `percolator`\nquery evaluates these queries, the fetches terms, shapes etc. as the were upon index time will be used. Important to note\nis that fetching of terms that these queries do, happens both each time the percolator query gets indexed on both primary\nand replica shards, so the terms that are actually indexed can be different between shard copies, if the source index\nchanged while indexing.\n\n[discrete]\n===== Script query\n\nThe script inside a `script` query can only access doc values fields. The `percolate` query indexes the provided document\ninto an in-memory index. This in-memory index doesn't support stored fields and because of that the `_source` field and\nother stored fields are not stored. This is the reason why in the `script` query the `_source` and other stored fields\naren't available.\n\n[discrete]\n===== Field aliases\n\nPercolator queries that contain <<field-alias, field aliases>> may not always behave as expected. In particular, if a\npercolator query is registered that contains a field alias, and then that alias is updated in the mappings to refer\nto a different field, the stored query will still refer to the original target field. To pick up the change to\nthe field alias, the percolator query must be explicitly reindexed.\n"
}
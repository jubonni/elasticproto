{
    "meta": {
        "timestamp": "2024-11-01T03:02:53.494596",
        "size": 4054,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-service-hugging-face.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "infer-service-hugging-face",
        "version": "8.15"
    },
    "doc": "[[infer-service-hugging-face]]\n=== HuggingFace {infer} service\n\nCreates an {infer} endpoint to perform an {infer} task with the `hugging_face` service.\n\n\n[discrete]\n[[infer-service-hugging-face-api-request]]\n==== {api-request-title}\n\n`PUT /_inference/<task_type>/<inference_id>`\n\n[discrete]\n[[infer-service-hugging-face-api-path-params]]\n==== {api-path-parms-title}\n\n`<inference_id>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=inference-id]\n\n`<task_type>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=task-type]\n+\n--\nAvailable task types:\n\n* `text_embedding`.\n--\n\n[discrete]\n[[infer-service-hugging-face-api-request-body]]\n==== {api-request-body-title}\n\n`chunking_settings`::\n(Optional, object)\ninclude::inference-shared.asciidoc[tag=chunking-settings]\n\n`max_chunking_size`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-max-chunking-size]\n\n`overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-overlap]\n\n`sentence_overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-sentence-overlap]\n\n`strategy`:::\n(Optional, string)\ninclude::inference-shared.asciidoc[tag=chunking-settings-strategy]\n\n`service`::\n(Required, string)\nThe type of service supported for the specified task type. In this case, \n`hugging_face`.\n\n`service_settings`::\n(Required, object)\ninclude::inference-shared.asciidoc[tag=service-settings]\n+\n--\nThese settings are specific to the `hugging_face` service.\n--\n\n`api_key`:::\n(Required, string)\nA valid access token of your Hugging Face account.\nYou can find your Hugging Face access tokens or you can create a new one\nhttps://huggingface.co/settings/tokens[on the settings page].\n+\n--\ninclude::inference-shared.asciidoc[tag=api-key-admonition]\n--\n\n`url`:::\n(Required, string)\nThe URL endpoint to use for the requests.\n\n`rate_limit`:::\n(Optional, object)\nBy default, the `huggingface` service sets the number of requests allowed per minute to `3000`.\nThis helps to minimize the number of rate limit errors returned from Hugging Face.\nTo modify this, set the `requests_per_minute` setting of this object in your service settings:\n+\n--\ninclude::inference-shared.asciidoc[tag=request-per-minute-example]\n--\n\n\n[discrete]\n[[inference-example-hugging-face]]\n==== Hugging Face service example\n\nThe following example shows how to create an {infer} endpoint called\n`hugging-face-embeddings` to perform a `text_embedding` task type.\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/text_embedding/hugging-face-embeddings\n{\n  \"service\": \"hugging_face\",\n  \"service_settings\": {\n    \"api_key\": \"<access_token>\", <1>\n    \"url\": \"<url_endpoint>\" <2>\n  }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n<1> A valid Hugging Face access token.\nYou can find on the\nhttps://huggingface.co/settings/tokens[settings page of your account].\n<2> The {infer} endpoint URL you created on Hugging Face.\n\nCreate a new {infer} endpoint on\nhttps://ui.endpoints.huggingface.co/[the Hugging Face endpoint page] to get an endpoint URL.\nSelect the model you want to use on the new endpoint creation page - for example `intfloat/e5-small-v2` - then select the `Sentence Embeddings`\ntask under the Advanced configuration section.\nCreate the endpoint.\nCopy the URL after the endpoint initialization has been finished.\n\n[discrete]\n[[inference-example-hugging-face-supported-models]]\nThe list of recommended models for the Hugging Face service:\n\n* https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2[all-MiniLM-L6-v2]\n* https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2[all-MiniLM-L12-v2]\n* https://huggingface.co/sentence-transformers/all-mpnet-base-v2[all-mpnet-base-v2]\n* https://huggingface.co/intfloat/e5-base-v2[e5-base-v2]\n* https://huggingface.co/intfloat/e5-small-v2[e5-small-v2]\n* https://huggingface.co/intfloat/multilingual-e5-base[multilingual-e5-base]\n* https://huggingface.co/intfloat/multilingual-e5-small[multilingual-e5-small]"
}
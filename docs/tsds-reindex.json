{
    "meta": {
        "timestamp": "2024-11-01T03:07:10.472271",
        "size": 8178,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/tsds-reindex.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "tsds-reindex",
        "version": "8.15"
    },
    "doc": "[[tsds-reindex]]\n=== Reindex a time series data stream (TSDS)\n\n++++\n<titleabbrev>Reindex a TSDS</titleabbrev>\n++++\n\n[discrete]\n[[tsds-reindex-intro]]\n==== Introduction\n\nWith reindexing, you can copy documents from an old <<tsds,time-series data stream (TSDS)>> to a new one. Data streams support\nreindexing in general, with a few <<reindex-with-a-data-stream, restrictions>>. Still, time-series data streams\nintroduce additional challenges due to tight control on the accepted timestamp range for each backing index they\ncontain. Direct use of the reindex API would likely error out due to attempting to insert documents with timestamps that are\noutside the current acceptance window.\n\nTo avoid these limitations, use the process that is outlined below:\n\n. Create an index template for the destination data stream that will contain the re-indexed data.\n. Update the template to\n.. Set `index.time_series.start_time` and `index.time_series.end_time` index settings to\nmatch the lowest and highest `@timestamp` values in the old data stream.\n.. Set the `index.number_of_shards` index setting to the sum of all primary shards of all backing\nindices of the old data stream.\n.. Set `index.number_of_replicas` to zero and unset the `index.lifecycle.name` index setting.\n. Run the reindex operation to completion.\n. Revert the overriden index settings in the destination index template.\n. Invoke the `rollover` api to create a new backing index that can receive new documents.\n\nNOTE: This process only applies to time-series data streams without <<downsampling, downsampling>> configuration. Data\nstreams with downsampling can only be re-indexed by re-indexing their backing indexes individually and adding them to an\nempty destination data stream.\n\nIn what follows, we elaborate on each step of the process with examples.\n\n[discrete]\n[[tsds-reindex-create-template]]\n==== Create a TSDS template to accept old documents\n\nConsider a TSDS with the following template:\n\n[source,console]\n----\nPOST /_component_template/source_template\n{\n  \"template\": {\n    \"settings\": {\n      \"index\": {\n        \"number_of_replicas\": 2,\n        \"number_of_shards\": 2,\n        \"mode\": \"time_series\",\n        \"routing_path\": [ \"metricset\" ]\n      }\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"@timestamp\": { \"type\": \"date\" },\n        \"metricset\": {\n          \"type\": \"keyword\",\n          \"time_series_dimension\": true\n        },\n        \"k8s\": {\n          \"properties\": {\n            \"tx\": { \"type\": \"long\" },\n            \"rx\": { \"type\": \"long\" }\n          }\n        }\n      }\n    }\n  }\n}\n\nPOST /_index_template/1\n{\n  \"index_patterns\": [\n    \"k8s*\"\n  ],\n  \"composed_of\": [\n    \"source_template\"\n  ],\n  \"data_stream\": {}\n}\n----\n// TEST[skip: not expected to match the sample below]\n\nA possible output of `/k8s/_settings` looks like:\n\n[source,console-result]\n----\n\n{\n  \".ds-k8s-2023.09.01-000002\": {\n    \"settings\": {\n      \"index\": {\n        \"mode\": \"time_series\",\n        \"routing\": {\n          \"allocation\": {\n            \"include\": {\n              \"_tier_preference\": \"data_hot\"\n            }\n          }\n        },\n        \"hidden\": \"true\",\n        \"number_of_shards\": \"2\",\n        \"time_series\": {\n          \"end_time\": \"2023-09-01T14:00:00.000Z\",\n          \"start_time\": \"2023-09-01T10:00:00.000Z\"\n        },\n        \"provided_name\": \".ds-k9s-2023.09.01-000002\",\n        \"creation_date\": \"1694439857608\",\n        \"number_of_replicas\": \"2\",\n        \"routing_path\": [\n          \"metricset\"\n        ],\n        ...\n      }\n    }\n  },\n  \".ds-k8s-2023.09.01-000001\": {\n    \"settings\": {\n      \"index\": {\n        \"mode\": \"time_series\",\n        \"routing\": {\n          \"allocation\": {\n            \"include\": {\n              \"_tier_preference\": \"data_hot\"\n            }\n          }\n        },\n        \"hidden\": \"true\",\n        \"number_of_shards\": \"2\",\n        \"time_series\": {\n          \"end_time\": \"2023-09-01T10:00:00.000Z\",\n          \"start_time\": \"2023-09-01T06:00:00.000Z\"\n        },\n        \"provided_name\": \".ds-k9s-2023.09.01-000001\",\n        \"creation_date\": \"1694439837126\",\n        \"number_of_replicas\": \"2\",\n        \"routing_path\": [\n          \"metricset\"\n        ],\n        ...\n      }\n    }\n  }\n}\n----\n// NOTCONSOLE\n\nTo reindex this TSDS, do not to re-use its index template in the destination data stream, to avoid impacting its\nfunctionality. Instead, clone the template of the source TSDS and apply the following modifications:\n\n* Set `index.time_series.start_time` and `index.time_series.end_time` index settings explicitly. Their values should be\nbased on the lowest and highest `@timestamp` values in the data stream to reindex. This way, the initial backing index can\nload all data that is contained in the source data stream.\n* Set `index.number_of_shards` index setting to the sum of all primary shards of all backing indices of the source data\nstream. This helps maintain the same level of search parallelism, as each shard is processed in a separate thread (or\nmore).\n* Unset the `index.lifecycle.name` index setting, if any. This prevents ILM from modifying the destination data stream\nduring reindexing.\n* (Optional) Set `index.number_of_replicas` to zero. This helps speed up the reindex operation. Since the data gets\ncopied, there is limited risk of data loss due to lack of replicas.\n\nUsing the example above as source TSDS, the template for the destination TSDS would be:\n\n[source,console]\n----\nPOST /_component_template/destination_template\n{\n  \"template\": {\n    \"settings\": {\n      \"index\": {\n        \"number_of_replicas\": 0,\n        \"number_of_shards\": 4,\n        \"mode\": \"time_series\",\n        \"routing_path\": [ \"metricset\" ],\n        \"time_series\": {\n          \"end_time\": \"2023-09-01T14:00:00.000Z\",\n          \"start_time\": \"2023-09-01T06:00:00.000Z\"\n        }\n      }\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"@timestamp\": { \"type\": \"date\" },\n        \"metricset\": {\n          \"type\": \"keyword\",\n          \"time_series_dimension\": true\n        },\n        \"k8s\": {\n          \"properties\": {\n            \"tx\": { \"type\": \"long\" },\n            \"rx\": { \"type\": \"long\" }\n          }\n        }\n      }\n    }\n  }\n}\n\nPOST /_index_template/2\n{\n  \"index_patterns\": [\n    \"k8s*\"\n  ],\n  \"composed_of\": [\n    \"destination_template\"\n  ],\n  \"data_stream\": {}\n}\n----\n// TEST[continued]\n\n[discrete]\n[[tsds-reindex-op]]\n==== Reindex\n\nInvoke the reindex api, for instance:\n\n[source,console]\n----\nPOST /_reindex\n{\n  \"source\": {\n    \"index\": \"k8s\"\n  },\n  \"dest\": {\n    \"index\": \"k9s\",\n    \"op_type\": \"create\"\n  }\n}\n----\n// TEST[continued]\n\n[discrete]\n[[tsds-reindex-restore]]\n==== Restore the destination index template\n\nOnce the reindexing operation completes, restore the index template for the destination TSDS as follows:\n\n* Remove the overrides for `index.time_series.start_time` and `index.time_series.end_time`.\n* Restore the values of `index.number_of_shards`, `index.number_of_replicas`  and  `index.lifecycle.name` as\napplicable.\n\nUsing the previous example, the destination template is modified as follows:\n\n[source,console]\n----\nPOST /_component_template/destination_template\n{\n  \"template\": {\n    \"settings\": {\n      \"index\": {\n        \"number_of_replicas\": 2,\n        \"number_of_shards\": 2,\n        \"mode\": \"time_series\",\n        \"routing_path\": [ \"metricset\" ]\n      }\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"@timestamp\": { \"type\": \"date\" },\n        \"metricset\": {\n          \"type\": \"keyword\",\n          \"time_series_dimension\": true\n        },\n        \"k8s\": {\n          \"properties\": {\n            \"tx\": { \"type\": \"long\" },\n            \"rx\": { \"type\": \"long\" }\n          }\n        }\n      }\n    }\n  }\n}\n----\n// TEST[continued]\n\nNext, Invoke the `rollover` api on the destination data stream without any conditions set.\n\n[source,console]\n----\nPOST /k9s/_rollover/\n----\n// TEST[continued]\n\nThis creates a new backing index with the updated index settings. The destination data stream is now ready to accept new documents.\n\nNote that the initial backing index can still accept documents within the range of timestamps derived from the source data\nstream. If this is not desired, mark it as <<index-blocks-read-only, read-only>> explicitly.\n"
}
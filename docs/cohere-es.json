{
    "meta": {
        "size": 11635,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/cohere-es.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "cohere-es",
        "version": "8.15"
    },
    "doc": "[[cohere-es]]\n=== Tutorial: Using Cohere with {es}\n++++\n<titleabbrev>Using Cohere with {es}</titleabbrev>\n++++\n\nThe instructions in this tutorial shows you how to compute embeddings with\nCohere using the {infer} API and store them for efficient vector or hybrid\nsearch in {es}. This tutorial will use the Python {es} client to perform the\noperations.\n\nYou'll learn how to:\n\n* create an {infer} endpoint for text embedding using the Cohere service,\n* create the necessary index mapping for the {es} index,\n* build an {infer} pipeline to ingest documents into the index together with the\nembeddings,\n* perform hybrid search on the data,\n* rerank search results by using Cohere's rerank model,\n* design a RAG system with Cohere's Chat API.\n\nThe tutorial uses the https://huggingface.co/datasets/mteb/scifact[SciFact] data\nset.\n\nRefer to https://docs.cohere.com/docs/elasticsearch-and-cohere[Cohere's tutorial]\nfor an example using a different data set.\n\nYou can also review the https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/integrations/cohere/cohere-elasticsearch.ipynb[Colab notebook version of this tutorial].\n\n\n[discrete]\n[[cohere-es-req]]\n==== Requirements\n\n* A paid https://cohere.com/[Cohere account] is required to use the {infer-cap} API with the Cohere service as the Cohere free trial API usage is limited,\n* an https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html[Elastic Cloud] account,\n* Python 3.7 or higher.\n\n\n[discrete]\n[[cohere-es-packages]]\n==== Install required packages\n\nInstall {es} and Cohere:\n\n[source,py]\n------------------------------------------------------------\n!pip install elasticsearch\n!pip install cohere\n------------------------------------------------------------\n\nImport the required packages:\n\n[source,py]\n------------------------------------------------------------\nfrom elasticsearch import Elasticsearch, helpers\nimport cohere\nimport json\nimport requests\n------------------------------------------------------------\n\n[discrete]\n[[cohere-es-client]]\n==== Create the {es} client\n\nTo create your {es} client, you need:\n\n* https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id[your Cloud ID],\n* https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key[an encoded API key].\n\n[source,py]\n------------------------------------------------------------\nELASTICSEARCH_ENDPOINT = \"elastic_endpoint\"\nELASTIC_API_KEY = \"elastic_api_key\"\n\nclient = Elasticsearch(\n  cloud_id=ELASTICSEARCH_ENDPOINT,\n  api_key=ELASTIC_API_KEY\n)\n\n# Confirm the client has connected\nprint(client.info())\n------------------------------------------------------------\n\n\n[discrete]\n[[cohere-es-infer-endpoint]]\n==== Create the {infer} endpoint\n\n<<put-inference-api,Create the {infer} endpoint>> first. In this example, the\n{infer} endpoint uses Cohere's `embed-english-v3.0` model and the\n`embedding_type` is set to `byte`.\n\n[source,py]\n------------------------------------------------------------\nCOHERE_API_KEY = \"cohere_api_key\"\n\nclient.inference.put_model(\n    task_type=\"text_embedding\",\n    inference_id=\"cohere_embeddings\",\n    body={\n        \"service\": \"cohere\",\n        \"service_settings\": {\n            \"api_key\": COHERE_API_KEY,\n            \"model_id\": \"embed-english-v3.0\",\n            \"embedding_type\": \"byte\"\n        }\n    },\n)\n------------------------------------------------------------\n\nYou can find your API keys in your Cohere dashboard under the\nhttps://dashboard.cohere.com/api-keys[API keys section].\n\n\n[discrete]\n[[cohere-es-index-mapping]]\n==== Create the index mapping\n\nCreate the index mapping for the index that will contain the embeddings.\n\n[source,py]\n------------------------------------------------------------\nclient.indices.create(\n    index=\"cohere-embeddings\",\n    settings={\"index\": {\"default_pipeline\": \"cohere_embeddings\"}},\n    mappings={\n        \"properties\": {\n            \"text_embedding\": {\n                \"type\": \"dense_vector\",\n                \"dims\": 1024,\n                \"element_type\": \"byte\",\n            },\n            \"text\": {\"type\": \"text\"},\n            \"id\": {\"type\": \"integer\"},\n            \"title\": {\"type\": \"text\"}\n        }\n    },\n)\n------------------------------------------------------------\n\n\n[discrete]\n[[cohere-es-infer-pipeline]]\n==== Create the {infer} pipeline\n\nNow you have an {infer} endpoint and an index ready to store embeddings. The\nnext step is to create an <<ingest,ingest pipeline>> with an\n<<inference-processor,{infer} processor>> that will create the embeddings using\nthe {infer} endpoint and stores them in the index.\n\n[source,py]\n--------------------------------------------------\nclient.ingest.put_pipeline(\n    id=\"cohere_embeddings\",\n    description=\"Ingest pipeline for Cohere inference.\",\n    processors=[\n        {\n            \"inference\": {\n                \"model_id\": \"cohere_embeddings\",\n                \"input_output\": {\n                    \"input_field\": \"text\",\n                    \"output_field\": \"text_embedding\",\n                },\n            }\n        }\n    ],\n)\n--------------------------------------------------\n\n\n[discrete]\n[[cohere-es-insert-documents]]\n==== Prepare data and insert documents\n\nThis example uses the https://huggingface.co/datasets/mteb/scifact[SciFact] data\nset that you can find on HuggingFace.\n\n[source,py]\n--------------------------------------------------\nurl = 'https://huggingface.co/datasets/mteb/scifact/raw/main/corpus.jsonl'\n\n# Fetch the JSONL data from the URL\nresponse = requests.get(url)\nresponse.raise_for_status()  # Ensure noticing bad responses\n\n# Split the content by new lines and parse each line as JSON\ndata = [json.loads(line) for line in response.text.strip().split('\\n') if line]\n# Now data is a list of dictionaries\n\n# Change `_id` key to `id` as `_id` is a reserved key in Elasticsearch.\nfor item in data:\n    if '_id' in item:\n        item['id'] = item.pop('_id')\n\n# Prepare the documents to be indexed\ndocuments = []\nfor line in data:\n    data_dict = line\n    documents.append({\n        \"_index\": \"cohere-embeddings\",\n        \"_source\": data_dict,\n        }\n      )\n\n# Use the bulk endpoint to index\nhelpers.bulk(client, documents)\n\nprint(\"Data ingestion completed, text embeddings generated!\")\n--------------------------------------------------\n\nYour index is populated with the SciFact data and text embeddings for the text\nfield.\n\n\n[discrete]\n[[cohere-es-hybrid-search]]\n==== Hybrid search\n\nLet's start querying the index!\n\nThe code below performs a hybrid search. The `kNN` query computes the relevance\nof search results based on vector similarity using the `text_embedding` field,\nthe lexical search query uses BM25 retrieval to compute keyword similarity on\nthe `title` and `text` fields.\n\n[source,py]\n--------------------------------------------------\nquery = \"What is biosimilarity?\"\n\nresponse = client.search(\n    index=\"cohere-embeddings\",\n    size=100,\n    knn={\n        \"field\": \"text_embedding\",\n        \"query_vector_builder\": {\n            \"text_embedding\": {\n                \"model_id\": \"cohere_embeddings\",\n                \"model_text\": query,\n            }\n        },\n        \"k\": 10,\n        \"num_candidates\": 50,\n    },\n    query={\n        \"multi_match\": {\n            \"query\": query,\n            \"fields\": [\"text\", \"title\"]\n        }\n    }\n)\n\nraw_documents = response[\"hits\"][\"hits\"]\n\n# Display the first 10 results\nfor document in raw_documents[0:10]:\n  print(f'Title: {document[\"_source\"][\"title\"]}\\nText: {document[\"_source\"][\"text\"]}\\n')\n\n# Format the documents for ranking\ndocuments = []\nfor hit in response[\"hits\"][\"hits\"]:\n    documents.append(hit[\"_source\"][\"text\"])\n--------------------------------------------------\n\n\n[discrete]\n[[cohere-es-rerank-results]]\n===== Rerank search results\n\nTo combine the results more effectively, use \nhttps://docs.cohere.com/docs/rerank-2[Cohere's Rerank v3] model through the\n{infer} API to provide a more precise semantic reranking of the results.\n\nCreate an {infer} endpoint with your Cohere API key and the used model name as\nthe `model_id` (`rerank-english-v3.0` in this example).\n\n[source,py]\n--------------------------------------------------\nclient.inference.put_model(\n    task_type=\"rerank\",\n    inference_id=\"cohere_rerank\",\n    body={\n        \"service\": \"cohere\",\n        \"service_settings\":{\n            \"api_key\": COHERE_API_KEY,\n            \"model_id\": \"rerank-english-v3.0\"\n           },\n        \"task_settings\": {\n            \"top_n\": 10,\n        },\n    }\n)\n--------------------------------------------------\n\nRerank the results using the new {infer} endpoint.\n\n[source,py]\n--------------------------------------------------\n# Pass the query and the search results to the service\nresponse = client.inference.inference(\n    inference_id=\"cohere_rerank\",\n    body={\n        \"query\": query,\n        \"input\": documents,\n        \"task_settings\": {\n            \"return_documents\": False\n            }\n        }\n)\n\n# Reconstruct the input documents based on the index provided in the rereank response\nranked_documents = []\nfor document in response.body[\"rerank\"]:\n  ranked_documents.append({\n      \"title\": raw_documents[int(document[\"index\"])][\"_source\"][\"title\"],\n      \"text\": raw_documents[int(document[\"index\"])][\"_source\"][\"text\"]\n  })\n\n# Print the top 10 results\nfor document in ranked_documents[0:10]:\n  print(f\"Title: {document['title']}\\nText: {document['text']}\\n\")\n--------------------------------------------------\n\nThe response is a list of documents in descending order of relevance. Each\ndocument has a corresponding index that reflects the order of the documents when \nthey were sent to the {infer} endpoint.\n\n\n[discrete]\n[[cohere-es-rag]]\n==== Retrieval Augmented Generation (RAG) with Cohere and {es}\n\nhttps://docs.cohere.com/docs/retrieval-augmented-generation-rag[RAG] is a method for generating text using additional information fetched from an external data source.\nWith the ranked results, you can build a RAG system on the top of what you previously created by using https://docs.cohere.com/docs/chat-api[Cohere's Chat API].\n\nPass in the retrieved documents and the query to receive a grounded response using Cohere's newest generative model https://docs.cohere.com/docs/command-r-plus[Command R+].\n\nThen pass in the query and the documents to the Chat API, and print out the response. \n\n[source,py]\n--------------------------------------------------\nresponse = co.chat(message=query, documents=ranked_documents, model='command-r-plus')\n\nsource_documents = []\nfor citation in response.citations:\n    for document_id in citation.document_ids:\n        if document_id not in source_documents:\n            source_documents.append(document_id)\n\nprint(f\"Query: {query}\")\nprint(f\"Response: {response.text}\")\nprint(\"Sources:\")\nfor document in response.documents:\n    if document['id'] in source_documents:\n        print(f\"{document['title']}: {document['text']}\")\n\n--------------------------------------------------\n\nThe response will look similar to this:\n\n[source,consol-result]\n--------------------------------------------------\nQuery: What is biosimilarity?\nResponse: Biosimilarity is based on the comparability concept, which has been used successfully for several decades to ensure close similarity of a biological product before and after a manufacturing change. Over the last 10 years, experience with biosimilars has shown that even complex biotechnology-derived proteins can be copied successfully.\nSources:\nInterchangeability of Biosimilars: A European Perspective: (...)\n--------------------------------------------------\n// NOTCONSOLE\n"
}
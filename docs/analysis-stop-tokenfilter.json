{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.549067",
        "size": 9274,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-stop-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-stop-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-stop-tokenfilter]]\n=== Stop token filter\n++++\n<titleabbrev>Stop</titleabbrev>\n++++\n\nRemoves {wikipedia}/Stop_words[stop words] from a token\nstream.\n\nWhen not customized, the filter removes the following English stop words by\ndefault:\n\n`a`, `an`, `and`, `are`, `as`, `at`, `be`, `but`, `by`, `for`, `if`, `in`,\n`into`, `is`, `it`, `no`, `not`, `of`, `on`, `or`, `such`, `that`, `the`,\n`their`, `then`, `there`, `these`, `they`, `this`, `to`, `was`, `will`, `with`\n\nIn addition to English, the `stop` filter supports predefined\n<<analysis-stop-tokenfilter-stop-words-by-lang,stop word lists for several\nlanguages>>. You can also specify your own stop words as an array or file.\n\nThe `stop` filter uses Lucene's\n{lucene-analysis-docs}/core/StopFilter.html[StopFilter].\n\n[[analysis-stop-tokenfilter-analyze-ex]]\n==== Example\n\nThe following analyze API request uses the `stop` filter to remove the stop words\n`a` and `the` from `a quick fox jumps over the lazy dog`:\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [ \"stop\" ],\n  \"text\": \"a quick fox jumps over the lazy dog\"\n}\n----\n\nThe filter produces the following tokens:\n\n[source,text]\n----\n[ quick, fox, jumps, over, lazy, dog ]\n----\n\n////\n[source,console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 2,\n      \"end_offset\": 7,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 8,\n      \"end_offset\": 11,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"jumps\",\n      \"start_offset\": 12,\n      \"end_offset\": 17,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"over\",\n      \"start_offset\": 18,\n      \"end_offset\": 22,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 4\n    },\n    {\n      \"token\": \"lazy\",\n      \"start_offset\": 27,\n      \"end_offset\": 31,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 6\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 32,\n      \"end_offset\": 35,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 7\n    }\n  ]\n}\n----\n////\n\n[[analysis-stop-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the `stop`\nfilter to configure a new <<analysis-custom-analyzer,custom analyzer>>.\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"stop\" ]\n        }\n      }\n    }\n  }\n}\n----\n\n[[analysis-stop-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`stopwords`::\n+\n--\n(Optional, string or array of strings)\nLanguage value, such as `_arabic_` or `_thai_`. Defaults to\n<<english-stop-words,`_english_`>>.\n\nEach language value corresponds to a predefined list of stop words in Lucene.\nSee <<analysis-stop-tokenfilter-stop-words-by-lang>> for supported language\nvalues and their stop words.\n\nAlso accepts an array of stop words.\n\nFor an empty list of stop words, use `_none_`.\n--\n\n`stopwords_path`::\n+\n--\n(Optional, string)\nPath to a file that contains a list of stop words to remove.\n\nThis path must be absolute or relative to the `config` location, and the file\nmust be UTF-8 encoded. Each stop word in the file must be separated by a line\nbreak.\n--\n\n`ignore_case`::\n(Optional, Boolean)\nIf `true`, stop word matching is case insensitive. For example, if `true`, a\nstop word of `the` matches and removes `The`, `THE`, or `the`. Defaults to\n`false`.\n\n`remove_trailing`::\n+\n--\n(Optional, Boolean)\nIf `true`, the last token of a stream is removed if it's a stop word. Defaults\nto `true`.\n\nThis parameter should be `false` when using the filter with a\n<<completion-suggester,completion suggester>>. This would ensure a query like\n`green a` matches and suggests `green apple` while still removing other stop\nwords.\n--\n\n[[analysis-stop-tokenfilter-customize]]\n==== Customize\n\nTo customize the `stop` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following request creates a custom case-insensitive `stop`\nfilter that removes stop words from the <<english-stop-words,`_english_`>> stop\nwords list:\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"my_custom_stop_words_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_stop_words_filter\": {\n          \"type\": \"stop\",\n          \"ignore_case\": true\n        }\n      }\n    }\n  }\n}\n----\n\nYou can also specify your own list of stop words. For example, the following\nrequest creates a custom case-insensitive `stop` filter that removes only the stop\nwords `and`, `is`, and `the`:\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"default\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"my_custom_stop_words_filter\" ]\n        }\n      },\n      \"filter\": {\n        \"my_custom_stop_words_filter\": {\n          \"type\": \"stop\",\n          \"ignore_case\": true,\n          \"stopwords\": [ \"and\", \"is\", \"the\" ]\n        }\n      }\n    }\n  }\n}\n----\n\n[[analysis-stop-tokenfilter-stop-words-by-lang]]\n==== Stop words by language\n\nThe following list contains supported language values for the `stopwords`\nparameter and a link to their predefined stop words in Lucene.\n\n[[arabic-stop-words]]\n`_arabic_`::\n{lucene-stop-word-link}/ar/stopwords.txt[Arabic stop words]\n\n[[armenian-stop-words]]\n`_armenian_`::\n{lucene-stop-word-link}/hy/stopwords.txt[Armenian stop words]\n\n[[basque-stop-words]]\n`_basque_`::\n{lucene-stop-word-link}/eu/stopwords.txt[Basque stop words]\n\n[[bengali-stop-words]]\n`_bengali_`::\n{lucene-stop-word-link}/bn/stopwords.txt[Bengali stop words]\n\n[[brazilian-stop-words]]\n`_brazilian_` (Brazilian Portuguese)::\n{lucene-stop-word-link}/br/stopwords.txt[Brazilian Portuguese stop words]\n\n[[bulgarian-stop-words]]\n`_bulgarian_`::\n{lucene-stop-word-link}/bg/stopwords.txt[Bulgarian stop words]\n\n[[catalan-stop-words]]\n`_catalan_`::\n{lucene-stop-word-link}/ca/stopwords.txt[Catalan stop words]\n\n[[cjk-stop-words]]\n`_cjk_` (Chinese, Japanese, and Korean)::\n{lucene-stop-word-link}/cjk/stopwords.txt[CJK stop words]\n\n[[czech-stop-words]]\n`_czech_`::\n{lucene-stop-word-link}/cz/stopwords.txt[Czech stop words]\n\n[[danish-stop-words]]\n`_danish_`::\n{lucene-stop-word-link}/snowball/danish_stop.txt[Danish stop words]\n\n[[dutch-stop-words]]\n`_dutch_`::\n{lucene-stop-word-link}/snowball/dutch_stop.txt[Dutch stop words]\n\n[[english-stop-words]]\n`_english_`::\n{lucene-gh-main-link}/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java#L48[English stop words]\n\n[[estonian-stop-words]]\n`_estonian_`::\n{lucene-stop-word-link}/et/stopwords.txt[Estonian stop words]\n\n[[finnish-stop-words]]\n`_finnish_`::\n{lucene-stop-word-link}/snowball/finnish_stop.txt[Finnish stop words]\n\n[[french-stop-words]]\n`_french_`::\n{lucene-stop-word-link}/snowball/french_stop.txt[French stop words]\n\n[[galician-stop-words]]\n`_galician_`::\n{lucene-stop-word-link}/gl/stopwords.txt[Galician stop words]\n\n[[german-stop-words]]\n`_german_`::\n{lucene-stop-word-link}/snowball/german_stop.txt[German stop words]\n\n[[greek-stop-words]]\n`_greek_`::\n{lucene-stop-word-link}/el/stopwords.txt[Greek stop words]\n\n[[hindi-stop-words]]\n`_hindi_`::\n{lucene-stop-word-link}/hi/stopwords.txt[Hindi stop words]\n\n[[hungarian-stop-words]]\n`_hungarian_`::\n{lucene-stop-word-link}/snowball/hungarian_stop.txt[Hungarian stop words]\n\n[[indonesian-stop-words]]\n`_indonesian_`::\n{lucene-stop-word-link}/id/stopwords.txt[Indonesian stop words]\n\n[[irish-stop-words]]\n`_irish_`::\n{lucene-stop-word-link}/ga/stopwords.txt[Irish stop words]\n\n[[italian-stop-words]]\n`_italian_`::\n{lucene-stop-word-link}/snowball/italian_stop.txt[Italian stop words]\n\n[[latvian-stop-words]]\n`_latvian_`::\n{lucene-stop-word-link}/lv/stopwords.txt[Latvian stop words]\n\n[[lithuanian-stop-words]]\n`_lithuanian_`::\n{lucene-stop-word-link}/lt/stopwords.txt[Lithuanian stop words]\n\n[[norwegian-stop-words]]\n`_norwegian_`::\n{lucene-stop-word-link}/snowball/norwegian_stop.txt[Norwegian stop words]\n\n[[persian-stop-words]]\n`_persian_`::\n{lucene-stop-word-link}/fa/stopwords.txt[Persian stop words]\n\n[[portuguese-stop-words]]\n`_portuguese_`::\n{lucene-stop-word-link}/snowball/portuguese_stop.txt[Portuguese stop words]\n\n[[romanian-stop-words]]\n`_romanian_`::\n{lucene-stop-word-link}/ro/stopwords.txt[Romanian stop words]\n\n[[russian-stop-words]]\n`_russian_`::\n{lucene-stop-word-link}/snowball/russian_stop.txt[Russian stop words]\n\n[[serbian-stop-words]]\n`_serbian_`::\n{lucene-stop-word-link}/sr/stopwords.txt[Serbian stop words]\n\n[[sorani-stop-words]]\n`_sorani_`::\n{lucene-stop-word-link}/ckb/stopwords.txt[Sorani stop words]\n\n[[spanish-stop-words]]\n`_spanish_`::\n{lucene-stop-word-link}/snowball/spanish_stop.txt[Spanish stop words]\n\n[[swedish-stop-words]]\n`_swedish_`::\n{lucene-stop-word-link}/snowball/swedish_stop.txt[Swedish stop words]\n\n[[thai-stop-words]]\n`_thai_`::\n{lucene-stop-word-link}/th/stopwords.txt[Thai stop words]\n\n[[turkish-stop-words]]\n`_turkish_`::\n{lucene-stop-word-link}/tr/stopwords.txt[Turkish stop words]\n"
}
{
    "meta": {
        "size": 2429,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-trim-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-trim-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-trim-tokenfilter]]\n=== Trim token filter\n++++\n<titleabbrev>Trim</titleabbrev>\n++++\n\nRemoves leading and trailing whitespace from each token in a stream. While this\ncan change the length of a token, the `trim` filter does _not_ change a token's\noffsets.\n\nThe `trim` filter uses Lucene's\nhttps://lucene.apache.org/core/{lucene_version_path}/analysis/common/org/apache/lucene/analysis/miscellaneous/TrimFilter.html[TrimFilter].\n\n[TIP]\n====\nMany commonly used tokenizers, such as the\n<<analysis-standard-tokenizer,`standard`>> or\n<<analysis-whitespace-tokenizer,`whitespace`>> tokenizer, remove whitespace by\ndefault. When using these tokenizers, you don't need to add a separate `trim`\nfilter.\n====\n\n[[analysis-trim-tokenfilter-analyze-ex]]\n==== Example\n\nTo see how the `trim` filter works, you first need to produce a token\ncontaining whitespace.\n\nThe following <<indices-analyze,analyze API>> request uses the\n<<analysis-keyword-tokenizer,`keyword`>> tokenizer to produce a token for \n`\" fox \"`.\n\n[source,console]\n----\nGET _analyze\n{\n  \"tokenizer\" : \"keyword\",\n  \"text\" : \" fox \"\n}\n----\n\nThe API returns the following response. Note the `\" fox \"` token contains the\noriginal text's whitespace. Note that despite changing the token's length, the\n`start_offset` and `end_offset` remain the same.\n\n[source,console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \" fox \",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"word\",\n      \"position\": 0\n    }\n  ]\n}\n----\n\nTo remove the whitespace, add the `trim` filter to the previous analyze API\nrequest.\n\n[source,console]\n----\nGET _analyze\n{\n  \"tokenizer\" : \"keyword\",\n  \"filter\" : [\"trim\"],\n  \"text\" : \" fox \"\n}\n----\n\nThe API returns the following response. The returned `fox` token does not\ninclude any leading or trailing whitespace.\n\n[source,console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"word\",\n      \"position\": 0\n    }\n  ]\n}\n----\n\n[[analysis-trim-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the `trim`\nfilter to configure a new <<analysis-custom-analyzer,custom analyzer>>.\n\n[source,console]\n----\nPUT trim_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"keyword_trim\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": [ \"trim\" ]\n        }\n      }\n    }\n  }\n}\n----\n"
}
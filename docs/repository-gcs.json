{
    "meta": {
        "size": 11996,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/repository-gcs.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "repository-gcs",
        "version": "8.15"
    },
    "doc": "[[repository-gcs]]\n=== Google Cloud Storage repository\n\nYou can use the https://cloud.google.com/storage/[Google Cloud Storage]\nservice as a repository for {ref}/snapshot-restore.html[Snapshot/Restore].\n\n[[repository-gcs-usage]]\n==== Getting started\n\nThis repository type uses the https://github.com/GoogleCloudPlatform/google-cloud-java/tree/master/google-cloud-clients/google-cloud-storage[Google Cloud Java Client for Storage]\nto connect to the Storage service. If you are using\nhttps://cloud.google.com/storage/[Google Cloud Storage] for the first time, you\nmust connect to the https://console.cloud.google.com/[Google Cloud Platform Console]\nand create a new project. After your project is created, you must enable the\nCloud Storage Service for your project.\n\n[[repository-gcs-creating-bucket]]\n===== Creating a bucket\n\nThe Google Cloud Storage service uses the concept of a\nhttps://cloud.google.com/storage/docs/key-terms[bucket] as a container for all\nthe data. Buckets are usually created using the\nhttps://console.cloud.google.com/[Google Cloud Platform Console]. This\nrepository type does not automatically create buckets.\n\nTo create a new bucket:\n\n1. Connect to the https://console.cloud.google.com/[Google Cloud Platform Console].\n2. Select your project.\n3. Go to the https://console.cloud.google.com/storage/browser[Storage Browser].\n4. Click the *Create Bucket* button.\n5. Enter the name of the new bucket.\n6. Select a storage class.\n7. Select a location.\n8. Click the *Create* button.\n\nFor more detailed instructions, see the\nhttps://cloud.google.com/storage/docs/quickstart-console#create_a_bucket[Google Cloud documentation].\n\n[[repository-gcs-service-authentication]]\n===== Service authentication\n\nThe repository must authenticate the requests it makes to the Google Cloud Storage\nservice. It is common for Google client libraries to employ a strategy named https://cloud.google.com/docs/authentication/production#providing_credentials_to_your_application[application default credentials].\nHowever, that strategy is only **partially supported** by Elasticsearch. The\nrepository operates under the Elasticsearch process, which runs with the security\nmanager enabled. The security manager obstructs the \"automatic\" credential discovery\nwhen the environment variable `GOOGLE_APPLICATION_CREDENTIALS` is used to point to a\nlocal file on disk. It can, however, retrieve the service account that is attached to\nthe resource that is running Elasticsearch, or fall back to the default service\naccount that Compute Engine, Kubernetes Engine or App Engine provide.\nAlternatively, you must configure <<repository-gcs-using-service-account,service account>>\ncredentials if you are using an environment that does not support automatic\ncredential discovery.\n\n[[repository-gcs-using-service-account]]\n===== Using a service account\nYou have to obtain and provide https://cloud.google.com/iam/docs/overview#service_account[service account credentials]\nmanually.\n\nFor detailed information about generating JSON service account files, see the https://cloud.google.com/storage/docs/authentication?hl=en#service_accounts[Google Cloud documentation].\nNote that the PKCS12 format is not supported by this repository type.\n\nHere is a summary of the steps:\n\n1. Connect to the https://console.cloud.google.com/[Google Cloud Platform Console].\n2. Select your project.\n3. Select the https://console.cloud.google.com/iam-admin/serviceaccounts[Service Accounts] tab.\n4. Click *Create service account*.\n5. After the account is created, select it and go to *Keys*.\n6. Select *Add Key* and then *Create new key*.\n7. Select Key Type *JSON* as P12 is unsupported.\n\nA JSON service account file looks like this:\n\n[source,js]\n----\n{\n  \"type\": \"service_account\",\n  \"project_id\": \"your-project-id\",\n  \"private_key_id\": \"...\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"service-account-for-your-repository@your-project-id.iam.gserviceaccount.com\",\n  \"client_id\": \"...\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/your-bucket@your-project-id.iam.gserviceaccount.com\"\n}\n----\n// NOTCONSOLE\n\nTo provide this file to the repository, it must be stored in the {ref}/secure-settings.html[Elasticsearch keystore]. You must\nadd a `file` setting with the name `gcs.client.NAME.credentials_file` using the `add-file` subcommand.\n `NAME` is the name of the client configuration for the repository. The implicit client\nname is `default`, but a different client name can be specified in the\nrepository settings with the `client` key.\n\nNOTE: Passing the file path via the GOOGLE_APPLICATION_CREDENTIALS environment\nvariable is **not** supported.\n\nFor example, if you added a `gcs.client.my_alternate_client.credentials_file`\nsetting in the keystore, you can configure a repository to use those credentials\nlike this:\n\n[source,console]\n----\nPUT _snapshot/my_gcs_repository\n{\n  \"type\": \"gcs\",\n  \"settings\": {\n    \"bucket\": \"my_bucket\",\n    \"client\": \"my_alternate_client\"\n  }\n}\n----\n// TEST[skip:we don't have gcs setup while testing this]\n\nThe `credentials_file` settings are {ref}/secure-settings.html#reloadable-secure-settings[reloadable].\nYou can define these settings before the node is started, \nor call the <<cluster-nodes-reload-secure-settings,Nodes reload secure settings API>> \nafter the settings are defined to apply them to a running node.\n\nAfter you reload the settings, the internal `gcs` clients, which are used to\ntransfer the snapshot contents, utilize the latest settings from the keystore.\n\nNOTE: Snapshot or restore jobs that are in progress are not preempted by a *reload*\nof the client's `credentials_file` settings. They complete using the client as\nit was built when the operation started.\n\n[[repository-gcs-client]]\n==== Client settings\n\nThe client used to connect to Google Cloud Storage has a number of settings available.\nClient setting names are of the form `gcs.client.CLIENT_NAME.SETTING_NAME` and are specified\ninside `elasticsearch.yml`. The default client name looked up by a `gcs` repository is\ncalled `default`, but can be customized with the repository setting `client`.\n\nFor example:\n\n[source,console]\n----\nPUT _snapshot/my_gcs_repository\n{\n  \"type\": \"gcs\",\n  \"settings\": {\n    \"bucket\": \"my_bucket\",\n    \"client\": \"my_alternate_client\"\n  }\n}\n----\n// TEST[skip:we don't have gcs setup while testing this]\n\nSome settings are sensitive and must be stored in the\n{ref}/secure-settings.html[Elasticsearch keystore]. This is the case for the service account file:\n\n[source,sh]\n----\nbin/elasticsearch-keystore add-file gcs.client.default.credentials_file /path/service-account.json\n----\n\nThe following are the available client settings. Those that must be stored in the keystore\nare marked as `Secure`.\n\n`credentials_file` ({ref}/secure-settings.html[Secure], {ref}/secure-settings.html#reloadable-secure-settings[reloadable])::\n\n    The service account file that is used to authenticate to the Google Cloud Storage service.\n\n`endpoint`::\n\n    The Google Cloud Storage service endpoint to connect to. This will be automatically\n    determined by the Google Cloud Storage client but can be specified explicitly.\n\n`connect_timeout`::\n\n    The timeout to establish a connection to the Google Cloud Storage service. The value should\n    specify the unit. For example, a value of `5s` specifies a 5 second timeout. The value of `-1`\n    corresponds to an infinite timeout. The default value is 20 seconds.\n\n`read_timeout`::\n\n    The timeout to read data from an established connection. The value should\n    specify the unit. For example, a value of `5s` specifies a 5 second timeout. The value of `-1`\n    corresponds to an infinite timeout. The default value is 20 seconds.\n\n`application_name`::\n\n    Name used by the client when it uses the Google Cloud Storage service. Setting\n    a custom name can be useful to authenticate your cluster when requests\n    statistics are logged in the Google Cloud Platform. Default to `repository-gcs`\n\n`project_id`::\n\n    The Google Cloud project id. This will be automatically inferred from the credentials file but\n    can be specified explicitly. For example, it can be used to switch between projects when the\n    same credentials are usable for both the production and the development projects.\n\n`proxy.host`::\n    Host name of a proxy to connect to the Google Cloud Storage through.\n\n`proxy.port`::\n    Port of a proxy to connect to the Google Cloud Storage through.\n\n`proxy.type`::\n    Proxy type for the client. Supported values are `direct` (no proxy),\n    `http`, and `socks`. Defaults to `direct`.\n\n[[repository-gcs-repository]]\n==== Repository settings\n\nThe `gcs` repository type supports a number of settings to customize how data\nis stored in Google Cloud Storage.\n\nThese can be specified when creating the repository. For example:\n\n[source,console]\n----\nPUT _snapshot/my_gcs_repository\n{\n  \"type\": \"gcs\",\n  \"settings\": {\n    \"bucket\": \"my_other_bucket\",\n    \"base_path\": \"dev\"\n  }\n}\n----\n// TEST[skip:we don't have gcs set up while testing this]\n\nThe following settings are supported:\n\n`bucket`::\n\n    The name of the bucket to be used for snapshots. (Mandatory)\n\n`client`::\n\n    The name of the client to use to connect to Google Cloud Storage.\n    Defaults to `default`.\n\n`base_path`::\n\n    Specifies the path within bucket to repository data. Defaults to\n    the root of the bucket.\n+\nNOTE: Don't set `base_path` when configuring a snapshot repository for {ECE}.\n{ECE} automatically generates the `base_path` for each deployment so that\nmultiple deployments may share the same bucket.\n\n`chunk_size`::\n\n    Big files can be broken down into multiple smaller blobs in the blob store during snapshotting.\n    It is not recommended to change this value from its default unless there is an explicit reason for limiting the\n    size of blobs in the repository. Setting a value lower than the default can result in an increased number of API\n    calls to the Google Cloud Storage Service during snapshot create as well as restore operations compared to using\n    the default value and thus make both operations slower as well as more costly.\n    Specify the chunk size as a value and unit, for example:\n    `10MB`, `5KB`, `500B`. Defaults to the maximum size of a blob in the Google Cloud Storage Service which is `5TB`.\n\n`compress`::\n\n    When set to `true` metadata files are stored in compressed format. This\n    setting doesn't affect index files that are already compressed by default.\n    Defaults to `true`.\n\ninclude::repository-shared-settings.asciidoc[]\n\n`application_name`::\n\n    deprecated:[6.3.0, \"This setting is now defined in the <<repository-gcs-client, client settings>>.\"]\n    Name used by the client when it uses the Google Cloud Storage service.\n\n[[repository-gcs-bucket-permission]]\n===== Recommended bucket permission\n\nThe service account used to access the bucket must have the \"Writer\" access to the bucket:\n\n1. Connect to the https://console.cloud.google.com/[Google Cloud Platform Console].\n2. Select your project.\n3. Go to the https://console.cloud.google.com/storage/browser[Storage Browser].\n4. Select the bucket and \"Edit bucket permission\".\n5. The service account must be configured as a \"User\" with \"Writer\" access.\n\n[[repository-gcs-linearizable-registers]]\n==== Linearizable register implementation\n\nThe linearizable register implementation for GCS repositories is based on GCS's\nsupport for strongly consistent preconditions on put-blob operations. To\nperform a compare-and-exchange operation on a register, {es} retrieves the\nregister blob and its current generation, and then uploads the updated blob\nusing the observed generation as its precondition. The precondition ensures\nthat the generation has not changed in the meantime.\n"
}
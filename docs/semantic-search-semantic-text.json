{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.373067",
        "size": 12066,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/semantic-search-semantic-text.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "semantic-search-semantic-text",
        "version": "8.15"
    },
    "doc": "[[semantic-search-semantic-text]]\n=== Tutorial: semantic search with `semantic_text`\n++++\n<titleabbrev>Semantic search with `semantic_text`</titleabbrev>\n++++\n\nbeta[]\n\nThis tutorial shows you how to use the semantic text feature to perform semantic search on your data.\n\nSemantic text simplifies the {infer} workflow by providing {infer} at ingestion time and sensible default values automatically.\nYou don't need to define model related settings and parameters, or create {infer} ingest pipelines.\n\nThe recommended way to use <<semantic-search,semantic search>> in the {stack} is following the `semantic_text` workflow.\nWhen you need more control over indexing and query settings, you can still use the complete {infer} workflow (refer to  <<semantic-search-inference,this tutorial>> to review the process).\n\nThis tutorial uses the <<inference-example-elser,`elser` service>> for demonstration, but you can use any service and their supported models offered by the {infer-cap} API.\n\n\n[discrete]\n[[semantic-text-requirements]]\n==== Requirements\n\nTo use the `semantic_text` field type, you must have an {infer} endpoint deployed in\nyour cluster using the <<put-inference-api>>.\n\n[discrete]\n[[semantic-text-infer-endpoint]]\n==== Create the {infer} endpoint\n\nCreate an inference endpoint by using the <<put-inference-api>>:\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/sparse_embedding/my-elser-endpoint <1>\n{\n  \"service\": \"elser\", <2>\n  \"service_settings\": {\n    \"adaptive_allocations\": { <3>\n      \"enabled\": true,\n      \"min_number_of_allocations\": 3,\n      \"max_number_of_allocations\": 10\n    },\n    \"num_threads\": 1\n  }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n<1> The task type is `sparse_embedding` in the path as the `elser` service will\nbe used and ELSER creates sparse vectors. The `inference_id` is\n`my-elser-endpoint`.\n<2> The `elser` service is used in this example.\n<3> This setting enables and configures {ml-docs}/ml-nlp-auto-scale.html#nlp-model-adaptive-allocations[adaptive allocations].\nAdaptive allocations make it possible for ELSER to automatically scale up or down resources based on the current load on the process.\n\n[NOTE]\n====\nYou might see a 502 bad gateway error in the response when using the {kib} Console.\nThis error usually just reflects a timeout, while the model downloads in the background.\nYou can check the download progress in the {ml-app} UI.\nIf using the Python client, you can set the `timeout` parameter to a higher value.\n====\n\n[discrete]\n[[semantic-text-index-mapping]]\n==== Create the index mapping\n\nThe mapping of the destination index - the index that contains the embeddings that the inference endpoint will generate based on your input text - must be created.\nThe destination index must have a field with the <<semantic-text,`semantic_text`>> field type to index the output of the used inference endpoint.\n\n[source,console]\n------------------------------------------------------------\nPUT semantic-embeddings\n{\n  \"mappings\": {\n    \"properties\": {\n      \"content\": { <1>\n        \"type\": \"semantic_text\", <2>\n        \"inference_id\": \"my-elser-endpoint\" <3>\n      }\n    }\n  }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n<1> The name of the field to contain the generated embeddings.\n<2> The field to contain the embeddings is a `semantic_text` field.\n<3> The `inference_id` is the inference endpoint you created in the previous step.\nIt will be used to generate the embeddings based on the input text.\nEvery time you ingest data into the related `semantic_text` field, this endpoint will be used for creating the vector representation of the text.\n\n[NOTE]\n====\nIf you're using web crawlers or connectors to generate indices, you have to\n<<indices-put-mapping,update the index mappings>> for these indices to\ninclude the `semantic_text` field. Once the mapping is updated, you'll need to run\na full web crawl or a full connector sync. This ensures that all existing\ndocuments are reprocessed and updated with the new semantic embeddings,\nenabling semantic search on the updated data.\n====\n\n\n[discrete]\n[[semantic-text-load-data]]\n==== Load data\n\nIn this step, you load the data that you later use to create embeddings from it.\n\nUse the `msmarco-passagetest2019-top1000` data set, which is a subset of the MS\nMARCO Passage Ranking data set. It consists of 200 queries, each accompanied by\na list of relevant text passages. All unique passages, along with their IDs,\nhave been extracted from that data set and compiled into a\nhttps://github.com/elastic/stack-docs/blob/main/docs/en/stack/ml/nlp/data/msmarco-passagetest2019-unique.tsv[tsv file].\n\nDownload the file and upload it to your cluster using the {kibana-ref}/connect-to-elasticsearch.html#upload-data-kibana[Data Visualizer] in the {ml-app} UI.\nAfter your data is analyzed, click **Override settings**.\nUnder **Edit field names**, assign `id` to the first column and `content` to the second.\nClick **Apply**, then **Import**.\nName the index `test-data`, and click **Import**.\nAfter the upload is complete, you will see an index named `test-data` with 182,469 documents.\n\n\n[discrete]\n[[semantic-text-reindex-data]]\n==== Reindex the data\n\nCreate the embeddings from the text by reindexing the data from the `test-data` index to the `semantic-embeddings` index.\nThe data in the `content` field will be reindexed into the `content` semantic text field of the destination index.\nThe reindexed data will be processed by the {infer} endpoint associated with the `content` semantic text field.\n\n[NOTE]\n====\nThis step uses the reindex API to simulate data ingestion. If you are working with data that has already been indexed,\nrather than using the test-data set, reindexing is required to ensure that the data is processed by the {infer} endpoint\nand the necessary embeddings are generated.\n====\n\n[source,console]\n------------------------------------------------------------\nPOST _reindex?wait_for_completion=false\n{\n  \"source\": { \n    \"index\": \"test-data\",\n    \"size\": 10 <1>\n  },\n  \"dest\": {\n    \"index\": \"semantic-embeddings\"\n  }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n<1> The default batch size for reindexing is 1000. Reducing size to a smaller\nnumber makes the update of the reindexing process quicker which enables you to\nfollow the progress closely and detect errors early.\n\nThe call returns a task ID to monitor the progress:\n\n[source,console]\n------------------------------------------------------------\nGET _tasks/<task_id>\n------------------------------------------------------------\n// TEST[skip:TBD]\n\nReindexing large datasets can take a long time.\nYou can test this workflow using only a subset of the dataset.\nDo this by cancelling the reindexing process, and only generating embeddings for the subset that was reindexed.\nThe following API request will cancel the reindexing task:\n\n[source,console]\n------------------------------------------------------------\nPOST _tasks/<task_id>/_cancel\n------------------------------------------------------------\n// TEST[skip:TBD]\n\n\n[discrete]\n[[semantic-text-semantic-search]]\n==== Semantic search\n\nAfter the data set has been enriched with the embeddings, you can query the data using semantic search.\nProvide the `semantic_text` field name and the query text in a `semantic` query type.\nThe {infer} endpoint used to generate the embeddings for the `semantic_text` field will be used to process the query text.\n\n[source,console]\n------------------------------------------------------------\nGET semantic-embeddings/_search\n{\n  \"query\": {\n    \"semantic\": { \n      \"field\": \"content\", <1>\n      \"query\": \"How to avoid muscle soreness while running?\" <2>\n    }\n  }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n<1> The `semantic_text` field on which you want to perform the search.\n<2> The query text.\n\nAs a result, you receive the top 10 documents that are closest in meaning to the\nquery from the `semantic-embedding` index:\n\n[source,console-result]\n------------------------------------------------------------\n\"hits\": [\n  {\n    \"_index\": \"semantic-embeddings\",\n    \"_id\": \"Jy5065EBBFPLbFsdh_f9\",\n    \"_score\": 21.487484,\n    \"_source\": {\n      \"id\": 8836652,\n      \"content\": {\n        \"text\": \"There are a few foods and food groups that will help to fight inflammation and delayed onset muscle soreness (both things that are inevitable after a long, hard workout) when you incorporate them into your postworkout eats, whether immediately after your run or at a meal later in the day. Advertisement. Advertisement.\",\n        \"inference\": {\n          \"inference_id\": \"my-elser-endpoint\",\n          \"model_settings\": {\n            \"task_type\": \"sparse_embedding\"\n          },\n          \"chunks\": [\n            {\n              \"text\": \"There are a few foods and food groups that will help to fight inflammation and delayed onset muscle soreness (both things that are inevitable after a long, hard workout) when you incorporate them into your postworkout eats, whether immediately after your run or at a meal later in the day. Advertisement. Advertisement.\",\n              \"embeddings\": {\n                (...)\n              }\n            }\n          ]\n        }\n      }\n    }\n  },\n  {\n    \"_index\": \"semantic-embeddings\",\n    \"_id\": \"Ji5065EBBFPLbFsdh_f9\",\n    \"_score\": 18.211695,\n    \"_source\": {\n      \"id\": 8836651,\n      \"content\": {\n        \"text\": \"During Your Workout. There are a few things you can do during your workout to help prevent muscle injury and soreness. According to personal trainer and writer for Iron Magazine, Marc David, doing warm-ups and cool-downs between sets can help keep muscle soreness to a minimum.\",\n        \"inference\": {\n          \"inference_id\": \"my-elser-endpoint\",\n          \"model_settings\": {\n            \"task_type\": \"sparse_embedding\"\n          },\n          \"chunks\": [\n            {\n              \"text\": \"During Your Workout. There are a few things you can do during your workout to help prevent muscle injury and soreness. According to personal trainer and writer for Iron Magazine, Marc David, doing warm-ups and cool-downs between sets can help keep muscle soreness to a minimum.\",\n              \"embeddings\": {\n                (...)\n              }\n            }\n          ]\n        }\n      }\n    }\n  },\n  {\n    \"_index\": \"semantic-embeddings\",\n    \"_id\": \"Wi5065EBBFPLbFsdh_b9\",\n    \"_score\": 13.089405,\n    \"_source\": {\n      \"id\": 8800197,\n      \"content\": {\n        \"text\": \"This is especially important if the soreness is due to a weightlifting routine. For this time period, do not exert more than around 50% of the level of effort (weight, distance and speed) that caused the muscle groups to be sore.\",\n        \"inference\": {\n          \"inference_id\": \"my-elser-endpoint\",\n          \"model_settings\": {\n            \"task_type\": \"sparse_embedding\"\n          },\n          \"chunks\": [\n            {\n              \"text\": \"This is especially important if the soreness is due to a weightlifting routine. For this time period, do not exert more than around 50% of the level of effort (weight, distance and speed) that caused the muscle groups to be sore.\",\n              \"embeddings\": {\n                (...)\n              }\n            }\n          ]\n        }\n      }\n    }\n  }\n]\n------------------------------------------------------------\n// NOTCONSOLE\n\n[discrete]\n[[semantic-text-further-examples]]\n==== Further examples and reading\n\n* If you want to use `semantic_text` in hybrid search, refer to https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/09-semantic-text.ipynb[this notebook] for a step-by-step guide.\n* For more information on how to optimize your ELSER endpoints, refer to {ml-docs}/ml-nlp-elser.html#elser-recommendations[the ELSER recommendations] section in the model documentation.\n* To learn more about model autoscaling, refer to the {ml-docs}/ml-nlp-auto-scale.html[trained model autoscaling] page."
}
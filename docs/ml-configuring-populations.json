{
    "meta": {
        "size": 3433,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-configuring-populations.html",
        "type": "documentation",
        "role": [
            "xpack",
            "screenshot",
            "screenshot",
            "screenshot"
        ],
        "has_code": false,
        "title": "ml-configuring-populations",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[ml-configuring-populations]]\n= Performing population analysis\n\nEntities or events in your data can be considered anomalous when:\n\n* Their behavior changes over time, relative to their own previous behavior, or\n* Their behavior is different than other entities in a specified population.\n\nThe latter method of detecting anomalies is known as _population analysis_. The\n{ml} analytics build a profile of what a \"typical\" user, machine, or other \nentity does over a specified time period and then identify when one is behaving\nabnormally compared to the population.\n\nThis type of analysis is most useful when the behavior of the population as a\nwhole is mostly homogeneous and you want to identify unusual behavior. In \ngeneral, population analysis is not useful when members of the population \ninherently have vastly different behavior. You can, however, segment your data \ninto groups that behave similarly and run these as separate jobs. For example, \nyou can use a query filter in the {dfeed} to segment your data or you can use \nthe `partition_field_name` to split the analysis for the different groups.\n\nPopulation analysis scales well and has a lower resource footprint than\nindividual analysis of each series. For example, you can analyze populations\nof hundreds of thousands or millions of entities.\n\nTo specify the population, use the `over_field_name` property. For example:\n\n[source,console]\n----------------------------------\nPUT _ml/anomaly_detectors/population\n{\n  \"description\" : \"Population analysis\",\n  \"analysis_config\" : {\n    \"bucket_span\":\"15m\",\n    \"influencers\": [\n      \"clientip\"\n    ],\n    \"detectors\": [\n      {\n        \"function\": \"mean\",\n        \"field_name\": \"bytes\",\n        \"over_field_name\": \"clientip\" <1>\n      }\n    ]\n  },\n  \"data_description\" : {\n    \"time_field\":\"timestamp\",\n    \"time_format\": \"epoch_ms\"\n  }\n}\n----------------------------------\n// TEST[skip:needs-licence]\n\n<1> This `over_field_name` property indicates that the metrics for each client \n  (as identified by their IP address) are analyzed relative to other clients\n  in each bucket.\n\nIf your data is stored in {es}, you can use the population job wizard in {kib}\nto create an {anomaly-job} with these same properties. For example, if you add\nthe sample web logs in {kib}, you can use the following job settings in the\npopulation job wizard:\n\n[role=\"screenshot\"]\nimage::images/ml-population-job.png[\"Job settings in the population job wizard]\n\nAfter you open the job and start the {dfeed} or supply data to the job, you can\nview the results in {kib}. For example, you can view the results in the\n**Anomaly Explorer**:\n\n[role=\"screenshot\"]\nimage::images/ml-population-results.png[\"Population analysis results in the Anomaly Explorer\"]\n\nAs in this case, the results are often quite sparse. There might be just a few\ndata points for the selected time period. Population analysis is particularly\nuseful when you have many entities and the data for specific entitles is \nsporadic or sparse.\n\nIf you click on a section in the timeline or swim lanes, you can see more\ndetails about the anomalies:\n\n[role=\"screenshot\"]\nimage::images/ml-population-anomaly.png[\"Anomaly details for a specific user\"]\n\nIn this example, the client IP address `30.156.16.164` received a low volume of\nbytes on the date and time shown. This event is anomalous because the mean is\nthree times lower than the expected behavior of the population.\n"
}
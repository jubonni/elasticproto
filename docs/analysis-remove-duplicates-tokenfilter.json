{
    "meta": {
        "timestamp": "2024-11-01T03:07:10.056271",
        "size": 3200,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-remove-duplicates-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-remove-duplicates-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-remove-duplicates-tokenfilter]]\n=== Remove duplicates token filter\n++++\n<titleabbrev>Remove duplicates</titleabbrev>\n++++\n\nRemoves duplicate tokens in the same position.\n\nThe `remove_duplicates` filter uses Lucene's\n{lucene-analysis-docs}/miscellaneous/RemoveDuplicatesTokenFilter.html[RemoveDuplicatesTokenFilter].\n\n[[analysis-remove-duplicates-tokenfilter-analyze-ex]]\n==== Example\n\nTo see how the `remove_duplicates` filter works, you first need to produce a\ntoken stream containing duplicate tokens in the same position.\n\nThe following <<indices-analyze,analyze API>> request uses the\n<<analysis-keyword-repeat-tokenfilter,`keyword_repeat`>> and\n<<analysis-stemmer-tokenfilter,`stemmer`>> filters to create stemmed and\nunstemmed tokens for `jumping dog`.\n\n[source,console]\n----\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\"\n  ],\n  \"text\": \"jumping dog\"\n}\n----\n\nThe API returns the following response. Note that the `dog` token in position\n`1` is duplicated.\n\n[source,console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"jumping\",\n      \"start_offset\": 0,\n      \"end_offset\": 7,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"jump\",\n      \"start_offset\": 0,\n      \"end_offset\": 7,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 8,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 8,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    }\n  ]\n}\n----\n\nTo remove one of the duplicate `dog` tokens, add the `remove_duplicates` filter\nto the previous analyze API request.\n\n[source,console]\n----\nGET _analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    \"keyword_repeat\",\n    \"stemmer\",\n    \"remove_duplicates\"\n  ],\n  \"text\": \"jumping dog\"\n}\n----\n\nThe API returns the following response. There is now only one `dog` token in\nposition `1`.\n\n[source,console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"jumping\",\n      \"start_offset\": 0,\n      \"end_offset\": 7,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"jump\",\n      \"start_offset\": 0,\n      \"end_offset\": 7,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 8,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    }\n  ]\n}\n----\n\n[[analysis-remove-duplicates-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`remove_duplicates` filter to configure a new <<analysis-custom-analyzer,custom\nanalyzer>>.\n\nThis custom analyzer uses the `keyword_repeat` and `stemmer` filters to create a\nstemmed and unstemmed version of each token in a stream. The `remove_duplicates`\nfilter then removes any duplicate tokens in the same position.\n\n[source,console]\n----\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"keyword_repeat\",\n            \"stemmer\",\n            \"remove_duplicates\"\n          ]\n        }\n      }\n    }\n  }\n}\n----"
}
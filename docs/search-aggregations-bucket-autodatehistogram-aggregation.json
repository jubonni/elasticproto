{
    "meta": {
        "size": 8717,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-autodatehistogram-aggregation.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "search-aggregations-bucket-autodatehistogram-aggregation",
        "version": "8.15"
    },
    "doc": "[[search-aggregations-bucket-autodatehistogram-aggregation]]\n=== Auto-interval date histogram aggregation\n++++\n<titleabbrev>Auto-interval date histogram</titleabbrev>\n++++\n\nA multi-bucket aggregation similar to the <<search-aggregations-bucket-datehistogram-aggregation>> except\ninstead of providing an interval to use as the width of each bucket, a target number of buckets is provided\nindicating the number of buckets needed and the interval of the buckets is automatically chosen to best achieve\nthat target. The number of buckets returned will always be less than or equal to this target number.\n\nThe buckets field is optional, and will default to 10 buckets if not specified.\n\nRequesting a target of 10 buckets.\n\n[source,console,id=autodatehistogram-aggregation-example]\n--------------------------------------------------\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 10\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:sales]\n\n==== Keys\n\nInternally, a date is represented as a 64 bit number representing a timestamp\nin milliseconds-since-the-epoch. These timestamps are returned as the bucket\n++key++s. The `key_as_string` is the same timestamp converted to a formatted\ndate string using the format specified with the `format` parameter:\n\nTIP: If no `format` is specified, then it will use the first date\n<<mapping-date-format,format>> specified in the field mapping.\n\n[source,console,id=autodatehistogram-aggregation-format-example]\n--------------------------------------------------\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 5,\n        \"format\": \"yyyy-MM-dd\" <1>\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:sales]\n\n<1> Supports expressive date <<date-format-pattern,format pattern>>\n\nResponse:\n\n[source,console-result]\n--------------------------------------------------\n{\n  ...\n  \"aggregations\": {\n    \"sales_over_time\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015-01-01\",\n          \"key\": 1420070400000,\n          \"doc_count\": 3\n        },\n        {\n          \"key_as_string\": \"2015-02-01\",\n          \"key\": 1422748800000,\n          \"doc_count\": 2\n        },\n        {\n          \"key_as_string\": \"2015-03-01\",\n          \"key\": 1425168000000,\n          \"doc_count\": 2\n        }\n      ],\n      \"interval\": \"1M\"\n    }\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\\.\\.\\./\"took\": $body.took,\"timed_out\": false,\"_shards\": $body._shards,\"hits\": $body.hits,/]\n\n==== Intervals\n\nThe interval of the returned buckets is selected based on the data collected by the\naggregation so that the number of buckets returned is less than or equal to the number\nrequested. The possible intervals returned are:\n\n[horizontal]\nseconds::      In multiples of 1, 5, 10 and 30\nminutes::      In multiples of 1, 5, 10 and 30\nhours::        In multiples of 1, 3 and 12\ndays::         In multiples of 1, and 7\nmonths::       In multiples of 1, and 3\nyears::        In multiples of 1, 5, 10, 20, 50 and 100\n\nIn the worst case, where the number of daily buckets are too many for the requested\nnumber of buckets, the number of buckets returned will be 1/7th of the number of\nbuckets requested.\n\n==== Time Zone\n\nDate-times are stored in Elasticsearch in UTC. By default, all bucketing and\nrounding is also done in UTC. The `time_zone` parameter can be used to indicate\nthat bucketing should use a different time zone.\n\nTime zones may either be specified as an ISO 8601 UTC offset (e.g. `+01:00` or\n`-08:00`)  or as a timezone id, an identifier used in the TZ database like\n`America/Los_Angeles`.\n\nConsider the following example:\n\n[source,console,id=autodatehistogram-aggregation-timezone-example]\n---------------------------------\nPUT my-index-000001/_doc/1?refresh\n{\n  \"date\": \"2015-10-01T00:30:00Z\"\n}\n\nPUT my-index-000001/_doc/2?refresh\n{\n  \"date\": \"2015-10-01T01:30:00Z\"\n}\n\nPUT my-index-000001/_doc/3?refresh\n{\n  \"date\": \"2015-10-01T02:30:00Z\"\n}\n\nGET my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"by_day\": {\n      \"auto_date_histogram\": {\n        \"field\":     \"date\",\n        \"buckets\" : 3\n      }\n    }\n  }\n}\n---------------------------------\n\nUTC is used if no time zone is specified, three 1-hour buckets are returned\nstarting at midnight UTC on 1 October 2015:\n\n[source,console-result]\n---------------------------------\n{\n  ...\n  \"aggregations\": {\n    \"by_day\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015-10-01T00:00:00.000Z\",\n          \"key\": 1443657600000,\n          \"doc_count\": 1\n        },\n        {\n          \"key_as_string\": \"2015-10-01T01:00:00.000Z\",\n          \"key\": 1443661200000,\n          \"doc_count\": 1\n        },\n        {\n          \"key_as_string\": \"2015-10-01T02:00:00.000Z\",\n          \"key\": 1443664800000,\n          \"doc_count\": 1\n        }\n      ],\n      \"interval\": \"1h\"\n    }\n  }\n}\n---------------------------------\n// TESTRESPONSE[s/\\.\\.\\./\"took\": $body.took,\"timed_out\": false,\"_shards\": $body._shards,\"hits\": $body.hits,/]\n\nIf a `time_zone` of `-01:00` is specified, then midnight starts at one hour before\nmidnight UTC:\n\n[source,console]\n---------------------------------\nGET my-index-000001/_search?size=0\n{\n  \"aggs\": {\n    \"by_day\": {\n      \"auto_date_histogram\": {\n        \"field\":     \"date\",\n        \"buckets\" : 3,\n        \"time_zone\": \"-01:00\"\n      }\n    }\n  }\n}\n---------------------------------\n// TEST[continued]\n\n\nNow three 1-hour buckets are still returned but the first bucket starts at\n11:00pm on 30 September 2015 since that is the local time for the bucket in\nthe specified time zone.\n\n[source,console-result]\n---------------------------------\n{\n  ...\n  \"aggregations\": {\n    \"by_day\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2015-09-30T23:00:00.000-01:00\", <1>\n          \"key\": 1443657600000,\n          \"doc_count\": 1\n        },\n        {\n          \"key_as_string\": \"2015-10-01T00:00:00.000-01:00\",\n          \"key\": 1443661200000,\n          \"doc_count\": 1\n        },\n        {\n          \"key_as_string\": \"2015-10-01T01:00:00.000-01:00\",\n          \"key\": 1443664800000,\n          \"doc_count\": 1\n        }\n      ],\n      \"interval\": \"1h\"\n    }\n  }\n}\n---------------------------------\n// TESTRESPONSE[s/\\.\\.\\./\"took\": $body.took,\"timed_out\": false,\"_shards\": $body._shards,\"hits\": $body.hits,/]\n\n<1> The `key_as_string` value represents midnight on each day\n    in the specified time zone.\n\nWARNING: When using time zones that follow DST (daylight savings time) changes,\nbuckets close to the moment when those changes happen can have slightly different\nsizes than neighbouring buckets.\nFor example, consider a DST start in the `CET` time zone: on 27 March 2016 at 2am,\nclocks were turned forward 1 hour to 3am local time. If the result of the aggregation\nwas daily buckets, the bucket covering that day will only hold data for 23 hours\ninstead of the usual 24 hours for other buckets. The same is true for shorter intervals\nlike e.g. 12h. Here, we will have only a 11h bucket on the morning of 27 March when the\nDST shift happens.\n\n==== Minimum Interval parameter\n\nThe `minimum_interval` allows the caller to specify the minimum rounding interval that should be used.\nThis can make the collection process more efficient, as the aggregation will not attempt to round at\nany interval lower than `minimum_interval`.\n\nThe accepted units for `minimum_interval` are:\n\n* year\n* month\n* day\n* hour\n* minute\n* second\n\n[source,console,id=autodatehistogram-aggregation-minimum-interval-example]\n--------------------------------------------------\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sale_date\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 10,\n        \"minimum_interval\": \"minute\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:sales]\n\n==== Missing value\n\nThe `missing` parameter defines how documents that are missing a value should be treated.\nBy default they will be ignored but it is also possible to treat them as if they\nhad a value.\n\n[source,console,id=autodatehistogram-aggregation-missing-example]\n--------------------------------------------------\nPOST /sales/_search?size=0\n{\n  \"aggs\": {\n    \"sale_date\": {\n      \"auto_date_histogram\": {\n        \"field\": \"date\",\n        \"buckets\": 10,\n        \"missing\": \"2000/01/01\" <1>\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:sales]\n\n<1> Documents without a value in the `publish_date` field will fall into the same bucket as documents that have the value `2000-01-01`.\n\n"
}
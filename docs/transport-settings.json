{
    "meta": {
        "timestamp": "2024-11-01T03:02:53.780601",
        "size": 10505,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/transport-settings.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "transport-settings",
        "version": "8.15"
    },
    "doc": "[[transport-settings]]\n==== Advanced transport settings\n\nUse the following advanced settings to configure the transport interface\nindependently of the <<http-settings,HTTP interface>>. Use the\n<<common-network-settings,network\nsettings>> to configure both interfaces together.\n\n`transport.host`::\n(<<static-cluster-setting,Static>>, string)\nSets the address of this node for transport traffic. The node will bind to this\naddress and will also use it as its transport publish address. Accepts an IP\naddress, a hostname, or a <<network-interface-values,special value>>.\nUse this setting only if you require different configurations for the\ntransport and HTTP interfaces.\n+\nDefaults to the address given by `network.host`.\n\n`transport.bind_host`::\n(<<static-cluster-setting,Static>>, string)\nThe network address(es) to which the node should bind in order to listen for\nincoming transport connections. Accepts a list of IP addresses, hostnames, and\n<<network-interface-values,special values>>. Defaults to the address given by\n`transport.host` or `network.bind_host`. Use this setting only if you require\nto bind to multiple addresses or to use different addresses for publishing and\nbinding, and you also require different binding configurations for the\ntransport and HTTP interfaces.\n\n`transport.publish_host`::\n(<<static-cluster-setting,Static>>, string)\nThe network address at which the node can be contacted by other nodes. Accepts\nan IP address, a hostname, or a <<network-interface-values,special value>>.\nDefaults to the address given by `transport.host` or `network.publish_host`.\nUse this setting only if you require to bind to multiple addresses or to use\ndifferent addresses for publishing and binding, and you also require different\nbinding configurations for the transport and HTTP interfaces.\n\n`transport.publish_port`::\n(<<static-cluster-setting,Static>>, integer)\nThe port of the <<modules-network-binding-publishing,transport publish\naddress>>. Set this parameter only if you need the publish port to be\ndifferent from `transport.port`. Defaults to the port assigned via\n`transport.port`.\n\n`transport.connect_timeout`::\n(<<static-cluster-setting,Static>>, <<time-units,time value>>)\nThe connect timeout for initiating a new connection (in\ntime setting format). Defaults to `30s`.\n\n[[transport-settings-compress]]\n`transport.compress`::\n(<<static-cluster-setting,Static>>, string)\nDetermines which transport requests are compressed before sending them to\nanother node. {es} will compress transport responses if and only if the\ncorresponding request was compressed. See also `transport.compression_scheme`,\nwhich specifies the compression scheme which is used. Accepts the following\nvalues:\n+\n--\n`false`::\n\nNo transport requests are compressed. This option uses the most network\nbandwidth, but avoids the CPU overhead of compression and decompression.\n\n`indexing_data`::\n\nCompresses only the raw indexing data sent between nodes during ingest, CCR\nfollowing (excluding bootstrapping) and operations-based shard recovery\n(excluding file-based recovery which copies the raw Lucene data). This option\nis a good trade-off between network bandwidth savings and the extra CPU\nrequired for compression and decompression. This option is the default.\n\n`true`::\n\nAll transport requests are compressed. This option may perform better than\n`indexing_data` in terms of network bandwidth, but will require the most CPU\nfor compression and decompression work.\n--\n\n[[transport-settings-compression-scheme]]\n`transport.compression_scheme`::\n(<<static-cluster-setting,Static>>, string)\nConfigures the compression scheme for requests which are selected for\ncompression by to the `transport.compress` setting. Accepts either `deflate` or\n`lz4`, which offer different trade-offs between compression ratio and CPU\nusage. {es} will use the same compression scheme for responses as for the\ncorresponding requests. Defaults to `lz4`.\n\n`transport.tcp.keep_alive`::\n(<<static-cluster-setting,Static>>, boolean)\nConfigures the `SO_KEEPALIVE` option for transport sockets, which determines\nwhether they send TCP keepalive probes. Defaults to `network.tcp.keep_alive`.\n\n`transport.tcp.keep_idle`::\n(<<static-cluster-setting,Static>>, integer)\nConfigures the `TCP_KEEPIDLE` option for transport sockets, which determines\nthe time in seconds that a connection must be idle before starting to send TCP\nkeepalive probes. Defaults to `network.tcp.keep_idle` if set, or the system\ndefault otherwise. This value cannot exceed `300` seconds. In cases where the\nsystem default is higher than `300`, the value is automatically lowered to\n`300`. Only applicable on Linux and macOS.\n\n`transport.tcp.keep_interval`::\n(<<static-cluster-setting,Static>>, integer)\nConfigures the `TCP_KEEPINTVL` option for transport sockets, which determines\nthe time in seconds between sending TCP keepalive probes. Defaults to\n`network.tcp.keep_interval` if set, or the system default otherwise. This value\ncannot exceed `300` seconds. In cases where the system default is higher than\n`300`, the value is automatically lowered to `300`. Only applicable on Linux\nand macOS.\n\n`transport.tcp.keep_count`::\n(<<static-cluster-setting,Static>>, integer)\nConfigures the `TCP_KEEPCNT` option for transport sockets, which determines the\nnumber of unacknowledged TCP keepalive probes that may be sent on a connection\nbefore it is dropped. Defaults to `network.tcp.keep_count` if set, or the\nsystem default otherwise. Only applicable on Linux and macOS.\n\n`transport.tcp.no_delay`::\n(<<static-cluster-setting,Static>>, boolean)\nConfigures the `TCP_NODELAY` option on transport sockets, which determines\nwhether {wikipedia}/Nagle%27s_algorithm[TCP no delay] is enabled. Defaults to\n`true`.\n\n`transport.tcp.reuse_address`::\n(<<static-cluster-setting,Static>>, boolean)\nConfigures the `SO_REUSEADDR` option for network sockets, which determines\nwhether the address can be reused or not. Defaults to\n`network.tcp.reuse_address`.\n\n`transport.tcp.send_buffer_size`::\n(<<static-cluster-setting,Static>>, <<byte-units,byte value>>)\nThe size of the TCP send buffer for transport traffic. Defaults to\n`network.tcp.send_buffer_size`.\n\n`transport.tcp.receive_buffer_size`::\n(<<static-cluster-setting,Static>>, <<byte-units,byte value>>)\nThe size of the TCP receive buffer for transport traffic. Defaults to\n`network.tcp.receive_buffer_size`.\n\n`transport.ping_schedule`::\n(<<static-cluster-setting,Static>>, <<time-units,time value>>)\nConfigures the time between sending application-level pings on all transport\nconnections to promptly detect when a transport connection has failed. Defaults\nto `-1` meaning that application-level pings are not sent. You should use TCP\nkeepalives (see `transport.tcp.keep_alive`) instead of application-level pings\nwherever possible.\n\n[[transport-profiles]]\n===== Transport profiles\n\nElasticsearch allows you to bind to multiple ports on different interfaces by\nthe use of transport profiles. See this example configuration\n\n[source,yaml]\n--------------\ntransport.profiles.default.port: 9300-9400\ntransport.profiles.default.bind_host: 10.0.0.1\ntransport.profiles.client.port: 9500-9600\ntransport.profiles.client.bind_host: 192.168.0.1\ntransport.profiles.dmz.port: 9700-9800\ntransport.profiles.dmz.bind_host: 172.16.1.2\n--------------\n\nThe `default` profile is special. It is used as a fallback for any other\nprofiles, if those do not have a specific configuration setting set, and is how\nthis node connects to other nodes in the cluster.\nOther profiles can have any name and can be used to set up specific endpoints\nfor incoming connections.\n\nThe following parameters can be configured on each transport profile, as in the\nexample above:\n\n* `port`: The port to which to bind.\n* `bind_host`: The host to which to bind.\n* `publish_host`: The host which is published in informational APIs.\n\nProfiles also support all the other transport settings specified in the\n<<transport-settings,transport settings>> section, and use these as defaults.\nFor example, `transport.profiles.client.tcp.reuse_address` can be explicitly\nconfigured, and defaults otherwise to `transport.tcp.reuse_address`.\n\n[[long-lived-connections]]\n===== Long-lived idle connections\n\nA transport connection between two nodes is made up of a number of long-lived\nTCP connections, some of which may be idle for an extended period of time.\nNonetheless, {es} requires these connections to remain open, and it can disrupt\nthe operation of your cluster if any inter-node connections are closed by an\nexternal influence such as a firewall. It is important to configure your network\nto preserve long-lived idle connections between {es} nodes, for instance by\nleaving `*.tcp.keep_alive` enabled and ensuring that the keepalive interval is\nshorter than any timeout that might cause idle connections to be closed, or by\nsetting `transport.ping_schedule` if keepalives cannot be configured. Devices\nwhich drop connections when they reach a certain age are a common source of\nproblems to {es} clusters, and must not be used.\n\nFor information about troubleshooting unexpected network disconnections, see\n<<troubleshooting-unstable-cluster-network>>.\n\n[[request-compression]]\n===== Request compression\n\nThe default `transport.compress` configuration option `indexing_data` will only\ncompress requests that relate to the transport of raw indexing source data\nbetween nodes. This option primarily compresses data sent during ingest,\nccr, and shard recovery. This default normally makes sense for local cluster\ncommunication as compressing raw documents tends significantly reduce inter-node\nnetwork usage with minimal CPU impact.\n\nThe `transport.compress` setting always configures local cluster request\ncompression and is the fallback setting for remote cluster request compression.\nIf you want to configure remote request compression differently than local\nrequest compression, you can set it on a per-remote cluster basis using the\n<<remote-clusters-settings,`cluster.remote.${cluster_alias}.transport.compress` setting>>.\n\n\n[[response-compression]]\n===== Response compression\n\nThe compression settings do not configure compression for responses. {es} will\ncompress a response if the inbound request was compressed--even when compression\nis not enabled. Similarly, {es} will not compress a response if the inbound\nrequest was uncompressed--even when compression is enabled. The compression\nscheme used to compress a response will be the same scheme the remote node used\nto compress the request.\n"
}
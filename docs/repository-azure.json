{
    "meta": {
        "size": 13447,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/repository-azure.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "repository-azure",
        "version": "8.15"
    },
    "doc": "[[repository-azure]]\n=== Azure repository\n\nYou can use\nhttps://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction[Azure\nBlob storage] as a repository for <<snapshot-restore,Snapshot and restore>>.\n\n[[repository-azure-usage]]\n==== Setup\n\nTo enable Azure repositories, first configure an Azure repository client by\nspecifying one or more settings of the form\n`azure.client.CLIENT_NAME.SETTING_NAME`. By default, `azure` repositories use a\nclient named `default`, but you may specify a different client name when\nregistering each repository.\n\nThe only mandatory Azure repository client setting is `account`, which is a\n{ref}/secure-settings.html[secure setting] defined in the <<secure-settings,{es}\nkeystore>>. To provide this setting, use the `elasticsearch-keystore` tool on\neach node:\n\n[source,sh]\n----------------------------------------------------------------\nbin/elasticsearch-keystore add azure.client.default.account\n----------------------------------------------------------------\n\nIf you adjust this setting after a node has started, call the\n<<cluster-nodes-reload-secure-settings,Nodes reload secure settings API>> to\nreload the new value.\n\nYou may define more than one client by setting their `account` values. For\ninstance, to set the `default` client and another client called `secondary`, run\nthe following commands on each node:\n\n[source,sh]\n----------------------------------------------------------------\nbin/elasticsearch-keystore add azure.client.default.account\nbin/elasticsearch-keystore add azure.client.secondary.account\n----------------------------------------------------------------\n\nThe `key` and `sas_token` settings are also secure settings and can be set using\ncommands like the following:\n\n[source,sh]\n----------------------------------------------------------------\nbin/elasticsearch-keystore add azure.client.default.key\nbin/elasticsearch-keystore add azure.client.secondary.sas_token\n----------------------------------------------------------------\n\nOther Azure repository client settings must be set in `elasticsearch.yml` before\nthe node starts. For example:\n\n[source,yaml]\n----\nazure.client.default.timeout: 10s\nazure.client.default.max_retries: 7\nazure.client.default.endpoint_suffix: core.chinacloudapi.cn\nazure.client.secondary.timeout: 30s\n----\n\nIn this example, the client side timeout is `10s` per try for repositories which\nuse the `default` client, with `7` retries before failing and an endpoint\nsuffix of `core.chinacloudapi.cn`. Repositories which use the `secondary` client\nwill have a timeout of `30s` per try, but will use the default endpoint and will\nfail after the default number of retries.\n\nOnce an Azure repository client is configured correctly, register an Azure\nrepository as follows, providing the client name using the `client`\n<<repository-azure-repository-settings,repository setting>>:\n\n[source,console]\n----\nPUT _snapshot/my_backup\n{\n  \"type\": \"azure\",\n  \"settings\": {\n    \"client\": \"secondary\"\n  }\n}\n----\n// TEST[skip:we don't have azure setup while testing this]\n\nIf you are using the `default` client, you may omit the `client` repository\nsetting:\n\n[source,console]\n----\nPUT _snapshot/my_backup\n{\n  \"type\": \"azure\"\n}\n----\n// TEST[skip:we don't have azure setup while testing this]\n\nNOTE: In progress snapshot or restore jobs will not be preempted by a *reload*\nof the storage secure settings. They will complete using the client as it was\nbuilt when the operation started.\n\n[[repository-azure-client-settings]]\n==== Client settings\n\nThe following list describes the available client settings. Those that must be\nstored in the keystore are marked as ({ref}/secure-settings.html[Secure],\n{ref}/secure-settings.html#reloadable-secure-settings[reloadable]); the other\nsettings must be stored in the `elasticsearch.yml` file. The default\n`CLIENT_NAME` is `default` but you may configure a client with a different name\nand specify that client by name when registering a repository.\n\n`azure.client.CLIENT_NAME.account` ({ref}/secure-settings.html[Secure], {ref}/secure-settings.html#reloadable-secure-settings[reloadable])::\n  The Azure account name, which is used by the repository's internal Azure\n  client. This setting is required for all clients.\n\n`azure.client.CLIENT_NAME.endpoint_suffix`::\n  The Azure endpoint suffix to connect to. The default value is\n  `core.windows.net`.\n\n`azure.client.CLIENT_NAME.key` ({ref}/secure-settings.html[Secure], {ref}/secure-settings.html#reloadable-secure-settings[reloadable])::\n  The Azure secret key, which is used by the repository's internal Azure client.\n  Alternatively, use `sas_token`.\n\n`azure.client.CLIENT_NAME.max_retries`::\n    The number of retries to use when an Azure request fails. This setting helps\n    control the exponential backoff policy. It specifies the number of retries\n    that must occur before the snapshot fails. The default value is `3`. The\n    initial backoff period is defined by Azure SDK as `30s`. Thus there is `30s`\n    of wait time before retrying after a first timeout or failure. The maximum\n    backoff period is defined by Azure SDK as `90s`.\n\n`azure.client.CLIENT_NAME.proxy.host`::\n  The host name of a proxy to connect to Azure through. By default, no proxy is\n  used.\n\n`azure.client.CLIENT_NAME.proxy.port`::\n  The port of a proxy to connect to Azure through. By default, no proxy is used.\n\n`azure.client.CLIENT_NAME.proxy.type`::\n Register a proxy type for the client. Supported values are `direct`, `http`,\n and `socks`. For example: `azure.client.default.proxy.type: http`. When\n `proxy.type` is set to `http` or `socks`, `proxy.host` and `proxy.port` must\n also be provided. The default value is `direct`.\n\n`azure.client.CLIENT_NAME.sas_token` ({ref}/secure-settings.html[Secure], {ref}/secure-settings.html#reloadable-secure-settings[reloadable])::\n  A shared access signatures (SAS) token, which the repository's internal Azure\n  client uses for authentication. The SAS token must have read (r), write (w),\n  list (l), and delete (d) permissions for the repository base path and all its\n  contents. These permissions must be granted for the blob service (b) and apply\n  to resource types service (s), container (c), and object (o). Alternatively,\n  use `key`.\n\n`azure.client.CLIENT_NAME.timeout`::\n  The client side timeout for any single request to Azure, as a\n  <<time-units,time unit>>. For example, a value of `5s` specifies a 5 second\n  timeout. There is no default value, which means that {es} uses the\n  https://azure.github.io/azure-storage-java/com/microsoft/azure/storage/RequestOptions.html#setTimeoutIntervalInMs(java.lang.Integer)[default\n  value] set by the Azure client.\n\n`azure.client.CLIENT_NAME.endpoint`::\n  The Azure endpoint to connect to. It must include the protocol used to connect\n  to Azure.\n\n`azure.client.CLIENT_NAME.secondary_endpoint`::\n  The Azure secondary endpoint to connect to. It must include the protocol used\n  to connect to Azure.\n\n[[repository-azure-default-credentials]]\n[NOTE]\n.Obtaining credentials from the environment\n======================================================\nIf you specify neither the `key` nor the `sas_token` settings for a client then\n{es} will attempt to automatically obtain credentials from the environment in\nwhich it is running using mechanisms built into the Azure SDK. This is ideal\nfor when running {es} on the Azure platform.\n\nWhen running {es} on an\nhttps://azure.microsoft.com/en-gb/products/virtual-machines[Azure Virtual\nMachine], you should use\nhttps://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview[Azure\nManaged Identity] to provide credentials to {es}. To use Azure Managed Identity,\nassign a suitably authorized identity to the Azure Virtual Machine on which {es}\nis running.\n\nWhen running {es} in\nhttps://azure.microsoft.com/en-gb/products/kubernetes-service[Azure Kubernetes\nService], for instance using {eck-ref}[{eck}], you should use\nhttps://azure.github.io/azure-workload-identity/docs/introduction.html[Azure\nWorkload Identity] to provide credentials to {es}. To use Azure Workload\nIdentity, mount the `azure-identity-token` volume as a subdirectory of the\n<<config-files-location,{es} config directory>> and set the\n`AZURE_FEDERATED_TOKEN_FILE` environment variable to point to a file called\n`azure-identity-token` within the mounted volume.\n\nThe Azure SDK has several other mechanisms to automatically obtain credentials\nfrom its environment, but the two methods described above are the only ones\nthat are tested and supported for use in {es}.\n======================================================\n\n\n\n[[repository-azure-repository-settings]]\n==== Repository settings\n\nThe Azure repository supports the following settings, which may be specified\nwhen registering an Azure repository as follows:\n\n[source,console]\n----\nPUT _snapshot/my_backup\n{\n  \"type\": \"azure\",\n  \"settings\": {\n    \"client\": \"secondary\",\n    \"container\": \"my_container\",\n    \"base_path\": \"snapshots_prefix\"\n  }\n}\n----\n// TEST[skip:we don't have azure setup while testing this]\n\n`client`::\n\n    The name of the Azure repository client to use. Defaults to `default`.\n\n`container`::\n\n    Container name. You must create the azure container before creating the repository.\n    Defaults to `elasticsearch-snapshots`.\n\n`base_path`::\n\n    Specifies the path within container to repository data. Defaults to empty\n    (root directory).\n+\nNOTE: Don't set `base_path` when configuring a snapshot repository for {ECE}.\n{ECE} automatically generates the `base_path` for each deployment so that\nmultiple deployments may share the same bucket.\n\n`chunk_size`::\n\n    Big files can be broken down into multiple smaller blobs in the blob store\n    during snapshotting. It is not recommended to change this value from its\n    default unless there is an explicit reason for limiting the size of blobs in\n    the repository. Setting a value lower than the default can result in an\n    increased number of API calls to the Azure blob store during snapshot create\n    as well as restore operations compared to using the default value and thus\n    make both operations slower as well as more costly. Specify the chunk size\n    as a <<byte-units,byte unit>>, for example: `10MB`, `5KB`, `500B`. Defaults\n    to the maximum size of a blob in the Azure blob store which is `5TB`.\n\n`compress`::\n\n    When set to `true` metadata files are stored in compressed format. This\n    setting doesn't affect index files that are already compressed by default.\n    Defaults to `true`.\n\ninclude::repository-shared-settings.asciidoc[]\n\n`location_mode`::\n\n    `primary_only` or `secondary_only`. Defaults to `primary_only`. Note that if you set it\n    to `secondary_only`, it will force `readonly` to true.\n\n`delete_objects_max_size`::\n\n    (integer) Sets the maxmimum batch size, betewen 1 and 256, used for `BlobBatch` requests. Defaults to 256 which is the maximum\n    number supported by the https://learn.microsoft.com/en-us/rest/api/storageservices/blob-batch#remarks[Azure blob batch API].\n\n`max_concurrent_batch_deletes`::\n\n    (integer) Sets the maximum number of concurrent batch delete requests that will be submitted for any individual bulk delete with `BlobBatch`. Note that the effective number of concurrent deletes is further limited by the Azure client connection and event loop thread limits. Defaults to 10, minimum is 1, maximum is 100.\n\n[[repository-azure-validation]]\n==== Repository validation rules\n\nAccording to the\nhttps://docs.microsoft.com/en-us/rest/api/storageservices/Naming-and-Referencing-Containers--Blobs--and-Metadata[containers\nnaming guide], a container name must be a valid DNS name, conforming to the\nfollowing naming rules:\n\n* Container names must start with a letter or number, and can contain only letters, numbers, and the dash (-) character.\n* Every dash (-) character must be immediately preceded and followed by a letter or number; consecutive dashes are not\npermitted in container names.\n* All letters in a container name must be lowercase.\n* Container names must be from 3 through 63 characters long.\n\n[IMPORTANT]\n.Supported Azure Storage Account types\n===============================================\nThe Azure repository type works with all Standard storage accounts\n\n* Standard Locally Redundant Storage - `Standard_LRS`\n* Standard Zone-Redundant Storage - `Standard_ZRS`\n* Standard Geo-Redundant Storage - `Standard_GRS`\n* Standard Read Access Geo-Redundant Storage - `Standard_RAGRS`\n\nhttps://azure.microsoft.com/en-gb/documentation/articles/storage-premium-storage[Premium Locally Redundant Storage] (`Premium_LRS`) is **not supported** as it is only usable as VM disk storage, not as general storage.\n===============================================\n\n[[repository-azure-linearizable-registers]]\n==== Linearizable register implementation\n\nThe linearizable register implementation for Azure repositories is based on\nAzure's support for strongly consistent leases. Each lease may only be held by\na single node at any time. The node presents its lease when performing a read\nor write operation on a protected blob. Lease-protected operations fail if the\nlease is invalid or expired. To perform a compare-and-exchange operation on a\nregister, {es} first obtains a lease on the blob, then reads the blob contents\nunder the lease, and finally uploads the updated blob under the same lease.\nThis process ensures that the read and write operations happen atomically.\n"
}
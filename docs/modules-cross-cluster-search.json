{
    "meta": {
        "timestamp": "2024-11-01T03:07:10.148271",
        "size": 47935,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cross-cluster-search.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "modules-cross-cluster-search",
        "version": "8.15"
    },
    "doc": "[[modules-cross-cluster-search]]\n== Search across clusters\n\n*{ccs-cap}* lets you run a single search request against one or more remote\nclusters. For example, you can use a {ccs} to filter and analyze log data stored\non clusters in different data centers.\n\n[discrete]\n[[ccs-supported-apis]]\n=== Supported APIs\n\nThe following APIs support {ccs}:\n\n* <<search-search,Search>>\n* <<async-search,Async search>>\n* <<search-multi-search,Multi search>>\n* <<search-template,Search template>>\n* <<multi-search-template,Multi search template>>\n* <<search-field-caps,Field capabilities>>\n* {painless}/painless-execute-api.html[Painless execute API]\n* <<indices-resolve-index-api,Resolve Index API>>\n* experimental:[] <<eql-search-api,EQL search>>\n* experimental:[] <<sql-search-api,SQL search>>\n* experimental:[] <<search-vector-tile-api,Vector tile search>>\n* experimental:[] <<esql,ES|QL>>\n\n[discrete]\n=== Prerequisites\n// tag::ccs-prereqs[]\n\n* {ccs-cap} requires remote clusters. To set up remote clusters on {ess},\nsee link:{cloud}/ec-enable-ccs.html[configure remote clusters on {ess}]. If you\nrun {es} on your own hardware, see <<remote-clusters>>.\n+\nTo ensure your remote cluster configuration supports {ccs}, see\n<<ccs-supported-configurations>>.\n\n* For full {ccs} capabilities, the local and remote cluster must be on the same\n{subscriptions}[subscription level].\n\n* The local coordinating node must have the\n<<remote-node,`remote_cluster_client`>> node role.\n// end::ccs-prereqs[]\n\n[[ccs-gateway-seed-nodes]]\n// tag::ccs-gateway-seed-nodes[]\n* If you use <<sniff-mode,sniff mode>>, the local coordinating node\nmust be able to connect to seed and gateway nodes on the remote cluster.\n+\nWe recommend using gateway nodes capable of serving as coordinating nodes.\nThe seed nodes can be a subset of these gateway nodes.\n// end::ccs-gateway-seed-nodes[]\n\n[[ccs-proxy-mode]]\n// tag::ccs-proxy-mode[]\n* If you use <<proxy-mode,proxy mode>>, the local coordinating node must be able\nto connect to the configured `proxy_address`. The proxy at this address must be\nable to route connections to gateway and coordinating nodes on the remote\ncluster.\n\n* {ccs-cap} requires different security privileges on the local cluster and\nremote cluster. See <<remote-clusters-privileges-ccs>> and\n<<remote-clusters>>.\n// end::ccs-proxy-mode[]\n\n[discrete]\n[[ccs-example]]\n=== {ccs-cap} examples\n\n[discrete]\n[[ccs-remote-cluster-setup]]\n==== Remote cluster setup\n// tag::ccs-remote-cluster-setup[]\n\nThe following <<cluster-update-settings,cluster update settings>> API request\nadds three remote clusters: `cluster_one`, `cluster_two`, and `cluster_three`.\n\n[source,console]\n--------------------------------\nPUT _cluster/settings\n{\n  \"persistent\": {\n    \"cluster\": {\n      \"remote\": {\n        \"cluster_one\": {\n          \"seeds\": [\n            \"35.238.149.1:9300\"\n          ],\n          \"skip_unavailable\": true\n        },\n        \"cluster_two\": {\n          \"seeds\": [\n            \"35.238.149.2:9300\"\n          ],\n          \"skip_unavailable\": false\n        },\n        \"cluster_three\": {  <1>\n          \"seeds\": [\n            \"35.238.149.3:9300\"\n          ]\n        }\n      }\n    }\n  }\n}\n--------------------------------\n// TEST[setup:host]\n// TEST[s/35.238.149.\\d+:930\\d+/\\${transport_host}/]\n// end::ccs-remote-cluster-setup[]\n\n<1> Since `skip_unavailable` was not set on `cluster_three`, it uses\nthe default of `false`. See the <<skip-unavailable-clusters>>\nsection for details.\n\n\n[discrete]\n[[ccs-search-remote-cluster]]\n==== Search a single remote cluster\n\nIn the search request, you specify data streams and indices on a remote cluster\nas `<remote_cluster_name>:<target>`.\n\nThe following <<search-search,search>> API request searches the\n`my-index-000001` index on a single remote cluster, `cluster_one`.\n\n[source,console]\n--------------------------------------------------\nGET /cluster_one:my-index-000001/_search\n{\n  \"size\": 1,\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"_source\": [\"user.id\", \"message\", \"http.response.status_code\"]\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[setup:my_index]\n\nThe API returns the following response. Note that when you\nsearch one or more remote clusters, a `_clusters` section is\nincluded to provide information about the search on each cluster.\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"took\": 150,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 12,\n    \"successful\": 12,\n    \"failed\": 0,\n    \"skipped\": 0\n  },\n  \"_clusters\": {\n    \"total\": 1,  <1>\n    \"successful\": 1,\n    \"skipped\": 0,\n    \"running\": 0,\n    \"partial\": 0,\n    \"failed\": 0,\n    \"details\": {\n      \"cluster_one\": {  <2>\n        \"status\": \"successful\",\n        \"indices\": \"my-index-000001\", <3>\n        \"took\": 148,  <4>\n        \"timed_out\": false,\n        \"_shards\": {  <5>\n          \"total\": 12,\n          \"successful\": 12,\n          \"skipped\": 0,\n          \"failed\": 0\n        }\n      }\n    }\n  },\n  \"hits\": {\n    \"total\" : {\n        \"value\": 1,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 1,\n    \"hits\": [\n      {\n        \"_index\": \"cluster_one:my-index-000001\", <6>\n        \"_id\": \"0\",\n        \"_score\": 1,\n        \"_source\": {\n          \"user\": {\n            \"id\": \"kimchy\"\n          },\n          \"message\": \"GET /search HTTP/1.1 200 1070000\",\n          \"http\": {\n            \"response\":\n              {\n                \"status_code\": 200\n              }\n          }\n        }\n      }\n    ]\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"took\": 150/\"took\": \"$body.took\"/]\n// TESTRESPONSE[s/\"max_score\": 1/\"max_score\": \"$body.hits.max_score\"/]\n// TESTRESPONSE[s/\"_score\": 1/\"_score\": \"$body.hits.hits.0._score\"/]\n// TESTRESPONSE[s/\"total\": 12/\"total\": \"$body._shards.total\"/]\n// TESTRESPONSE[s/\"successful\": 12/\"successful\": \"$body._shards.successful\"/]\n// TESTRESPONSE[s/\"skipped\": 0/\"skipped\": \"$body._shards.skipped\"/]\n// TESTRESPONSE[s/\"took\": 148/\"took\": \"$body._clusters.details.cluster_one.took\"/]\n\n<1> This section of counters shows all possible cluster search states and how many cluster\nsearches are currently in that state. The clusters can be one of the following statuses: *running*,\n*successful* (searches on all shards were successful), *partial* (searches on at least\none shard of the cluster was successful and at least one failed), *skipped* (the search\nfailed on a cluster marked with `skip_unavailable`=`true`) or *failed* (the search\nfailed on a cluster marked with `skip_unavailable`=`false`).\n<2> The `_clusters/details` section shows metadata about the search on each cluster.\n<3> The index expression supplied by the user. If you provide a wildcard such as `logs-*`,\nthis section will show the value with the wildcard, not the concrete indices being searched.\n<4> How long (in milliseconds) the sub-search took on that cluster.\n<5> The shard details for the sub-search on that cluster.\n<6> The search response body includes the name of the remote cluster in the\n`_index` parameter.\n\n\n\n[discrete]\n[[ccs-search-multi-remote-cluster]]\n==== Search multiple remote clusters\n\nThe following <<search,search>> API request searches the `my-index-000001` index on\nthree clusters:\n\n* The local (\"querying\") cluster, with 10 shards\n* Two remote clusters, `cluster_one`, with 12 shards and `cluster_two`\nwith 6 shards.\n\n[source,console]\n--------------------------------------------------\nGET /my-index-000001,cluster_one:my-index-000001,cluster_two:my-index-000001/_search\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"_source\": [\"user.id\", \"message\", \"http.response.status_code\"]\n}\n--------------------------------------------------\n// TEST[continued]\n\nThe API returns the following response:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"took\": 150,\n  \"timed_out\": false,\n  \"num_reduce_phases\": 4,\n  \"_shards\": {\n    \"total\": 28,\n    \"successful\": 28,\n    \"failed\": 0,\n    \"skipped\": 0\n  },\n  \"_clusters\": {\n    \"total\": 3,\n    \"successful\": 3,\n    \"skipped\": 0,\n    \"running\": 0,\n    \"partial\": 0,\n    \"failed\": 0,\n    \"details\": {\n      \"(local)\": {            <1>\n        \"status\": \"successful\",\n        \"indices\": \"my-index-000001\",\n        \"took\": 21,\n        \"timed_out\": false,\n        \"_shards\": {\n          \"total\": 10,\n          \"successful\": 10,\n          \"skipped\": 0,\n          \"failed\": 0\n        }\n      },\n      \"cluster_one\": {\n        \"status\": \"successful\",\n        \"indices\": \"my-index-000001\",\n        \"took\": 48,\n        \"timed_out\": false,\n        \"_shards\": {\n          \"total\": 12,\n          \"successful\": 12,\n          \"skipped\": 0,\n          \"failed\": 0\n        }\n      },\n      \"cluster_two\": {\n        \"status\": \"successful\",\n        \"indices\": \"my-index-000001\",\n        \"took\": 141,\n        \"timed_out\": false,\n        \"_shards\": {\n          \"total\" : 6,\n          \"successful\" : 6,\n          \"skipped\": 0,\n          \"failed\": 0\n        }\n      }\n    }\n  },\n  \"hits\": {\n    \"total\" : {\n        \"value\": 3,\n        \"relation\": \"eq\"\n    },\n    \"max_score\": 1,\n    \"hits\": [\n      {\n        \"_index\": \"my-index-000001\", <2>\n        \"_id\": \"0\",\n        \"_score\": 2,\n        \"_source\": {\n          \"user\": {\n            \"id\": \"kimchy\"\n          },\n          \"message\": \"GET /search HTTP/1.1 200 1070000\",\n          \"http\": {\n            \"response\":\n              {\n                \"status_code\": 200\n              }\n          }\n        }\n      },\n      {\n        \"_index\": \"cluster_one:my-index-000001\", <3>\n        \"_id\": \"0\",\n        \"_score\": 1,\n        \"_source\": {\n          \"user\": {\n            \"id\": \"kimchy\"\n          },\n          \"message\": \"GET /search HTTP/1.1 200 1070000\",\n          \"http\": {\n            \"response\":\n              {\n                \"status_code\": 200\n              }\n          }\n        }\n      },\n      {\n        \"_index\": \"cluster_two:my-index-000001\", <4>\n        \"_id\": \"0\",\n        \"_score\": 1,\n        \"_source\": {\n          \"user\": {\n            \"id\": \"kimchy\"\n          },\n          \"message\": \"GET /search HTTP/1.1 200 1070000\",\n          \"http\": {\n            \"response\":\n              {\n                \"status_code\": 200\n              }\n          }\n        }\n      }\n    ]\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\"took\": 150/\"took\": \"$body.took\"/]\n// TESTRESPONSE[s/\"max_score\": 1/\"max_score\": \"$body.hits.max_score\"/]\n// TESTRESPONSE[s/\"_score\": 1/\"_score\": \"$body.hits.hits.0._score\"/]\n// TESTRESPONSE[s/\"_score\": 2/\"_score\": \"$body.hits.hits.1._score\"/]\n// TESTRESPONSE[s/\"total\": 28/\"total\": \"$body._shards.total\"/]\n// TESTRESPONSE[s/\"successful\": 28/\"successful\": \"$body._shards.successful\"/]\n// TESTRESPONSE[s/\"total\": 10/\"total\": \"$body._clusters.details.(local)._shards.total\"/]\n// TESTRESPONSE[s/\"successful\": 10/\"successful\": \"$body._clusters.details.(local)._shards.successful\"/]\n// TESTRESPONSE[s/\"took\": 21/\"took\": \"$body._clusters.details.(local).took\"/]\n// TESTRESPONSE[s/\"total\": 12/\"total\": \"$body._clusters.details.cluster_one._shards.total\"/]\n// TESTRESPONSE[s/\"successful\": 12/\"successful\": \"$body._clusters.details.cluster_one._shards.successful\"/]\n// TESTRESPONSE[s/\"took\": 48/\"took\": \"$body._clusters.details.cluster_one.took\"/]\n// TESTRESPONSE[s/\"total\" : 6/\"total\": \"$body._clusters.details.cluster_two._shards.total\"/]\n// TESTRESPONSE[s/\"successful\" : 6/\"successful\": \"$body._clusters.details.cluster_two._shards.successful\"/]\n// TESTRESPONSE[s/\"took\": 141/\"took\": \"$body._clusters.details.cluster_two.took\"/]\n\n<1> The local (querying) cluster is identified as \"(local)\".\n<2> This document's `_index` parameter doesn't include a cluster name. This\nmeans the document came from the local cluster.\n<3> This document came from `cluster_one`.\n<4> This document came from `cluster_two`.\n\n\n[discrete]\n[[ccs-async-search-minimize-roundtrips-true]]\n=== Using async search for {ccs} with ccs_minimize_roundtrips=true\n\nRemote clusters can be queried asynchronously using the <<async-search,async search>> API.\nA {ccs} accepts a <<ccs-minimize-roundtrips,`ccs_minimize_roundtrips`>> parameter. For\nasynchronous searches it defaults to `false`. (Note: for synchronous searches it defaults to `true`.)\nSee <<ccs-min-roundtrips>> to learn more about this option.\n\nThe following request does an asynchronous search of the `my-index-000001` index using\n`ccs_minimize_roundtrips=true` against three clusters (same ones as the previous example).\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001,cluster_one:my-index-000001,cluster_two:my-index-000001/_async_search?ccs_minimize_roundtrips=true\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"_source\": [\"user.id\", \"message\", \"http.response.status_code\"]\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[s/ccs_minimize_roundtrips=true/ccs_minimize_roundtrips=true&wait_for_completion_timeout=100ms&keep_on_completion=true/]\n\n\nThe API returns the following response:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"id\": \"FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=\", <1>\n  \"is_partial\": true,\n  \"is_running\": true,\n  \"start_time_in_millis\": 1685563581380,\n  \"expiration_time_in_millis\": 1685995581380,\n  \"response\": {\n    \"took\": 1020,\n    \"timed_out\": false,\n    \"num_reduce_phases\": 0,\n    \"_shards\": {\n      \"total\": 10,     <2>\n      \"successful\": 0,\n      \"failed\": 0,\n      \"skipped\": 0\n    },\n    \"_clusters\": {    <3>\n      \"total\" : 3,\n      \"successful\" : 0,\n      \"skipped\": 0,\n      \"running\": 3,\n      \"partial\": 0,\n      \"failed\": 0,\n      \"details\": {\n        \"(local)\": {\n          \"status\": \"running\",\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false\n        },\n        \"cluster_one\": {\n          \"status\": \"running\",\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false\n        },\n        \"cluster_one\": {\n          \"status\": \"running\",\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false\n        }\n      }\n    },\n    \"hits\": {\n      \"total\" : {\n          \"value\": 0,\n          \"relation\": \"eq\"\n      },\n      \"max_score\": null,\n      \"hits\": []\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip: hard to reproduce initial state]\n\n<1> The async search id.\n<2> When `ccs_minimize_roundtrips` = `true` and searches on the remote clusters\nare still running, this section indicates the number of shards in scope for the\nlocal cluster only and any clusters that have finished their search so far.\nThis will be updated to include the total number of shards across all clusters only\nwhen the search is completed. When `ccs_minimize_roundtrips`= `false`, the total shard\ncount across all clusters is known up front and will be correct.\n<3> The `_clusters` section indicates that 3 clusters are in scope for the search\nand all are currently in the \"running\" state.\n\nIf you query the <<get-async-search,get async search>> endpoint while the query is\nstill running, you will see an update in the `_clusters` and `_shards` section of\nthe response as each cluster finishes its search.\n\nIf you set `ccs_minimize_roundtrips=false`, then you will also see partial aggregation\nresults from shards (from any cluster) that have finished, but no results are shown in\n\"hits\" section until the search has completed.\n\nIf you set `ccs_minimize_roundtrips=true`, then you will also see partial results\nin the \"hits\" and \"aggregations\" section of the response from all clusters that have\ncompleted so far. (Note: you can also see partial aggregation results from the local cluster\neven before it finishes.) The example below shows the `ccs_minimize_roundtrips=true` case.\n\n\n[source,console]\n--------------------------------------------------\nGET /_async_search/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=\n--------------------------------------------------\n// TEST[continued s/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=/\\${body.id}/]\n\nResponse:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"id\": \"FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=\",\n  \"is_partial\": true,\n  \"is_running\": true,\n  \"start_time_in_millis\": 1685564911108,\n  \"expiration_time_in_millis\": 1685996911108,\n  \"response\": {\n    \"took\": 11164,\n    \"timed_out\": false,\n    \"terminated_early\": false,\n    \"_shards\": {\n      \"total\": 22,\n      \"successful\": 22,  <1>\n      \"skipped\": 0,\n      \"failed\": 0\n    },\n    \"_clusters\": {\n      \"total\": 3,\n      \"successful\": 2,  <2>\n      \"skipped\": 0,\n      \"running\": 1,\n      \"partial\": 0,\n      \"failed\": 0,\n      \"details\": {\n        \"(local)\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 2034,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 10,\n            \"successful\": 10,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_one\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 9039,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 12,\n            \"successful\": 12,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_two\": {\n          \"status\": \"running\",\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false\n        }\n      }\n    },\n    \"hits\": {\n      \"total\": {\n        \"value\": 542,  <3>\n        \"relation\": \"eq\"\n      },\n      \"max_score\": 1.7232,\n      \"hits\": [...list of hits here...] <4>\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip: hard to reproduce intermediate results]\n\n\n<1> Searches on all shards of the local cluster and remote `cluster_one` cluster have completed.\n<2> Since two clusters have completed the search, the \"successful\" clusters entry\nis set to 2 and \"running\" clusters entry is reduced to 1. The `_clusters` response metadata\nwill be updated as each cluster finishes.\n<3> Number of hits from the completed searches so far. Final hits are not shown\nuntil searches on all clusters have been completed and merged. Thus, the \"hits\"\nsection can change as you call this endpoint until the search is completely done.\n\n\nAfter searches on all the clusters have completed, querying the\n<<get-async-search,get async search>> endpoint will show the final\nstatus of the `_clusters` and `_shards` section as well as the hits\nand any aggregation results.\n\n[source,console]\n--------------------------------------------------\nGET /_async_search/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=\n--------------------------------------------------\n// TEST[continued s/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=/\\${body.id}/]\n\n\nResponse:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"id\": \"FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=\",\n  \"is_partial\": false,\n  \"is_running\": false,\n  \"start_time_in_millis\": 1685564911108,\n  \"expiration_time_in_millis\": 1685996911108,\n  \"completion_time_in_millis\": 1685564938727,  <1>\n  \"response\": {\n    \"took\": 27619,\n    \"timed_out\": false,\n    \"num_reduce_phases\": 4,\n    \"_shards\": {\n      \"total\": 28,\n      \"successful\": 28,  <2>\n      \"skipped\": 0,\n      \"failed\": 0\n    },\n    \"_clusters\": {\n      \"total\": 3,\n      \"successful\": 3,   <3>\n      \"skipped\": 0,\n      \"running\": 0,\n      \"partial\": 0,\n      \"failed\": 0,\n      \"details\": {\n        \"(local)\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 2034,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 10,\n            \"successful\": 10,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_one\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 9039,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 12,\n            \"successful\": 12,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_two\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 27550,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 6,\n            \"successful\": 6,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        }\n      }\n    },\n    \"hits\": {\n      \"total\": {\n        \"value\": 1067,\n        \"relation\": \"eq\"\n      },\n      \"max_score\": 1.8293576,\n      \"hits\": [...list of hits here...]\n    }\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=/$body.id/]\n// TESTRESPONSE[s/\"is_partial\": true/\"is_partial\": $body.is_partial/]\n// TESTRESPONSE[s/\"is_running\": true/\"is_running\": $body.is_running/]\n// TESTRESPONSE[s/1685564911108/$body.start_time_in_millis/]\n// TESTRESPONSE[s/1685996911108/$body.expiration_time_in_millis/]\n// TESTRESPONSE[s/1685564938727/$body.completion_time_in_millis/]\n// TESTRESPONSE[s/\"took\": 27619/\"took\": \"$body.response.took\"/]\n// TESTRESPONSE[s/\"took\": 2034/\"took\": \"$body.$_path\"/]\n// TESTRESPONSE[s/\"took\": 9039/\"took\": \"$body.$_path\"/]\n// TESTRESPONSE[s/\"took\": 27550/\"took\": \"$body.$_path\"/]\n// TESTRESPONSE[s/\"total\": 28/\"total\": $body.response._shards.total/]\n// TESTRESPONSE[s/\"successful\": 28/\"successful\": $body.response._shards.successful/]\n// TESTRESPONSE[s/\"successful\": 3/\"successful\": $body.response._clusters.successful/]\n// TESTRESPONSE[s/\"value\": 1067/\"value\": \"$body.response.hits.total.value\"/]\n// TESTRESPONSE[s/\"relation\": \"eq\"/\"relation\": \"$body.response.hits.total.relation\"/]\n// TESTRESPONSE[s/\"max_score\": 1.8293576/\"max_score\": \"$body.response.hits.max_score\"/]\n// TESTRESPONSE[s/\"hits\": \\[...list of hits here...\\]/\"hits\": $body.response.hits.hits/]\n// TESTRESPONSE[s/\"total\": \\d+/\"total\": $body.$_path/]\n// TESTRESPONSE[s/\"successful\": \\d+/\"successful\": $body.$_path/]\n\n\n<1> Once the search has finished, the completion_time is present.\n<2> The `_shards` section is now updated to show that 28 total shards\nwere searched across all clusters and that all were successful.\n<3> The `_clusters` section shows that searches on all 3 clusters were successful.\n\n\n[discrete]\n[[cross-cluster-search-failures]]\n=== {ccs-cap} failures\n\nFailures during a {ccs} can result in one of two conditions:\n\n. partial results (2xx HTTP status code)\n. a failed search (4xx or 5xx HTTP status code)\n\nFailure details will be present in the search response in both cases.\n\nA search will be failed if a cluster marked with `skip_unavailable`=`false`\nis unavailable, disconnects during the search, or has search failures on\nall shards. In all other cases, failures will result in partial results.\n\nSearch failures on individual shards will be present in both the `_shards`\nsection and the `_clusters` section of the response.\n\nA failed search will have an additional top-level `errors` entry in the response.\n\nHere is an example of a search with partial results due to a failure on one shard\nof one cluster. The search would be similar to ones shown previously. The\n`_async_search/status` endpoint is used here to show the completion status and\nnot show the hits.\n\n[source,console]\n--------------------------------------------------\nGET /_async_search/status/FmpwbThueVB4UkRDeUxqb1l4akIza3cbWEJyeVBPQldTV3FGZGdIeUVabXBldzoyMDIw\n--------------------------------------------------\n// TEST[continued s/FmpwbThueVB4UkRDeUxqb1l4akIza3cbWEJyeVBPQldTV3FGZGdIeUVabXBldzoyMDIw/\\${body.id}/]\n\n\nResponse:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"id\": \"FmpwbThueVB4UkRDeUxqb1l4akIza3cbWEJyeVBPQldTV3FGZGdIeUVabXBldzoyMDIw\",\n  \"is_partial\": true,  <1>\n  \"is_running\": false,\n  \"start_time_in_millis\": 1692106901478,\n  \"expiration_time_in_millis\": 1692538901478,\n  \"completion_time_in_millis\": 1692106903547,\n  \"response\": {\n    \"took\": 2069,\n    \"timed_out\": false,\n    \"num_reduce_phases\": 4,\n    \"_shards\": {\n      \"total\": 28,\n      \"successful\": 27,\n      \"skipped\": 0,\n      \"failed\": 1,\n      \"failures\": [   <2>\n        {\n          \"shard\": 1,\n          \"index\": \"cluster_two:my-index-000001\",\n          \"node\": \"LMpUnAu0QEeCUMfg_56sAg\",\n          \"reason\": {\n            \"type\": \"query_shard_exception\",\n            \"reason\": \"failed to create query: [my-index-000001][1] exception message here\",\n            \"index_uuid\": \"4F2VWx8RQSeIhUE-nksvCQ\",\n            \"index\": \"cluster_two:my-index-000001\",\n            \"caused_by\": {\n              \"type\": \"runtime_exception\",\n              \"reason\": \"runtime_exception: [my-index-000001][1] exception message here\"\n            }\n          }\n        }\n      ]\n    },\n    \"_clusters\": {\n      \"total\": 3,\n      \"successful\": 2,\n      \"skipped\": 0,\n      \"running\": 0,\n      \"partial\": 1,   <3>\n      \"failed\": 0,\n      \"details\": {\n        \"(local)\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 1753,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 10,\n            \"successful\": 10,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_one\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 2054,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 12,\n            \"successful\": 12,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_two\": {\n          \"status\": \"partial\",   <4>\n          \"indices\": \"my-index-000001\",\n          \"took\": 2039,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 6,\n            \"successful\": 5,\n            \"skipped\": 0,\n            \"failed\": 1   <5>\n          },\n          \"failures\": [  <6>\n            {\n              \"shard\": 1,\n              \"index\": \"cluster_two:my-index-000001\",\n              \"node\": \"LMpUnAu0QEeCUMfg_56sAg\",\n              \"reason\": {\n                \"type\": \"query_shard_exception\",\n                \"reason\": \"failed to create query: [my-index-000001][1] exception message here\",\n                \"index_uuid\": \"4F2VWx8RQSeIhUE-nksvCQ\",\n                \"index\": \"cluster_two:my-index-000001\",\n                \"caused_by\": {\n                  \"type\": \"runtime_exception\",\n                  \"reason\": \"runtime_exception: [my-index-000001][1] exception message here\"\n                }\n              }\n            }\n          ]\n        }\n      }\n    },\n    \"hits\": {\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip: hard to reproduce failure results]\n\n\n<1> The search results are marked as partial, since at least one shard search failed.\n<2> The `_shards` section includes shard failure info.\n<3> Clusters that have partial results are still marked as \"partial\". They are\nmarked with status \"skipped\" (or \"failed\") only if no data was returned from the search.\n<4> The `partial` status has been applied to the cluster with partial results.\n<5> The failed shard count is shown.\n<6> The shard failures are listed under the cluster/details entry also.\n\n\n\nHere is an example where both `cluster_one` and `cluster_two` lost connectivity\nduring a {ccs}. Since `cluster_one` is marked as `skip_unavailable`=`true`,\nits status is `skipped` and since `cluster_two` is marked as `skip_unavailable`=`false`,\nits status is `failed`. Since there was a `failed` cluster, a top level `error`\nis also present and this returns an HTTP status of 500 (not shown).\n\nIf you want the search to still return results even when a cluster is\nunavailable, set `skip_unavailable`=`true` for all the remote clusters.\n\n[source,console]\n--------------------------------------------------\nGET /_async_search/FjktRGJ1Y2w1U0phLTRhZnVyeUZ2MVEbWEJyeVBPQldTV3FGZGdIeUVabXBldzo5NzA4\n--------------------------------------------------\n// TEST[continued s/FjktRGJ1Y2w1U0phLTRhZnVyeUZ2MVEbWEJyeVBPQldTV3FGZGdIeUVabXBldzo5NzA4/\\${body.id}/]\n\n\nResponse:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"id\": \"FjktRGJ1Y2w1U0phLTRhZnVyeUZ2MVEbWEJyeVBPQldTV3FGZGdIeUVabXBldzo5NzA4\",\n  \"is_partial\": true,\n  \"is_running\": false,\n  \"start_time_in_millis\": 1692112102650,\n  \"expiration_time_in_millis\": 1692544102650,\n  \"completion_time_in_millis\": 1692112106177,\n  \"response\": {\n    \"took\": 3527,\n    \"timed_out\": false,\n    \"terminated_early\": false,\n    \"_shards\": {\n      \"total\": 10,   <1>\n      \"successful\": 10,\n      \"skipped\": 0,\n      \"failed\": 0\n    },\n    \"_clusters\": {\n      \"total\": 3,\n      \"successful\": 1,\n      \"skipped\": 1,\n      \"running\": 0,\n      \"partial\": 0,\n      \"failed\": 1,\n      \"details\": {\n        \"(local)\": {\n          \"status\": \"successful\",\n          \"indices\": \"my-index-000001\",\n          \"took\": 1473,\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 10,\n            \"successful\": 10,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_one\": {\n          \"status\": \"skipped\",   <2>\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false,\n          \"failures\": [\n            {\n              \"shard\": -1,\n              \"index\": null,\n              \"reason\": {\n                \"type\": \"node_disconnected_exception\",   <3>\n                \"reason\": \"[myhostname1][35.238.149.1:9300][indices:data/read/search] disconnected\"\n              }\n            }\n          ]\n        },\n        \"cluster_two\": {\n          \"status\": \"failed\",   <4>\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false,\n          \"failures\": [\n            {\n              \"shard\": -1,\n              \"index\": null,\n              \"reason\": {\n                \"type\": \"node_disconnected_exception\",\n                \"reason\": \"[myhostname2][35.238.149.2:9300][indices:data/read/search] disconnected\"\n              }\n            }\n          ]\n        }\n      }\n    },\n    \"hits\": {\n    },\n  }\n  \"error\": {  <5>\n    \"type\": \"status_exception\",\n    \"reason\": \"error while executing search\",\n    \"caused_by\": {\n      \"type\": \"node_disconnected_exception\",\n      \"reason\": \"[myhostname2][35.238.149.2:9300][indices:data/read/search] disconnected\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip: hard to reproduce failure results]\n\n<1> The shard accounting will often be only partial when errors like this occur,\nsince we need to be able to get shard info from remote clusters on each search.\n<2> `cluster_one` disconnected during the search and it returned no results.\nSince it is marked in the remote cluster configuration as `skip_unavailable`=`true`,\nits status is \"skipped\", which will not fail the entire search.\n<3> The failures list shows that the remote cluster node disconnected from the\nquerying cluster.\n<4> `cluster_two` status is \"failed\", since it is marked in the remote cluster\nconfiguration as `skip_unavailable`=`false`.\n<5> A top level `error` entry is included when there is a \"failed\" cluster.\n\n\n[discrete]\n[[exclude-problematic-clusters]]\n=== Excluding clusters or indices from a {ccs}\n\nIf you use a wildcard to include a large list of clusters and/or indices,\nyou can explicitly exclude one or more clusters or indices with a `-` minus\nsign in front of the cluster or index.\n\nTo exclude an entire cluster, you would put the minus sign in front of the\ncluster alias, such as: `-mycluster:*`. When excluding a cluster, you must\nuse `*` in the index position or an error will be returned.\n\nTo exclude a specific remote index, you would put the minus sign in front\nof the index, such as `mycluster:-myindex`.\n\n*Exclude a remote cluster*\n\nHere's how you would exclude `cluster_three` from a\n{ccs} that uses a wildcard to specify a list of clusters:\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001,cluster*:my-index-000001,-cluster_three:*/_async_search  <1>\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"_source\": [\"user.id\", \"message\", \"http.response.status_code\"]\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[s/ccs_minimize_roundtrips=true/ccs_minimize_roundtrips=true&wait_for_completion_timeout=100ms&keep_on_completion=true/]\n\n<1> The `cluster*` notation would naturally include `cluster_one`, `cluster_two` and `cluster_three`.\nTo exclude `cluster_three` use a `-` before the cluster name along with a simple wildcard `*` in\nthe index position. This indicates that you do not want the search to make any contact with\n`cluster_three`.\n\n\n*Exclude a remote index*\n\nSuppose you want to search all indices matching `my-index-*` but you want to exclude\n`my-index-000001` on `cluster_three`. Here's how you could do that:\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001,cluster*:my-index-*,cluster_three:-my-index-000001/_async_search  <1>\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"_source\": [\"user.id\", \"message\", \"http.response.status_code\"]\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[s/ccs_minimize_roundtrips=true/ccs_minimize_roundtrips=true&wait_for_completion_timeout=100ms&keep_on_completion=true/]\n\n<1> This will *not* exclude `cluster_three` from the search. It will still be\ncontacted and told to search any indexes matching `my-index-*` except for\n`my-index-000001`.\n\n\n\n[discrete]\n[[ccs-async-search-minimize-roundtrips-false]]\n=== Using async search for {ccs} with ccs_minimize_roundtrips=false\n\nThe `_shards` and `_clusters` section of the response behave\ndifferently when `ccs_minimize_roundtrips` is `false`.\n\nKey differences are:\n\n. The `_shards` section total count will be accurate immediately as the total number\nof shards is gathered from all clusters before the search starts.\n\n. The `_shards` section will be incrementally updated as searches on individual\nshards complete, whereas when minimizing roundtrips, the shards section will be\nupdated as searches on shards complete on the local cluster and then as each\nremote cluster reports back its full search results.\n\n. The `_cluster` section starts off listing all of its shard counts, since\nthey are also obtained before the query phase begins.\n\nExample using the same setup as in the previous section (`ccs_minimize_roundtrips=true`):\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001,cluster_one:my-index-000001,cluster_two:my-index-000001/_async_search?ccs_minimize_roundtrips=false\n{\n  \"query\": {\n    \"match\": {\n      \"user.id\": \"kimchy\"\n    }\n  },\n  \"_source\": [\"user.id\", \"message\", \"http.response.status_code\"]\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[s/ccs_minimize_roundtrips=false/ccs_minimize_roundtrips=false&wait_for_completion_timeout=2s&keep_on_completion=true/]\n\n\nThe API returns the following response if the query takes longer than\nthe `wait_for_completion_timeout` duration (see <<async-search>>).\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"id\": \"FklQYndoTDJ2VEFlMEVBTzFJMGhJVFEaLVlKYndBWWZSMUdicUc4WVlEaFl4ZzoxNTU=\",\n  \"is_partial\": true,\n  \"is_running\": true,\n  \"start_time_in_millis\": 1685563581380,\n  \"expiration_time_in_millis\": 1685995581380,\n  \"response\": {\n    \"took\": 1020,\n    \"timed_out\": false,\n    \"_shards\": {\n      \"total\": 28,     <1>\n      \"successful\": 0,\n      \"failed\": 0,\n      \"skipped\": 0\n    },\n    \"_clusters\": {\n      \"total\" : 3,\n      \"successful\": 0,\n      \"skipped\": 0,\n      \"running\": 3,    <2>\n      \"partial\": 0,\n      \"failed\": 0,\n      \"details\": {    <3>\n        \"(local)\": {\n          \"status\": \"running\",\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 10,\n            \"successful\": 0,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_one\": {\n          \"status\": \"running\",\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 12,\n            \"successful\": 0,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        },\n        \"cluster_two\": {\n          \"status\": \"running\",\n          \"indices\": \"my-index-000001\",\n          \"timed_out\": false,\n          \"_shards\": {\n            \"total\": 6,\n            \"successful\": 0,\n            \"skipped\": 0,\n            \"failed\": 0\n          }\n        }\n      }\n    },\n    \"hits\": {\n      \"total\" : {\n          \"value\": 0,\n          \"relation\": \"eq\"\n      },\n      \"max_score\": null,\n      \"hits\": []\n    }\n  }\n}\n--------------------------------------------------\n// TEST[skip: hard to reproduce intermediate results]\n\n\n<1> All shards from all clusters in scope for the search are listed here. Watch this\nsection and/or the _clusters section for updates to monitor search progress.\n<2> From the `_clusters` section we can see that all the clusters are in \"running\" state.\n<3> The `_clusters` section shows that shard information was successfully\ngathered from all 3 clusters and the total shard count on each cluster is listed.\n\n\n\n\n[discrete]\n[[skip-unavailable-clusters]]\n=== Optional remote clusters\n\nBy default, a {ccs} fails if a remote cluster in the request is unavailable\nor returns an error where the search on all shards failed. Use the\n`skip_unavailable` cluster setting to mark a specific remote cluster as\neither optional or required for {ccs}.\n\nIMPORTANT: In Elasticsearch 8.15, the default value for `skip_unavailable` was\nchanged from `false` to `true`. Before Elasticsearch 8.15, if you want a cluster\nto be treated as optional for a {ccs}, then you need to set that configuration.\nFrom Elasticsearch 8.15 forward, you need to set the configuration in order to\nmake a cluster required for the {ccs}.\n\nIf `skip_unavailable` is `true`, a {ccs}:\n\n* Skips the remote cluster if its nodes are unavailable during the search. The\nresponse's `_clusters.skipped` value contains a count of any skipped clusters\nand the `_clusters.details` section of the response will show a `skipped` status.\n\n* Ignores errors returned by the remote cluster, such as errors related to\nunavailable shards or indices. This can include errors related to search\nparameters such as <<api-multi-index,`allow_no_indices`>> and\n<<api-multi-index,`ignore_unavailable`>>.\n\n* Ignores the <<search-partial-responses,`allow_partial_search_results`>>\nparameter and the related `search.default_allow_partial_results` cluster setting\nwhen searching the remote cluster. This means searches on the remote cluster may\nreturn partial results.\n\nYou can modify the `skip_unavailable` setting by editing the `cluster.remote.<cluster_alias>`\nsettings in the elasticsearch.yml config file. For example:\n\n```\ncluster:\n    remote:\n        cluster_one:\n            seeds: 35.238.149.1:9300\n            skip_unavailable: false\n        cluster_two:\n            seeds: 35.238.149.2:9300\n            skip_unavailable: true\n```\n\nOr you can set the cluster.remote settings via the\n<<cluster-update-settings,cluster update settings>> API as shown\n<<ccs-remote-cluster-setup, here>>.\n\nWhen a remote cluster configured with `skip_unavailable: true` (such as\n`cluster_two` above) is disconnected or unavailable during a {ccs}, {es} won't\ninclude matching documents from that cluster in the final results and the\nsearch will be considered successful (HTTP status 200 OK).\n\nIf at least one shard from a cluster provides search results, those results will\nbe used and the search will return partial data. This is true regardless of\nthe `skip_unavailable` setting of the remote cluster. (If doing {ccs} using async\nsearch, the `is_partial` field will be set to `true` to indicate partial results.)\n\n[discrete]\n[[ccs-network-delays]]\n=== How {ccs} handles network delays\n\nBecause {ccs} involves sending requests to remote clusters, any network delays\ncan impact search speed. To avoid slow searches, {ccs} offers two options for\nhandling network delays:\n\n<<ccs-min-roundtrips,Minimize network roundtrips>>::\nBy default, {es} reduces the number of network roundtrips between remote\nclusters. This reduces the impact of network delays on search speed. However,\n{es} can't reduce network roundtrips for large search requests, such as those\nincluding a <<scroll-search-results, scroll>> or\n<<inner-hits,inner hits>>.\n+\nSee <<ccs-min-roundtrips>> to learn how this option works.\n\n<<ccs-unmin-roundtrips, Don't minimize network roundtrips>>:: For search\nrequests that include a scroll or inner hits, {es} sends multiple outgoing and\ningoing requests to each remote cluster. You can also choose this option by\nsetting the <<ccs-minimize-roundtrips,`ccs_minimize_roundtrips`>> parameter to\n`false`. While typically slower, this approach may work well for networks with\nlow latency.\n+\nSee <<ccs-unmin-roundtrips>> to learn how this option works.\n\nNOTE: The <<search-vector-tile-api,vector tile search API>> always minimizes\nnetwork roundtrips and doesn't include the `ccs_minimize_roundtrips` parameter.\n\nNOTE: The <<approximate-knn, Approximate kNN search>> doesn't support minimizing\nnetwork roundtrips, and sets the parameter `ccs_minimize_roundtrips` to `false`.\n\n[discrete]\n[[ccs-min-roundtrips]]\n==== Considerations for choosing whether to minimize roundtrips in a {ccs}\n\nAdvantages of minimizing roundtrips:\n\n. For cross-cluster searches that query a large number of shards, the minimize roundtrips\noption typically provides much better performance. This is especially true if the clusters\nbeing searched have high network latency (e.g., distant geographic regions).\n\n. When doing an async {ccs}, the `GET _async_search/<search_id>` endpoint will provide both\ntop hits and aggregations from all clusters that have reported back results even while the search\nis still running on other clusters. In other words, it provides \"incremental\" partial results as\nthe search progresses. Note that if the local cluster is included in the search, it has special\nhandling in that it can show partial aggregations (but not partial top hits) while the search\non the local cluster is still running.\n\n\nNot minimizing roundtrips when using async-search allows you to get back incremental results of\nany aggregations in your query as individual shards complete (rather than whole clusters) while\nthe search is still running, but top hits are not shown until the search has completed on all clusters.\n\nBy default, synchronous searches minimize roundtrips, while asynchronous searches\ndo not. You can override the default by using the `ccs_minimize_roundtrips` parameter,\nsetting it to either `true` or `false`, as shown in several examples earlier in this\ndocument.\n\n\n[discrete]\n[[ccs-min-roundtrips-true]]\n\n==== Minimize network roundtrips\n\nHere's how {ccs} works when you minimize network roundtrips.\n\n. You send a {ccs} request to your local cluster. A coordinating node in that\ncluster receives and parses the request.\n+\nimage:images/ccs/ccs-min-roundtrip-client-request.svg[]\n\n. The coordinating node sends a single search request to each cluster, including\nthe local cluster. Each cluster performs the search request independently,\napplying its own cluster-level settings to the request.\n+\nimage:images/ccs/ccs-min-roundtrip-cluster-search.svg[]\n\n. Each remote cluster sends its search results back to the coordinating node.\n+\nimage:images/ccs/ccs-min-roundtrip-cluster-results.svg[]\n\n. After collecting results from each cluster, the coordinating node returns the\nfinal results in the {ccs} response.\n+\nimage:images/ccs/ccs-min-roundtrip-client-response.svg[]\n\n[discrete]\n[[ccs-unmin-roundtrips]]\n==== Don't minimize network roundtrips\n\nHere's how {ccs} works when you don't minimize network roundtrips.\n\n. You send a {ccs} request to your local cluster. A coordinating node in that\ncluster receives and parses the request.\n+\nimage:images/ccs/ccs-min-roundtrip-client-request.svg[]\n\n. The coordinating node sends a \"search shards\" transport layer request\nto each remote cluster to have them to perform a \"can match\" search to determine\nwhich shards on each cluster should be searched.\n+\nimage:images/ccs/ccs-min-roundtrip-cluster-search.svg[]\n\n. Each remote cluster sends its response back to the coordinating node.\nThis response contains information about the indices and shards the {ccs}\nrequest will be executed on.\n+\nimage:images/ccs/ccs-min-roundtrip-cluster-results.svg[]\n\n. The coordinating node sends a search request to each shard, including those in\nits own cluster. Each shard performs the search request independently.\n+\n[WARNING]\n====\nWhen network roundtrips aren't minimized, the search is executed as if all data\nwere in the coordinating node's cluster. We recommend updating cluster-level\nsettings that limit searches, such as `action.search.shard_count.limit`,\n`pre_filter_shard_size`, and `max_concurrent_shard_requests`, to account for\nthis. If these limits are too low, the search may be rejected.\n====\n+\nimage:images/ccs/ccs-dont-min-roundtrip-shard-search.svg[]\n\n. Each shard sends its search results back to the coordinating node.\n+\nimage:images/ccs/ccs-dont-min-roundtrip-shard-results.svg[]\n\n. After collecting results from each cluster, the coordinating node returns the\nfinal results in the {ccs} response.\n+\nimage:images/ccs/ccs-min-roundtrip-client-response.svg[]\n\n[discrete]\n[[ccs-supported-configurations]]\n=== Supported {ccs} configurations\n\nIn 8.0+, Elastic supports searches from a local cluster to a remote cluster\nrunning:\n\n* The previous minor version.\n* The same version.\n* A newer minor version in the same major version.\n\nElastic also supports searches from a local cluster running the last minor\nversion of a major version to a remote cluster running any minor version in the\nfollowing major version. For example, a local 7.17 cluster can search any\nremote 8.x cluster.\n\n[[ccs-version-compatibility]]\ninclude::{es-ref-dir}/search/search-your-data/ccs-version-compat-matrix.asciidoc[]\n\nIMPORTANT: For the <<eql-search-api,EQL search API>>, the local and remote\nclusters must use the same {es} version if they have versions prior to 7.17.7 (included) or prior to 8.5.1 (included).\n\nFor example, a local 8.0 cluster can search a remote 7.17 or any remote 8.x\ncluster. However, a search from a local 8.0 cluster to a remote 7.16 or 6.8\ncluster is not supported.\n\nOnly features that exist across all searched clusters are supported. Using a\nfeature with a remote cluster where the feature is not supported will result in\nundefined behavior.\n\nA {ccs} using an unsupported configuration may still work. However, such\nsearches aren't tested by Elastic, and their behavior isn't guaranteed.\n\n[discrete]\n[[ensure-ccs-support]]\n==== Ensure {ccs} support\n\nThe simplest way to ensure your clusters support {ccs} is to keep each cluster\non the same version of {es}. If you need to maintain clusters with different\nversions, you can:\n\n* Maintain a dedicated cluster for {ccs}. Keep this cluster on the earliest\nversion needed to search the other clusters. For example, if you have 7.17 and 8.x clusters,\nyou can maintain a dedicated 7.17 cluster to use as the local cluster for {ccs}.\n\n* Keep each cluster no more than one minor version apart. This lets you use any\ncluster as the local cluster when running a {ccs}.\n\n[discrete]\n[[ccs-during-upgrade]]\n==== {ccs-cap} during an upgrade\n\n// tag::ccs-during-upgrade[]\nYou can still search a remote cluster while performing a\nrolling upgrade on the local cluster. However, the local\ncoordinating node's \"upgrade from\" and \"upgrade to\" version must be compatible\nwith the remote cluster's gateway node.\n\nWARNING: Running multiple versions of {es} in the same cluster beyond the\nduration of an upgrade is not supported.\n\nFor more information about upgrades, see\n{stack-ref}/upgrading-elasticsearch.html[Upgrading {es}].\n// end::ccs-during-upgrade[]\n"
}
{
    "meta": {
        "size": 11815,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/data-tiers.html",
        "type": "documentation",
        "role": [
            "xpack",
            "screenshot"
        ],
        "has_code": true,
        "title": "data-tiers",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[data-tiers]]\n== Data tiers\n\nA _data tier_ is a collection of <<modules-node,nodes>> within a cluster that share the same \n<<node-roles,data node role>>, and a hardware profile that's appropriately sized for the role. Elastic recommends that nodes in the same tier share the same \nhardware profile to avoid <<hotspotting,hot spotting>>. \n\nThe data tiers that you use, and the way that you use them, depends on the data's <<data-management,category>>.\n\nThe following data tiers are can be used with each data category:\n\nContent data:\n\n* <<content-tier,Content tier>> nodes handle the indexing and query load for non-timeseries \nindices, such as a product catalog.\n\nTime series data:\n\n* <<hot-tier,Hot tier>> nodes handle the indexing load for time series data, \nsuch as logs or metrics. They hold your most recent, most-frequently-accessed data.\n* <<warm-tier,Warm tier>> nodes hold time series data that is accessed less-frequently\nand rarely needs to be updated.\n* <<cold-tier,Cold tier>> nodes hold time series data that is accessed\ninfrequently and not normally updated. To save space, you can keep\n<<fully-mounted,fully mounted indices>> of\n<<ilm-searchable-snapshot,{search-snaps}>> on the cold tier. These fully mounted\nindices eliminate the need for replicas, reducing required disk space by\napproximately 50% compared to the regular indices.\n* <<frozen-tier,Frozen tier>> nodes hold time series data that is accessed \nrarely and never updated. The frozen tier stores <<partially-mounted,partially\nmounted indices>> of <<ilm-searchable-snapshot,{search-snaps}>> exclusively.\nThis extends the storage capacity even further \u2014 by up to 20 times compared to\nthe warm tier. \n\nTIP: The performance of an {es} node is often limited by the performance of the underlying storage and hardware profile. \nFor example hardware profiles, refer to Elastic Cloud's {cloud}/ec-reference-hardware.html[instance configurations]. \nReview our recommendations for optimizing your storage for <<indexing-use-faster-hardware,indexing>> and <<search-use-faster-hardware,search>>.\n\nIMPORTANT: {es} generally expects nodes within a data tier to share the same \nhardware profile. Variations not following this recommendation should be \ncarefully architected to avoid <<hotspotting,hot spotting>>.\n\nThe way data tiers are used often depends on the data's category:\n\n- Content data remains on the <<content-tier,content tier>> for its entire\ndata lifecycle. \n\n- Time series data may progress through the \ndescending temperature data tiers (hot, warm, cold, and frozen) according to your \nperformance, resiliency, and data retention requirements. \n+ \nYou can automate these lifecycle transitions using the <<data-streams,data stream lifecycle>>, or custom <<index-lifecycle-management,{ilm}>>. \n\n[discrete]\n[[available-tier]]\n=== Available data tiers\n\nLearn more about each data tier, including when and how it should be used.\n\n[discrete]\n[[content-tier]]\n==== Content tier\n\n// tag::content-tier[]\nData stored in the content tier is generally a collection of items such as a product catalog or article archive.\nUnlike time series data, the value of the content remains relatively constant over time,\nso it doesn't make sense to move it to a tier with different performance characteristics as it ages.\nContent data typically has long data retention requirements, and you want to be able to retrieve\nitems quickly regardless of how old they are.\n\nContent tier nodes are usually optimized for query performance--they prioritize processing power over IO throughput\nso they can process complex searches and aggregations and return results quickly.\nWhile they are also responsible for indexing, content data is generally not ingested at as high a rate\nas time series data such as logs and metrics. From a resiliency perspective the indices in this\ntier should be configured to use one or more replicas.\n\nThe content tier is required and is often deployed within the same node \ngrouping as the hot tier. System indices and other indices that aren't part\nof a data stream are automatically allocated to the content tier. \n// end::content-tier[]\n\n[discrete]\n[[hot-tier]]\n==== Hot tier\n\n// tag::hot-tier[]\nThe hot tier is the {es} entry point for time series data and holds your most-recent,\nmost-frequently-searched time series data.\nNodes in the hot tier need to be fast for both reads and writes,\nwhich requires more hardware resources and faster storage (SSDs).\nFor resiliency, indices in the hot tier should be configured to use one or more replicas.\n\nThe hot tier is required. New indices that are part of a <<data-streams,\ndata stream>> are automatically allocated to the hot tier.\n// end::hot-tier[]\n\n[discrete]\n[[warm-tier]]\n==== Warm tier\n\n// tag::warm-tier[]\nTime series data can move to the warm tier once it is being queried less frequently\nthan the recently-indexed data in the hot tier.\nThe warm tier typically holds data from recent weeks.\nUpdates are still allowed, but likely infrequent.\nNodes in the warm tier generally don't need to be as fast as those in the hot tier.\nFor resiliency, indices in the warm tier should be configured to use one or more replicas.\n// end::warm-tier[]\n\n[discrete]\n[[cold-tier]]\n==== Cold tier\n\n// tag::cold-tier[]\nWhen you no longer need to search time series data regularly, it can move from\nthe warm tier to the cold tier. While still searchable, this tier is typically\noptimized for lower storage costs rather than search speed.\n\nFor better storage savings, you can keep <<fully-mounted,fully mounted indices>>\nof <<ilm-searchable-snapshot,{search-snaps}>> on the cold tier. Unlike regular\nindices, these fully mounted indices don't require replicas for reliability. In\nthe event of a failure, they can recover data from the underlying snapshot\ninstead. This potentially halves the local storage needed for the data. A\nsnapshot repository is required to use fully mounted indices in the cold tier.\nFully mounted indices are read-only.\n\nAlternatively, you can use the cold tier to store regular indices with replicas instead\nof using {search-snaps}. This lets you store older data on less expensive hardware\nbut doesn't reduce required disk space compared to the warm tier.\n// end::cold-tier[]\n\n[discrete]\n[[frozen-tier]]\n==== Frozen tier\n\n// tag::frozen-tier[]\nOnce data is no longer being queried, or being queried rarely, it may move from\nthe cold tier to the frozen tier where it stays for the rest of its life.\n\nThe frozen tier requires a snapshot repository.\nThe frozen tier uses <<partially-mounted,partially mounted indices>> to store\nand load data from a snapshot repository. This reduces local storage and\noperating costs while still letting you search frozen data. Because {es} must\nsometimes fetch frozen data from the snapshot repository, searches on the frozen\ntier are typically slower than on the cold tier.\n// end::frozen-tier[]\n\n[discrete]\n[[configure-data-tiers]]\n=== Configure data tiers\n\nFollow the instructions for your deployment type to configure data tiers.\n\n[discrete]\n[[configure-data-tiers-cloud]]\n==== {ess} or {ece}\n\nThe default configuration for an {ecloud} deployment includes a shared tier for\nhot and content data. This tier is required and can't be removed.\n\nTo add a warm, cold, or frozen tier when you create a deployment:\n\n. On the **Create deployment** page, click **Advanced Settings**.\n\n. Click **+ Add capacity** for any data tiers to add.\n\n. Click **Create deployment** at the bottom of the page to save your changes.\n\n[role=\"screenshot\"]\nimage::images/data-tiers/ess-advanced-config-data-tiers.png[{ecloud}'s deployment Advanced configuration page,align=center]\n\nTo add a data tier to an existing deployment:\n\n. Log in to the {ess-console}[{ecloud} console].\n\n. On the **Deployments** page, select your deployment.\n\n. In your deployment menu, select **Edit**.\n\n. Click **+ Add capacity** for any data tiers to add.\n\n. Click **Save** at the bottom of the page to save your changes.\n\n\nTo remove a data tier, refer to {cloud}/ec-disable-data-tier.html[Disable a data\ntier].\n\n[discrete]\n[[configure-data-tiers-on-premise]]\n==== Self-managed deployments\n\nFor self-managed deployments, each node's <<data-node,data role>> is configured\nin `elasticsearch.yml`. For example, the highest-performance nodes in a cluster\nmight be assigned to both the hot and content tiers:\n\n[source,yaml]\n----\nnode.roles: [\"data_hot\", \"data_content\"]\n----\n\nNOTE: We recommend you use <<data-frozen-node,dedicated nodes>> in the frozen\ntier.\n\n[discrete]\n[[data-tier-allocation]]\n=== Data tier index allocation\n\nThe <<tier-preference-allocation-filter, `index.routing.allocation.include._tier_preference`>> setting determines which tier the index should be allocated to.\n\nWhen you create an index, by default {es} sets the `_tier_preference`\nto `data_content` to automatically allocate the index shards to the content tier.\n\nWhen {es} creates an index as part of a <<data-streams, data stream>>,\nby default {es} sets the `_tier_preference`\nto `data_hot` to automatically allocate the index shards to the hot tier.\n\nAt the time of index creation, you can override the default setting by explicitly setting \nthe preferred value in one of two ways:\n\n- Using an <<index-templates,index template>>. Refer to <<getting-started-index-lifecycle-management,Automate rollover with ILM>> for details.\n- Within the <<indices-create-index,create index>> request body. \n\nYou can override this \nsetting after index creation by <<indices-update-settings,updating the index setting>> to the preferred \nvalue. \n\nThis setting also accepts multiple tiers in order of preference. This prevents indices from remaining unallocated if no nodes are available in the preferred tier. For example, when {ilm} migrates an index to the cold phase, it sets the index `_tier_preference` to `data_cold,data_warm,data_hot`.\n\nTo remove the data tier preference \nsetting, set the `_tier_preference` value to `null`. This allows the index to allocate to any data node within the cluster. Setting the `_tier_preference` to `null` does not restore the default value. Note that, in the case of managed indices, a <<ilm-migrate,migrate>> action might apply a new value in its place. \n\n[discrete]\n[[data-tier-allocation-value]]\n==== Determine the current data tier preference\n\nYou can check an existing index's data tier preference by <<indices-get-settings,polling its \nsettings>> for `index.routing.allocation.include._tier_preference`:\n\n[source,console]\n--------------------------------------------------\nGET /my-index-000001/_settings?filter_path=*.settings.index.routing.allocation.include._tier_preference\n--------------------------------------------------\n// TEST[setup:my_index]\n\n[discrete]\n[[data-tier-allocation-troubleshooting]]\n==== Troubleshooting\n\nThe `_tier_preference` setting might conflict with other allocation settings. This conflict might prevent the shard from allocating. A conflict might occur when a cluster has not yet been completely <<troubleshoot-migrate-to-tiers,migrated \nto data tiers>>. \n\nThis setting will not unallocate a currently allocated shard, but might prevent it from migrating from its current location to its designated data tier. To troubleshoot, call the <<cluster-allocation-explain,cluster allocation explain API>> and specify the suspected problematic shard.\n\n[discrete]\n[[data-tier-migration]]\n==== Automatic data tier migration\n\n{ilm-init} automatically transitions managed\nindices through the available data tiers using the <<ilm-migrate, migrate>> action.\nBy default, this action is automatically injected in every phase.\nYou can explicitly specify the migrate action with `\"enabled\": false` to <<ilm-disable-migrate-ex,disable automatic migration>>,\nfor example, if you're using the <<ilm-allocate, allocate action>> to manually\nspecify allocation rules.\n"
}
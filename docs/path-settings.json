{
    "meta": {
        "timestamp": "2024-11-01T02:49:25.901068",
        "size": 5558,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/path-settings.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "path-settings",
        "version": "8.15"
    },
    "doc": "[[path-settings]]\n[discrete]\n==== Path settings\n\n{es} writes the data you index to indices and data streams to a `data`\ndirectory. {es} writes its own application logs, which contain information about\ncluster health and operations, to a `logs` directory.\n\nFor <<targz,macOS `.tar.gz`>>, <<targz,Linux `.tar.gz`>>, and\n<<zip-windows,Windows `.zip`>> installations, `data` and `logs` are\nsubdirectories of `$ES_HOME` by default. However, files in `$ES_HOME` risk\ndeletion during an upgrade.\n\nIn production, we strongly recommend you set the `path.data` and `path.logs` in\n`elasticsearch.yml` to locations outside of `$ES_HOME`. <<docker,Docker>>,\n<<deb,Debian>>, and <<rpm,RPM>> installations write\ndata and log to locations outside of `$ES_HOME` by default.\n\nSupported `path.data` and `path.logs` values vary by platform:\n\ninclude::{es-ref-dir}/tab-widgets/customize-data-log-path-widget.asciidoc[]\n\ninclude::{es-ref-dir}/modules/node.asciidoc[tag=modules-node-data-path-warning-tag]\n\n[discrete]\n==== Multiple data paths\ndeprecated::[7.13.0]\n\nIf needed, you can specify multiple paths in `path.data`. {es} stores the node's\ndata across all provided paths but keeps each shard's data on the same path.\n\n{es} does not balance shards across a node's data paths. High disk\nusage in a single path can trigger a <<disk-based-shard-allocation,high disk\nusage watermark>> for the entire node. If triggered, {es} will not add shards to\nthe node, even if the node\u2019s other paths have available disk space. If you need\nadditional disk space, we recommend you add a new node rather than additional\ndata paths.\n\ninclude::{es-ref-dir}/tab-widgets/multi-data-path-widget.asciidoc[]\n\n[discrete]\n[[mdp-migrate]]\n==== Migrate from multiple data paths\n\nSupport for multiple data paths was deprecated in 7.13 and will be removed\nin a future release.\n\nAs an alternative to multiple data paths, you can create a filesystem which\nspans multiple disks with a hardware virtualisation layer such as RAID, or a\nsoftware virtualisation layer such as Logical Volume Manager (LVM) on Linux or\nStorage Spaces on Windows. If you wish to use multiple data paths on a single\nmachine then you must run one node for each data path.\n\nIf you currently use multiple data paths in a\n{ref}/high-availability-cluster-design.html[highly available cluster] then you\ncan migrate to a setup that uses a single path for each node without downtime\nusing a process similar to a\n{ref}/restart-cluster.html#restart-cluster-rolling[rolling restart]: shut each\nnode down in turn and replace it with one or more nodes each configured to use\na single data path. In more detail, for each node that currently has multiple\ndata paths you should follow the following process. In principle you can\nperform this migration during a rolling upgrade to 8.0, but we recommend\nmigrating to a single-data-path setup before starting to upgrade.\n\n1. Take a snapshot to protect your data in case of disaster.\n\n2. Optionally, migrate the data away from the target node by using an\n{ref}/modules-cluster.html#cluster-shard-allocation-filtering[allocation filter]:\n+\n[source,console]\n--------------------------------------------------\nPUT _cluster/settings\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.exclude._name\": \"target-node-name\"\n  }\n}\n--------------------------------------------------\n+\nYou can use the {ref}/cat-allocation.html[cat allocation API] to track progress\nof this data migration. If some shards do not migrate then the\n{ref}/cluster-allocation-explain.html[cluster allocation explain API] will help\nyou to determine why.\n\n3. Follow the steps in the\n{ref}/restart-cluster.html#restart-cluster-rolling[rolling restart process]\nup to and including shutting the target node down.\n\n4. Ensure your cluster health is `yellow` or `green`, so that there is a copy\nof every shard assigned to at least one of the other nodes in your cluster.\n\n5. If applicable, remove the allocation filter applied in the earlier step.\n+\n[source,console]\n--------------------------------------------------\nPUT _cluster/settings\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.exclude._name\": null\n  }\n}\n--------------------------------------------------\n\n6. Discard the data held by the stopped node by deleting the contents of its\ndata paths.\n\n7. Reconfigure your storage. For instance, combine your disks into a single\nfilesystem using LVM or Storage Spaces. Ensure that your reconfigured storage\nhas sufficient space for the data that it will hold.\n\n8. Reconfigure your node by adjusting the `path.data` setting in its\n`elasticsearch.yml` file. If needed, install more nodes each with their own\n`path.data` setting pointing at a separate data path.\n\n9. Start the new nodes and follow the rest of the\n{ref}/restart-cluster.html#restart-cluster-rolling[rolling restart process] for\nthem.\n\n10. Ensure your cluster health is `green`, so that every shard has been\nassigned.\n\nYou can alternatively add some number of single-data-path nodes to your\ncluster, migrate all your data over to these new nodes using\n{ref}/modules-cluster.html#cluster-shard-allocation-filtering[allocation filters],\nand then remove the old nodes from the cluster. This approach will temporarily\ndouble the size of your cluster so it will only work if you have the capacity to\nexpand your cluster like this.\n\nIf you currently use multiple data paths but your cluster is not highly\navailable then you can migrate to a non-deprecated configuration by taking\na snapshot, creating a new cluster with the desired configuration and restoring\nthe snapshot into it.\n"
}
{
    "meta": {
        "size": 5299,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-get-influencer.html",
        "type": "documentation",
        "role": [
            "xpack"
        ],
        "has_code": true,
        "title": "ml-get-influencer",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[ml-get-influencer]]\n= Get influencers API\n++++\n<titleabbrev>Get influencers</titleabbrev>\n++++\n\nRetrieves {anomaly-job} results for one or more influencers.\n\n[[ml-get-influencer-request]]\n== {api-request-title}\n\n`GET _ml/anomaly_detectors/<job_id>/results/influencers`\n\n[[ml-get-influencer-prereqs]]\n== {api-prereq-title}\n\nRequires the `monitor_ml` cluster privilege. This privilege is included in the \n`machine_learning_user` built-in role.`\n\n[[ml-get-influencer-desc]]\n== {api-description-title}\n\nInfluencers are the entities that have contributed to, or are to blame for,\nthe anomalies. Influencer results are available only if an\n`influencer_field_name` is specified in the job configuration.\n\n[[ml-get-influencer-path-parms]]\n== {api-path-parms-title}\n\n`<job_id>`::\n(Required, string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=job-id-anomaly-detection]\n\n\n[[ml-get-influencer-query-parms]]\n== {api-query-parms-title}\n\n`desc`::\n(Optional, Boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=desc-results]\n\n`end`::\n(Optional, string) Returns influencers with timestamps earlier than this time.\nDefaults to `-1`, which means it is unset and results are not limited to \nspecific timestamps.\n\n`exclude_interim`::\n(Optional, Boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=exclude-interim-results]\n\n`from`::\n(Optional, integer)\nSkips the specified number of influencers. Defaults to `0`.\n\n`influencer_score`::\n(Optional, double) Returns influencers with anomaly scores greater than or\nequal to this value. Defaults to `0.0`.\n\n`size`::\n(Optional, integer)\nSpecifies the maximum number of influencers to obtain. Defaults to `100`.\n\n`sort`::\n(Optional, string) Specifies the sort field for the requested influencers. By\ndefault, the influencers are sorted by the `influencer_score` value.\n\n`start`::\n(Optional, string) Returns influencers with timestamps after this time. Defaults \nto `-1`, which means it is unset and results are not limited to specific \ntimestamps.\n\n\n[[ml-get-influencer-request-body]]\n== {api-request-body-title}\n\nYou can also specify the query parameters in the request body; the exception are\n`from` and `size`, use `page` instead:\n\n`page`::\n+\n.Properties of `page`\n[%collapsible%open]\n====\n\n`from`:::\n(Optional, integer) Skips the specified number of influencers. Defaults to `0`.\n\n`size`:::\n(Optional, integer) Specifies the maximum number of influencers to obtain. \nDefaults to `100`.\n====\n\n[[ml-get-influencer-results]]\n== {api-response-body-title}\n\nThe API returns an array of influencer objects, which have the following\nproperties:\n\n`bucket_span`::\n(number)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=bucket-span-results]\n\n`influencer_score`::\n(number) A normalized score between 0-100, which is based on the probability of\nthe influencer in this bucket aggregated across detectors. Unlike\n`initial_influencer_score`, this value will be updated by a re-normalization\nprocess as new data is analyzed.\n\n`influencer_field_name`::\n(string) The field name of the influencer.\n\n`influencer_field_value`::\n(string) The entity that influenced, contributed to, or was to blame for the\nanomaly.\n\n`initial_influencer_score`::\n(number) A normalized score between 0-100, which is based on the probability of\nthe influencer aggregated across detectors. This is the initial value that was\ncalculated at the time the bucket was processed.\n\n`is_interim`::\n(Boolean)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=is-interim]\n\n`job_id`::\n(string)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=job-id-anomaly-detection]\n\n`probability`::\n(number) The probability that the influencer has this behavior, in the range 0\nto 1. For example, 0.0000109783. This value can be held to a high precision of\nover 300 decimal places, so the `influencer_score` is provided as a\nhuman-readable and friendly interpretation of this.\n\n`result_type`::\n(string) Internal. This value is always set to `influencer`.\n\n`timestamp`::\n(date)\ninclude::{es-ref-dir}/ml/ml-shared.asciidoc[tag=timestamp-results]\n\nNOTE: Additional influencer properties are added, depending on the fields being\nanalyzed. For example, if it's analyzing `user_name` as an influencer, then a\nfield `user_name` is added to the result document. This information enables you to\nfilter the anomaly results more easily.\n\n[[ml-get-influencer-example]]\n== {api-examples-title}\n\n[source,console]\n--------------------------------------------------\nGET _ml/anomaly_detectors/high_sum_total_sales/results/influencers\n{\n  \"sort\": \"influencer_score\",\n  \"desc\": true\n}\n--------------------------------------------------\n// TEST[skip:Kibana sample data]\n\nIn this example, the API returns the following information, sorted based on the\ninfluencer score in descending order:\n[source,js]\n----\n{\n  \"count\": 189,\n  \"influencers\": [\n    {\n      \"job_id\": \"high_sum_total_sales\",\n      \"result_type\": \"influencer\",\n      \"influencer_field_name\": \"customer_full_name.keyword\",\n      \"influencer_field_value\": \"Wagdi Shaw\",\n      \"customer_full_name.keyword\" : \"Wagdi Shaw\",\n      \"influencer_score\": 99.02493,\n      \"initial_influencer_score\" : 94.67233079580171,\n      \"probability\" : 1.4784807245686567E-10,\n      \"bucket_span\" : 3600,\n      \"is_interim\" : false,\n      \"timestamp\" : 1574661600000\n    },\n  ...\n  ]\n}\n----\n"
}
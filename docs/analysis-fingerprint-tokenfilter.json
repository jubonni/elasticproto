{
    "meta": {
        "timestamp": "2024-11-01T03:07:09.234270",
        "size": 3848,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-fingerprint-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-fingerprint-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-fingerprint-tokenfilter]]\n=== Fingerprint token filter\n++++\n<titleabbrev>Fingerprint</titleabbrev>\n++++\n\nSorts and removes duplicate tokens from a token stream, then concatenates the\nstream into a single output token. \n\nFor example, this filter changes the `[ the, fox, was, very, very, quick ]`\ntoken stream as follows:\n\n. Sorts the tokens alphabetically to `[ fox, quick, the, very, very, was ]`\n\n. Removes a duplicate instance of the `very` token.\n\n. Concatenates the token stream to a output single token: `[fox quick the very was ]`\n\nOutput tokens produced by this filter are useful for\nfingerprinting and clustering a body of text as described in the\nhttps://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth#fingerprint[OpenRefine\nproject].\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/miscellaneous/FingerprintFilter.html[FingerprintFilter].\n\n[[analysis-fingerprint-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the `fingerprint`\nfilter to create a single output token for the text `zebra jumps over resting\nresting dog`:\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\" : \"whitespace\",\n  \"filter\" : [\"fingerprint\"],\n  \"text\" : \"zebra jumps over resting resting dog\"\n}\n--------------------------------------------------\n\nThe filter produces the following token:\n\n[source,text]\n--------------------------------------------------\n[ dog jumps over resting zebra ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"dog jumps over resting zebra\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 36,\n      \"type\" : \"fingerprint\",\n      \"position\" : 0\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-fingerprint-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`fingerprint` filter to configure a new <<analysis-custom-analyzer,custom\nanalyzer>>.\n\n[source,console]\n--------------------------------------------------\nPUT fingerprint_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_fingerprint\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"fingerprint\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-fingerprint-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n[[analysis-fingerprint-tokenfilter-max-size]]\n`max_output_size`::\n(Optional, integer)\nMaximum character length, including whitespace, of the output token. Defaults to\n`255`. Concatenated tokens longer than this will result in no token output.\n\n`separator`::\n(Optional, string)\nCharacter to use to concatenate the token stream input. Defaults to a space.\n\n[[analysis-fingerprint-tokenfilter-customize]]\n==== Customize\n\nTo customize the `fingerprint` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following request creates a custom `fingerprint` filter with\nthat use `+` to concatenate token streams. The filter also limits\noutput tokens to `100` characters or fewer.\n\n[source,console]\n--------------------------------------------------\nPUT custom_fingerprint_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"fingerprint_plus_concat\" ]\n        }\n      },\n      \"filter\": {\n        \"fingerprint_plus_concat\": {\n          \"type\": \"fingerprint\",\n          \"max_output_size\": 100,\n          \"separator\": \"+\"\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T03:02:52.108580",
        "size": 13824,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "bootstrap-checks",
        "version": "8.15"
    },
    "doc": "[[bootstrap-checks]]\n== Bootstrap Checks\n\nCollectively, we have a lot of experience with users suffering\nunexpected issues because they have not configured\n<<important-settings,important settings>>. In previous versions of\nElasticsearch, misconfiguration of some of these settings were logged\nas warnings. Understandably, users sometimes miss these log messages.\nTo ensure that these settings receive the attention that they deserve,\nElasticsearch has bootstrap checks upon startup.\n\nThese bootstrap checks inspect a variety of Elasticsearch and system\nsettings and compare them to values that are safe for the operation of\nElasticsearch. If Elasticsearch is in development mode, any bootstrap\nchecks that fail appear as warnings in the Elasticsearch log. If\nElasticsearch is in production mode, any bootstrap checks that fail will\ncause Elasticsearch to refuse to start.\n\nThere are some bootstrap checks that are always enforced to prevent\nElasticsearch from running with incompatible settings. These checks are\ndocumented individually.\n\n[discrete]\n[[dev-vs-prod-mode]]\n=== Development vs. production mode\n\nBy default, {es} binds to loopback addresses for\n<<modules-network,HTTP and transport (internal) communication>>. This is fine\nfor downloading and playing with {es} as well as everyday development,\nbut it's useless for production systems. To join a cluster, an {es}\nnode must be reachable via transport communication. To join a cluster via a\nnon-loopback address, a node must bind transport to a non-loopback address and\nnot be using <<single-node-discovery,single-node discovery>>. Thus, we consider\nan Elasticsearch node to be in development mode if it can not form a cluster\nwith another machine via a non-loopback address, and is otherwise in production\nmode if it can join a cluster via non-loopback addresses.\n\nNote that HTTP and transport can be configured independently via\n<<http-settings,`http.host`>> and <<transport-settings,`transport.host`>>; this\ncan be useful for configuring a single node to be reachable via HTTP for testing\npurposes without triggering production mode.\n\n[[single-node-discovery]]\n[discrete]\n=== Single-node discovery\nWe recognize that some users need to bind the transport to an external\ninterface for testing a remote-cluster configuration. For this situation, we\nprovide the discovery type `single-node` (configure it by setting\n`discovery.type` to `single-node`); in this situation, a node will elect itself\nmaster and will not join a cluster with any other node.\n\n[discrete]\n=== Forcing the bootstrap checks\nIf you are running a single node in production, it is possible to evade the\nbootstrap checks (either by not binding transport to an external interface, or\nby binding transport to an external interface and setting the discovery type to\n`single-node`). For this situation, you can force execution of the bootstrap\nchecks by setting the system property `es.enforce.bootstrap.checks` to `true`\nin the <<set-jvm-options,JVM options>>. We strongly encourage you to do\nthis if you are in this specific situation. This system property can be used to\nforce execution of the bootstrap checks independent of the node configuration.\n\n[[bootstrap-checks-heap-size]]\n=== Heap size check\n\nBy default, {es} automatically sizes JVM heap based on a node's\n<<node-roles,roles>> and total memory. If you manually override the default\nsizing and start the JVM with different initial and max heap sizes, the JVM may\npause as it resizes the heap during system usage. If you enable\n<<bootstrap-memory_lock,`bootstrap.memory_lock`>>, the JVM locks the initial heap\nsize on startup. If the initial heap size is not equal to the maximum heap size,\nsome JVM heap may not be locked after a resize. To avoid these issues, start the\nJVM with an initial heap size equal to the maximum heap size.\n\n[[bootstrap-checks-file-descriptor]]\n=== File descriptor check\n\nFile descriptors are a Unix construct for tracking open \"files\". In Unix\nthough, {wikipedia}/Everything_is_a_file[everything is\na file]. For example, \"files\" could be a physical file, a virtual file\n(e.g., `/proc/loadavg`), or network sockets. Elasticsearch requires\nlots of file descriptors (e.g., every shard is composed of multiple\nsegments and other files, plus connections to other nodes, etc.). This\nbootstrap check is enforced on OS X and Linux. To pass the file\ndescriptor check, you might have to configure <<file-descriptors,file\ndescriptors>>.\n\n[[bootstrap-checks-memory-lock]]\n=== Memory lock check\n\nWhen the JVM does a major garbage collection it touches every page of\nthe heap. If any of those pages are swapped out to disk they will have\nto be swapped back in to memory. That causes lots of disk thrashing that\nElasticsearch would much rather use to service requests. There are\nseveral ways to configure a system to disallow swapping. One way is by\nrequesting the JVM to lock the heap in memory through `mlockall` (Unix)\nor virtual lock (Windows). This is done via the Elasticsearch setting\n<<bootstrap-memory_lock,`bootstrap.memory_lock`>>. However, there are\ncases where this setting can be passed to Elasticsearch but\nElasticsearch is not able to lock the heap (e.g., if the `elasticsearch`\nuser does not have `memlock unlimited`). The memory lock check verifies\nthat *if* the `bootstrap.memory_lock` setting is enabled, that the JVM\nwas successfully able to lock the heap. To pass the memory lock check,\nyou might have to configure <<bootstrap-memory_lock,`bootstrap.memory_lock`>>.\n\n[[max-number-threads-check]]\n=== Maximum number of threads check\n\nElasticsearch executes requests by breaking the request down into stages\nand handing those stages off to different thread pool executors. There\nare different <<modules-threadpool,thread pool executors>> for a variety\nof tasks within Elasticsearch. Thus, Elasticsearch needs the ability to\ncreate a lot of threads. The maximum number of threads check ensures\nthat the Elasticsearch process has the rights to create enough threads\nunder normal use. This check is enforced only on Linux. If you are on\nLinux, to pass the maximum number of threads check, you must configure\nyour system to allow the Elasticsearch process the ability to create at\nleast 4096 threads. This can be done via `/etc/security/limits.conf`\nusing the `nproc` setting (note that you might have to increase the\nlimits for the `root` user too).\n\n[[bootstrap-checks-max-file-size]]\n=== Max file size check\n\nThe segment files that are the components of individual shards and the translog\ngenerations that are components of the translog can get large (exceeding\nmultiple gigabytes). On systems where the max size of files that can be created\nby the Elasticsearch process is limited, this can lead to failed\nwrites. Therefore, the safest option here is that the max file size is unlimited\nand that is what the max file size bootstrap check enforces. To pass the max\nfile check, you must configure your system to allow the Elasticsearch process\nthe ability to write files of unlimited size. This can be done via\n`/etc/security/limits.conf` using the `fsize` setting to `unlimited` (note that\nyou might have to increase the limits for the `root` user too).\n\n[[max-size-virtual-memory-check]]\n=== Maximum size virtual memory check\n\nElasticsearch and Lucene use `mmap` to great effect to map portions of\nan index into the Elasticsearch address space. This keeps certain index\ndata off the JVM heap but in memory for blazing fast access. For this to\nbe effective, the Elasticsearch should have unlimited address space. The\nmaximum size virtual memory check enforces that the Elasticsearch\nprocess has unlimited address space and is enforced only on Linux. To\npass the maximum size virtual memory check, you must configure your\nsystem to allow the Elasticsearch process the ability to have unlimited\naddress space. This can be done via adding `<user> - as unlimited`\nto `/etc/security/limits.conf`. This may require you to increase the limits\nfor the `root` user too.\n\n[[bootstrap-checks-max-map-count]]\n=== Maximum map count check\n\nContinuing from the previous <<max-size-virtual-memory-check,point>>, to\nuse `mmap` effectively, Elasticsearch also requires the ability to\ncreate many memory-mapped areas. The maximum map count check checks that\nthe kernel allows a process to have at least 262,144 memory-mapped areas\nand is enforced on Linux only. To pass the maximum map count check, you\nmust configure `vm.max_map_count` via `sysctl` to be at least `262144`.\n\nAlternatively, the maximum map count check is only needed if you are using\n`mmapfs` or `hybridfs` as the <<index-modules-store,store type>> for your\nindices. If you <<allow-mmap,do not allow>> the use of `mmap` then this\nbootstrap check will not be enforced.\n\n[[bootstrap-checks-client-jvm]]\n=== Client JVM check\n\nThere are two different JVMs provided by OpenJDK-derived JVMs: the\nclient JVM and the server JVM. These JVMs use different compilers for\nproducing executable machine code from Java bytecode. The client JVM is\ntuned for startup time and memory footprint while the server JVM is\ntuned for maximizing performance. The difference in performance between\nthe two VMs can be substantial. The client JVM check ensures that\nElasticsearch is not running inside the client JVM. To pass the client\nJVM check, you must start Elasticsearch with the server VM. On modern\nsystems and operating systems, the server VM is the\ndefault.\n\n[[bootstrap-checks-serial-collector]]\n=== Use serial collector check\n\nThere are various garbage collectors for the OpenJDK-derived JVMs\ntargeting different workloads. The serial collector in particular is\nbest suited for single logical CPU machines or extremely small heaps,\nneither of which are suitable for running Elasticsearch. Using the\nserial collector with Elasticsearch can be devastating for performance.\nThe serial collector check ensures that Elasticsearch is not configured\nto run with the serial collector. To pass the serial collector check,\nyou must not start Elasticsearch with the serial collector (whether it's\nfrom the defaults for the JVM that you're using, or you've explicitly\nspecified it with `-XX:+UseSerialGC`). Note that the default JVM\nconfiguration that ships with Elasticsearch configures Elasticsearch to\nuse the G1GC garbage collector with JDK14 and later versions. For earlier\nJDK versions, the configuration defaults to the CMS collector.\n\n[[bootstrap-checks-syscall-filter]]\n=== System call filter check\nElasticsearch installs system call filters of various flavors depending\non the operating system (e.g., seccomp on Linux). These system call\nfilters are installed to prevent the ability to execute system calls\nrelated to forking as a defense mechanism against arbitrary code\nexecution attacks on Elasticsearch. The system call filter check ensures\nthat if system call filters are enabled, then they were successfully\ninstalled. To pass the system call filter check you must fix any\nconfiguration errors on your system that prevented system call filters\nfrom installing (check your logs).\n\n[[bootstrap-checks-onerror]]\n=== OnError and OnOutOfMemoryError checks\n\nThe JVM options `OnError` and `OnOutOfMemoryError` enable executing\narbitrary commands if the JVM encounters a fatal error (`OnError`) or an\n`OutOfMemoryError` (`OnOutOfMemoryError`). However, by default,\nElasticsearch system call filters (seccomp) are enabled and these\nfilters prevent forking. Thus, using `OnError` or `OnOutOfMemoryError`\nand system call filters are incompatible. The `OnError` and\n`OnOutOfMemoryError` checks prevent Elasticsearch from starting if\neither of these JVM options are used and system call filters are\nenabled. This check is always enforced. To pass this check do not enable\n`OnError` nor `OnOutOfMemoryError`; instead, upgrade to Java 8u92 and\nuse the JVM flag `ExitOnOutOfMemoryError`. While this does not have the\nfull capabilities of `OnError` nor `OnOutOfMemoryError`, arbitrary\nforking will not be supported with seccomp enabled.\n\n[[bootstrap-checks-early-access]]\n=== Early-access check\n\nThe OpenJDK project provides early-access snapshots of upcoming releases. These\nreleases are not suitable for production. The early-access check detects these\nearly-access snapshots. To pass this check, you must start Elasticsearch on a\nrelease build of the JVM.\n\n[[bootstrap-checks-all-permission]]\n=== All permission check\n\nThe all permission check ensures that the security policy used during bootstrap\ndoes not grant the `java.security.AllPermission` to Elasticsearch. Running with\nthe all permission granted is equivalent to disabling the security manager.\n\n[[bootstrap-checks-discovery-configuration]]\n=== Discovery configuration check\n\nBy default, when Elasticsearch first starts up it will try and discover other\nnodes running on the same host. If no elected master can be discovered within a\nfew seconds then Elasticsearch will form a cluster that includes any other\nnodes that were discovered. It is useful to be able to form this cluster\nwithout any extra configuration in development mode, but this is unsuitable for\nproduction because it's possible to form multiple clusters and lose data as a\nresult.\n\nThis bootstrap check ensures that discovery is not running with the default\nconfiguration. It can be satisfied by setting at least one of the following\nproperties:\n\n- `discovery.seed_hosts`\n- `discovery.seed_providers`\n- `cluster.initial_master_nodes`\n\nNote that you must <<initial_master_nodes,remove `cluster.initial_master_nodes`\nfrom the configuration of every node>> after the cluster has started for the\nfirst time. Instead, configure `discovery.seed_hosts` or\n`discovery.seed_providers`. If you do not need any discovery configuration, for\ninstance if running a single-node cluster, set `discovery.seed_hosts: []` to\ndisable discovery and satisfy this bootstrap check.\n"
}
{
    "meta": {
        "size": 3729,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/get-ml-info.html",
        "type": "documentation",
        "role": [
            "xpack"
        ],
        "has_code": true,
        "title": "get-ml-info",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[get-ml-info]]\n= Get machine learning info API\n\n[subs=\"attributes\"]\n++++\n<titleabbrev>Get {ml} info</titleabbrev>\n++++\n\nReturns defaults and limits used by machine learning.\n\n[[get-ml-info-request]]\n== {api-request-title}\n\n`GET _ml/info`\n\n[[get-ml-info-prereqs]]\n== {api-prereq-title}\n\nRequires the `monitor_ml` cluster privilege. This privilege is included in the\n`machine_learning_user` built-in role.\n\n[[get-ml-info-desc]]\n== {api-description-title}\n\nThis endpoint is designed to be used by a user interface that needs to fully\nunderstand machine learning configurations where some options are not specified,\nmeaning that the defaults should be used. This endpoint may be used to find out\nwhat those defaults are. It also provides information about the maximum size\nof {ml} jobs that could run in the current cluster configuration.\n\n[[get-ml-info-example]]\n== {api-examples-title}\n\nThe endpoint takes no arguments:\n\n[source,console]\n--------------------------------------------------\nGET _ml/info\n--------------------------------------------------\n// TEST\n\nThis is a possible response:\n\n[source,console-result]\n----\n{\n  \"defaults\" : {\n    \"anomaly_detectors\" : {\n      \"categorization_analyzer\" : {\n        \"char_filter\" : [\n          \"first_line_with_letters\"\n        ],\n        \"tokenizer\" : \"ml_standard\",\n        \"filter\" : [\n          {\n            \"type\" : \"stop\",\n            \"stopwords\" : [\n              \"Monday\",\n              \"Tuesday\",\n              \"Wednesday\",\n              \"Thursday\",\n              \"Friday\",\n              \"Saturday\",\n              \"Sunday\",\n              \"Mon\",\n              \"Tue\",\n              \"Wed\",\n              \"Thu\",\n              \"Fri\",\n              \"Sat\",\n              \"Sun\",\n              \"January\",\n              \"February\",\n              \"March\",\n              \"April\",\n              \"May\",\n              \"June\",\n              \"July\",\n              \"August\",\n              \"September\",\n              \"October\",\n              \"November\",\n              \"December\",\n              \"Jan\",\n              \"Feb\",\n              \"Mar\",\n              \"Apr\",\n              \"May\",\n              \"Jun\",\n              \"Jul\",\n              \"Aug\",\n              \"Sep\",\n              \"Oct\",\n              \"Nov\",\n              \"Dec\",\n              \"GMT\",\n              \"UTC\"\n            ]\n          },\n          {\n            \"type\": \"limit\",\n            \"max_token_count\": \"100\"\n          }\n        ]\n      },\n      \"model_memory_limit\" : \"1gb\",\n      \"categorization_examples_limit\" : 4,\n      \"model_snapshot_retention_days\" : 10,\n      \"daily_model_snapshot_retention_after_days\" : 1\n    },\n    \"datafeeds\" : {\n      \"scroll_size\" : 1000\n    }\n  },\n  \"upgrade_mode\": false,\n  \"native_code\" : {\n    \"version\": \"7.0.0\",\n    \"build_hash\": \"99a07c016d5a73\"\n  },\n  \"limits\" : {\n    \"effective_max_model_memory_limit\": \"28961mb\",\n    \"total_ml_memory\": \"86883mb\",\n    \"total_ml_processors\": 16,\n    \"max_single_ml_node_processors\": 16\n  }\n}\n----\n// TESTRESPONSE[s/\"upgrade_mode\": false/\"upgrade_mode\": $body.upgrade_mode/]\n// TESTRESPONSE[s/\"version\": \"7.0.0\",/\"version\": \"$body.native_code.version\",/]\n// TESTRESPONSE[s/\"build_hash\": \"99a07c016d5a73\"/\"build_hash\": \"$body.native_code.build_hash\"/]\n// TESTRESPONSE[s/\"effective_max_model_memory_limit\": \"28961mb\"/\"effective_max_model_memory_limit\": \"$body.limits.effective_max_model_memory_limit\"/]\n// TESTRESPONSE[s/\"total_ml_memory\": \"86883mb\"/\"total_ml_memory\": \"$body.limits.total_ml_memory\"/]\n// TESTRESPONSE[s/\"total_ml_processors\": 16/\"total_ml_processors\": $body.limits.total_ml_processors/]\n// TESTRESPONSE[s/\"max_single_ml_node_processors\": 16/\"max_single_ml_node_processors\": $body.limits.max_single_ml_node_processors/]\n"
}
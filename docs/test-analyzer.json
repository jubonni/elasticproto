{
    "meta": {
        "size": 4371,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/test-analyzer.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "test-analyzer",
        "version": "8.15"
    },
    "doc": "[[test-analyzer]]\n=== Test an analyzer\n\nThe <<indices-analyze,`analyze` API>> is an invaluable tool for viewing the\nterms produced by an analyzer. A built-in analyzer can be specified inline in\nthe request:\n\n[source,console]\n-------------------------------------\nPOST _analyze\n{\n  \"analyzer\": \"whitespace\",\n  \"text\":     \"The quick brown fox.\"\n}\n-------------------------------------\n\nThe API returns the following response:\n\n[source,console-result]\n-------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"The\",\n      \"start_offset\": 0,\n      \"end_offset\": 3,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 4,\n      \"end_offset\": 9,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 10,\n      \"end_offset\": 15,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"fox.\",\n      \"start_offset\": 16,\n      \"end_offset\": 20,\n      \"type\": \"word\",\n      \"position\": 3\n    }\n  ]\n}\n-------------------------------------\n\nYou can also test combinations of:\n\n* A tokenizer\n* Zero or more token filters\n* Zero or more character filters\n\n[source,console]\n-------------------------------------\nPOST _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\":  [ \"lowercase\", \"asciifolding\" ],\n  \"text\":      \"Is this d\u00e9ja vu?\"\n}\n-------------------------------------\n\nThe API returns the following response:\n\n[source,console-result]\n-------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"is\",\n      \"start_offset\": 0,\n      \"end_offset\": 2,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"this\",\n      \"start_offset\": 3,\n      \"end_offset\": 7,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"deja\",\n      \"start_offset\": 8,\n      \"end_offset\": 12,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"vu\",\n      \"start_offset\": 13,\n      \"end_offset\": 15,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 3\n    }\n  ]\n}\n-------------------------------------\n\n.Positions and character offsets\n*********************************************************\n\nAs can be seen from the output of the `analyze` API, analyzers not only\nconvert words into terms, they also record the order or relative _positions_\nof each term (used for phrase queries or word proximity queries), and the\nstart and end _character offsets_ of each term in the original text (used for\nhighlighting search snippets).\n\n*********************************************************\n\n\nAlternatively, a <<analysis-custom-analyzer,`custom` analyzer>> can be\nreferred to when running the `analyze` API on a specific index:\n\n[source,console]\n-------------------------------------\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"std_folded\": { <1>\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"asciifolding\"\n          ]\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"my_text\": {\n        \"type\": \"text\",\n        \"analyzer\": \"std_folded\" <2>\n      }\n    }\n  }\n}\n\nGET my-index-000001/_analyze <3>\n{\n  \"analyzer\": \"std_folded\", <4>\n  \"text\":     \"Is this d\u00e9j\u00e0 vu?\"\n}\n\nGET my-index-000001/_analyze <3>\n{\n  \"field\": \"my_text\", <5>\n  \"text\":  \"Is this d\u00e9j\u00e0 vu?\"\n}\n-------------------------------------\n\nThe API returns the following response:\n\n[source,console-result]\n-------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"is\",\n      \"start_offset\": 0,\n      \"end_offset\": 2,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"this\",\n      \"start_offset\": 3,\n      \"end_offset\": 7,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"deja\",\n      \"start_offset\": 8,\n      \"end_offset\": 12,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"vu\",\n      \"start_offset\": 13,\n      \"end_offset\": 15,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 3\n    }\n  ]\n}\n-------------------------------------\n\n<1> Define a `custom` analyzer called `std_folded`.\n<2> The field `my_text` uses the `std_folded` analyzer.\n<3> To refer to this analyzer, the `analyze` API must specify the index name.\n<4> Refer to the analyzer by name.\n<5> Refer to the analyzer used by field `my_text`.\n"
}
{
    "meta": {
        "size": 5318,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/data-stream-lifecycle-settings.html",
        "type": "documentation",
        "role": [
            "xpack"
        ],
        "has_code": false,
        "title": "data-stream-lifecycle-settings",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[data-stream-lifecycle-settings]]\n=== Data stream lifecycle settings in {es}\n[subs=\"attributes\"]\n++++\n<titleabbrev>Data stream lifecycle settings</titleabbrev>\n++++\n\nThese are the settings available for configuring <<data-stream-lifecycle, data stream lifecycle>>.\n\n==== Cluster level settings\n\n[[data-streams-lifecycle-retention-max]]\n`data_streams.lifecycle.retention.max`::\n(<<dynamic-cluster-setting,Dynamic>>, <<time-units, time unit value>>)\nThe maximum retention period that will apply to all user data streams managed by the data stream lifecycle. The max retention will also\noverride the retention of a data stream whose configured retention exceeds the max retention. It should be greater than `10s`.\n\n[[data-streams-lifecycle-retention-default]]\n`data_streams.lifecycle.retention.default`::\n(<<dynamic-cluster-setting,Dynamic>>, <<time-units, time unit value>>)\nThe retention period that will apply to all user data streams managed by the data stream lifecycle that do not have retention configured.\nIt should be greater than `10s` and less or equals than <<data-streams-lifecycle-retention-max, `data_streams.lifecycle.retention.max`>>.\n\n[[data-streams-lifecycle-poll-interval]]\n`data_streams.lifecycle.poll_interval`::\n(<<dynamic-cluster-setting,Dynamic>>, <<time-units, time unit value>>)\nHow often {es} checks what is the next action for all data streams with a built-in lifecycle. Defaults to `5m`.\n\n[[cluster-lifecycle-default-rollover]]\n`cluster.lifecycle.default.rollover`::\n(<<dynamic-cluster-setting,Dynamic>>, string)\nThis property accepts a key value pair formatted string and configures the conditions that would trigger a data stream\nto <<index-rollover,rollover>> when it has `lifecycle` configured. This property is an implementation detail and subject to\nchange. Currently, it defaults to `max_age=auto,max_primary_shard_size=50gb,min_docs=1,max_primary_shard_docs=200000000`,\nthis means that your data stream will rollover if any of the following conditions are met:\n\n* Either any primary shard reaches the size of 50GB,\n* or any primary shard contains 200.000.000 documents\n* or the index reaches a certain age which depends on the retention time of your data stream,\n* **and** has at least one document.\n\n[[data-streams-lifecycle-target-merge-factor]]\n`data_streams.lifecycle.target.merge.policy.merge_factor`::\n(<<dynamic-cluster-setting,Dynamic>>, integer)\nData stream lifecycle implements <<data-streams-lifecycle-how-it-works, tail merging>> by\nupdating the lucene merge policy factor for the target backing index. The merge factor \nis both the number of segments that should be merged together, and the maximum number \nof segments that we expect to find on a given tier.\nThis setting controls what value does <<data-stream-lifecycle, Data stream lifecycle>>\nconfigures on the target index. It defaults to `16`. \nThe value will be visible under the `index.merge.policy.merge_factor` index setting \non the target index.\n\n[[data-streams-lifecycle-target-floor-segment]]\n`data_streams.lifecycle.target.merge.policy.floor_segment`::\n(<<dynamic-cluster-setting,Dynamic>>)\nData stream lifecycle implements <<data-streams-lifecycle-how-it-works, tail merging>> by\nupdating the lucene merge policy floor segment for the target backing index. This floor \nsegment size is a way to prevent indices from having a long tail of very small segments. \nThis setting controls what value does <<data-stream-lifecycle, data stream lifecycle>>\nconfigures on the target index. It defaults to `100MB`.\n\n[[data-streams-lifecycle-signalling-error-retry-interval]]\n`data_streams.lifecycle.signalling.error_retry_interval`::\n(<<dynamic-cluster-setting,Dynamic>>, integer)\nRepresents the number of retries data stream lifecycle has to perform for an index\nin an error step in order to signal that the index is not progressing (i.e. it's \nstuck in an error step).\nThe current signalling mechanism is a log statement at the `error` level however,\nthe signalling mechanism can be extended in the future.\nDefaults to 10 retries.\n\n\n==== Index level settings\nThe following index-level settings are typically configured on the backing indices of a data stream.\n\n[[index-lifecycle-prefer-ilm]]\n`index.lifecycle.prefer_ilm`::\n(<<indices-update-settings,Dynamic>>, boolean)\nThis setting determines which feature is managing the backing index of a data stream if, and only if, the backing index\nhas an <<index-lifecycle-management,{ilm}>> ({ilm-init}) policy and the data stream has also a built-in lifecycle. When\n`true` this index is managed by {ilm-init}, when `false` the backing index is managed by the data stream lifecycle.\nDefaults to `true`.\n\n[[index-data-stream-lifecycle-origination-date]]\n`index.lifecycle.origination_date`::\n(<<indices-update-settings,Dynamic>>, long)\nIf specified, this is the timestamp used to calculate the backing index generation age after this backing index has been\n<<index-rollover,rolled over>>. The generation age is used to determine data retention, consequently, you can use this\nsetting if you create a backing index that contains older data and want to ensure that the retention period or\nother parts of the lifecycle will be applied based on the data's original timestamp and not the timestamp they got\nindexed. Specified as a Unix epoch value in milliseconds.\n"
}
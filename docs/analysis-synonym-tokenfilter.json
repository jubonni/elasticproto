{
    "meta": {
        "timestamp": "2024-11-01T03:07:10.371276",
        "size": 7663,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-synonym-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-synonym-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-synonym-tokenfilter]]\n=== Synonym token filter\n++++\n<titleabbrev>Synonym</titleabbrev>\n++++\n\nThe `synonym` token filter allows to easily handle <<search-with-synonyms,synonyms>> during the\nanalysis process.\n\n[discrete]\n[[analysis-synonym-define-synonyms]]\n==== Define synonyms sets\n\ninclude::synonyms-format.asciidoc[]\n\n[discrete]\n[[analysis-synonym-configure-sets]]\n==== Configure synonyms sets\n\nSynonyms can be configured using the <<synonyms-store-synonyms-api,synonyms API>>, a <<synonyms-store-synonyms-file,synonyms file>>, or directly <<synonyms-store-synonyms-inline,inlined>> in the token filter configuration.\nSee <<synonyms-store-synonyms,store your synonyms set>> for more details on each option.\n\nUse `synonyms_set` configuration option to provide a synonym set created via Synonyms Management APIs:\n\n[source,JSON]\n----\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym\",\n      \"synonyms_set\": \"my-synonym-set\",\n      \"updateable\": true\n    }\n  }\n----\n\n[WARNING]\n======\nSynonyms sets must exist before they can be added to indices.\nIf an index is created referencing a nonexistent synonyms set, the index will remain in a partially created and inoperable state.\nThe only way to recover from this scenario is to ensure the synonyms set exists then either delete and re-create the index, or close and re-open the index.\n======\n\nUse `synonyms_path` to provide a synonym file :\n\n[source,JSON]\n----\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym\",\n      \"synonyms_path\": \"analysis/synonym-set.txt\"\n    }\n  }\n----\n\nThe above configures a `synonym` filter, with a path of\n`analysis/synonym-set.txt` (relative to the `config` location).\n\nUse `synonyms` to define inline synonyms:\n\n[source,JSON]\n----\n  \"filter\": {\n    \"synonyms_filter\": {\n      \"type\": \"synonym\",\n      \"synonyms\": [\"pc => personal computer\", \"computer, pc, laptop\"]\n    }\n  }\n----\n\nAdditional settings are:\n\n* `updateable` (defaults to `false`). If `true` allows\n<<indices-reload-analyzers,reloading>> search analyzers to pick up\nchanges to synonym files. Only to be used for search analyzers.\n* `expand` (defaults to `true`).\nExpands definitions for equivalent synonym rules.\nSee <<synonym-tokenizer-expand-equivalent-synonyms,expand equivalent synonyms>>.\n* `lenient` (defaults to the value of the `updateable` setting).\nIf `true` ignores errors while parsing the synonym rules.\nIt is important to note that only those synonym rules which cannot get parsed are ignored.\nSee <<synonym-tokenizer-stop-token-filter,synonyms and stop token filters>> for an example of `lenient` behaviour for invalid synonym rules.\n\n[discrete]\n[[synonym-tokenizer-expand-equivalent-synonyms]]\n===== `expand` equivalent synonym rules\n\nThe `expand` parameter controls whether to expand equivalent synonym rules.\nConsider a synonym defined like:\n\n`foo, bar, baz`\n\nUsing `expand: true`, the synonym rule would be expanded into:\n\n```\nfoo => foo\nfoo => bar\nfoo => baz\nbar => foo\nbar => bar\nbar => baz\nbaz => foo\nbaz => bar\nbaz => baz\n```\n\nWhen `expand` is set to `false`, the synonym rule is not expanded and the first synonym is treated as the canonical representation. The synonym would be equivalent to:\n\n```\nfoo => foo\nbar => foo\nbaz => foo\n```\n\nThe `expand` parameter does not affect explicit synonym rules, like `foo, bar => baz`.\n\n[discrete]\n[[synonym-tokenizer-ignore_case-deprecated]]\n===== `tokenizer` and `ignore_case` are deprecated\n\nThe `tokenizer` parameter controls the tokenizers that will be used to\ntokenize the synonym, this parameter is for backwards compatibility for indices that created before 6.0.\nThe `ignore_case` parameter works with `tokenizer` parameter only.\n\n[discrete]\n[[analysis-synonym-analizers-configure]]\n==== Configure analyzers with synonym token filters\n\nTo apply synonyms, you will need to include a synonym token filters into an analyzer:\n\n[source,JSON]\n----\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\"stemmer\", \"synonym\"]\n        }\n      }\n----\n\n[discrete]\n[[analysis-synonym-token-order]]\n===== Token filters ordering\n\nOrder is important for your token filters.\nText will be processed first through filters preceding the synonym filter before being processed by the synonym filter.\n\n{es} will also use the token filters preceding the synonym filter in a tokenizer chain to parse the entries in a synonym file or synonym set.\nIn the above example, the synonyms token filter is placed after a stemmer. The stemmer will also be applied to the synonym entries.\n\nBecause entries in the synonym map cannot have stacked positions, some token filters may cause issues here.\nToken filters that produce multiple versions of a token may choose which version of the token to emit when parsing synonyms.\nFor example, `asciifolding` will only produce the folded version of the token.\nOthers, like `multiplexer`, `word_delimiter_graph` or `ngram` will throw an error.\n\nIf you need to build analyzers that include both multi-token filters and synonym filters, consider using the <<analysis-multiplexer-tokenfilter,multiplexer>> filter, with the multi-token filters in one branch and the synonym filter in the other.\n\n[discrete]\n[[synonym-tokenizer-stop-token-filter]]\n===== Synonyms and `stop` token filters\n\nSynonyms and <<analysis-stop-tokenfilter,stop token filters>> interact with each other in the following ways:\n\n[discrete]\n====== Stop token filter *before* synonym token filter\n\nStop words will be removed from the synonym rule definition.\nThis can can cause errors on the synonym rule.\n\n[WARNING]\n====\nIf `lenient` is set to `false`, invalid synonym rules can cause errors when applying analyzer changes.\nFor reloadable analyzers, this prevents reloading and applying changes.\nYou must correct errors in the synonym rules and reload the analyzer.\n\nWhen `lenient` is set to `false`, an index with invalid synonym rules cannot be reopened, making it inoperable when:\n\n* A node containing the index starts\n* The index is opened from a closed state\n* A node restart occurs (which reopens the node assigned shards)\n====\n\nFor *explicit synonym rules* like `foo, bar => baz` with a stop filter that removes `bar`:\n\n- If `lenient` is set to `false`, an error will be raised as `bar` would be removed from the left hand side of the synonym rule.\n- If `lenient` is set to `true`, the rule `foo => baz` will be added and `bar => baz` will be ignored.\n\nIf the stop filter removed `baz` instead:\n\n- If `lenient` is set to `false`, an error will be raised as `baz` would be removed from the right hand side of the synonym rule.\n- If `lenient` is set to `true`, the synonym will have no effect as the target word is removed.\n\nFor *equivalent synonym rules* like `foo, bar, baz` and `expand: true, with a stop filter that removes `bar`:\n\n- If `lenient` is set to `false`, an error will be raised as `bar` would be removed from the synonym rule.\n- If `lenient` is set to `true`, the synonyms added would be equivalent to the following synonym rules, which do not contain the removed word:\n\n```\nfoo => foo\nfoo => baz\nbaz => foo\nbaz => baz\n```\n\n[discrete]\n====== Stop token filter *after* synonym token filter\n\nThe stop filter will remove the terms from the resulting synonym expansion.\n\nFor example, a synonym rule like `foo, bar => baz` and a stop filter that removes `baz` will get no matches for `foo` or `bar`, as both would get expanded to `baz` which is removed by the stop filter.\n\nIf the stop filter removed `foo` instead, then searching for `foo` would get expanded to `baz`, which is not removed by the stop filter thus potentially providing matches for `baz`.\n"
}
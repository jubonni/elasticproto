{
    "meta": {
        "timestamp": "2024-11-01T03:02:52.176584",
        "size": 21686,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/high-availability-cluster-design.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "high-availability-cluster-design",
        "version": "8.15"
    },
    "doc": "[[high-availability-cluster-design]]\n== Designing for resilience\n\nDistributed systems like {es} are designed to keep working even if some of\ntheir components have failed. As long as there are enough well-connected\nnodes to take over their responsibilities, an {es} cluster can continue\noperating normally if some of its nodes are unavailable or disconnected.\n\nThere is a limit to how small a resilient cluster can be. All {es} clusters\nrequire the following components to function:\n\n- One <<modules-discovery-quorums,elected master node>>\n- At least one node for each <<modules-node,role>>\n- At least one copy of every <<scalability,shard>>\n\nA resilient cluster requires redundancy for every required cluster component.\nThis means a resilient cluster must have the following components:\n\n- At least three master-eligible nodes\n- At least two nodes of each role\n- At least two copies of each shard (one primary and one or more replicas,\n  unless the index is a <<searchable-snapshots,searchable snapshot index>>)\n\nA resilient cluster needs three master-eligible nodes so that if one of\nthem fails then the remaining two still form a majority and can hold a\nsuccessful election.\n\nSimilarly, redundancy of nodes of each role means that if a node for a\nparticular role fails, another node can take on its responsibilities.\n\nFinally, a resilient cluster should have at least two copies of each shard. If\none copy fails then there should be another good copy to take over. {es}\nautomatically rebuilds any failed shard copies on the remaining nodes in order\nto restore the cluster to full health after a failure.\n\nFailures temporarily reduce the total capacity of your cluster. In addition,\nafter a failure the cluster must perform additional background activities to\nrestore itself to health. You should make sure that your cluster has the\ncapacity to handle your workload even if some nodes fail.\n\nDepending on your needs and budget, an {es} cluster can consist of a single\nnode, hundreds of nodes, or any number in between. When designing a smaller\ncluster, you should typically focus on making it resilient to single-node\nfailures. Designers of larger clusters must also consider cases where multiple\nnodes fail at the same time. The following pages give some recommendations for\nbuilding resilient clusters of various sizes:\n\n- <<high-availability-cluster-small-clusters>>\n- <<high-availability-cluster-design-large-clusters>>\n\n[[high-availability-cluster-small-clusters]]\n=== Resilience in small clusters\n\nIn smaller clusters, it is most important to be resilient to single-node\nfailures. This section gives some guidance on making your cluster as resilient\nas possible to the failure of an individual node.\n\n[[high-availability-cluster-design-one-node]]\n==== One-node clusters\n\nIf your cluster consists of one node, that single node must do everything.\nTo accommodate this, {es} assigns nodes every role by default.\n\nA single node cluster is not resilient. If the node fails, the cluster will\nstop working. Because there are no replicas in a one-node cluster, you cannot\nstore your data redundantly. However, by default at least one replica is\nrequired for a <<cluster-health,`green` cluster health status>>. To ensure your\ncluster can report a `green` status, override the default by setting\n<<dynamic-index-settings,`index.number_of_replicas`>> to `0` on every index.\n\nIf the node fails, you may need to restore an older copy of any lost indices\nfrom a <<snapshot-restore,snapshot>>.\n\nBecause they are not resilient to any failures, we do not recommend using\none-node clusters in production.\n\n[[high-availability-cluster-design-two-nodes]]\n==== Two-node clusters\n\nIf you have two nodes, we recommend they both be data nodes. You should also\nensure every shard is stored redundantly on both nodes by setting\n<<dynamic-index-settings,`index.number_of_replicas`>> to `1` on every index\nthat is not a <<searchable-snapshots,searchable snapshot index>>. This is the\ndefault behaviour but may be overridden by an <<index-templates,index\ntemplate>>. <<dynamic-index-settings,Auto-expand replicas>> can also achieve\nthe same thing, but it's not necessary to use this feature in such a small\ncluster.\n\nWe recommend you set only one of your two nodes to be\n<<master-node,master-eligible>>. This means you can be certain which of your\nnodes is the elected master of the cluster. The cluster can tolerate the loss of\nthe other master-ineligible node. If you set both nodes to master-eligible, two\nnodes are required for a master election. Since the election will fail if either\nnode is unavailable, your cluster cannot reliably tolerate the loss of either\nnode.\n\nBy default, each node is assigned every role. We recommend you assign both nodes\nall other roles except master eligibility. If one node fails, the other node can\nhandle its tasks.\n\nYou should avoid sending client requests to just one of your nodes. If you do\nand this node fails, such requests will not receive responses even if the\nremaining node is a healthy cluster on its own. Ideally, you should balance your\nclient requests across both nodes. A good way to do this is to specify the\naddresses of both nodes when configuring the client to connect to your cluster.\nAlternatively, you can use a resilient load balancer to balance client requests\nacross the nodes in your cluster.\n\nBecause it's not resilient to failures, we do not recommend deploying a two-node\ncluster in production.\n\n[[high-availability-cluster-design-two-nodes-plus]]\n==== Two-node clusters with a tiebreaker\n\nBecause master elections are majority-based, the two-node cluster described\nabove is tolerant to the loss of one of its nodes but not the\nother one. You cannot configure a two-node cluster so that it can tolerate\nthe loss of _either_ node because this is theoretically impossible. You might\nexpect that if either node fails then {es} can elect the remaining node as the\nmaster, but it is impossible to tell the difference between the failure of a\nremote node and a mere loss of connectivity between the nodes. If both nodes\nwere capable of running independent elections, a loss of connectivity would\nlead to a {wikipedia}/Split-brain_(computing)[split-brain\nproblem] and therefore data loss. {es} avoids this and\nprotects your data by electing neither node as master until that node can be\nsure that it has the latest cluster state and that there is no other master in\nthe cluster. This could result in the cluster having no master until\nconnectivity is restored.\n\nYou can solve this problem by adding a third node and making all three nodes\nmaster-eligible. A <<modules-discovery-quorums,master election>> requires only\ntwo of the three master-eligible nodes. This means the cluster can tolerate the\nloss of any single node. This third node acts as a tiebreaker in cases where the\ntwo original nodes are disconnected from each other. You can reduce the resource\nrequirements of this extra node by making it a <<voting-only-node,dedicated\nvoting-only master-eligible node>>, also known as a dedicated tiebreaker.\nBecause it has no other roles, a dedicated tiebreaker does not need to be as\npowerful as the other two nodes. It will not perform any searches nor coordinate\nany client requests and cannot be elected as the master of the cluster.\n\nThe two original nodes should not be voting-only master-eligible nodes since a\nresilient cluster requires at least three master-eligible nodes, at least two\nof which are not voting-only master-eligible nodes. If two of your three nodes\nare voting-only master-eligible nodes then the elected master must be the third\nnode. This node then becomes a single point of failure.\n\nWe recommend assigning both non-tiebreaker nodes all other roles. This creates\nredundancy by ensuring any task in the cluster can be handled by either node.\n\nYou should not send any client requests to the dedicated tiebreaker node.\nYou should also avoid sending client requests to just one of the other two\nnodes. If you do, and this node fails, then any requests will not\nreceive responses, even if the remaining nodes form a healthy cluster. Ideally,\nyou should balance your client requests across both of the non-tiebreaker\nnodes. You can do this by specifying the address of both nodes\nwhen configuring your client to connect to your cluster. Alternatively, you can\nuse a resilient load balancer to balance client requests across the appropriate\nnodes in your cluster. The {ess-trial}[Elastic Cloud] service\nprovides such a load balancer.\n\nA two-node cluster with an additional tiebreaker node is the smallest possible\ncluster that is suitable for production deployments.\n\n[[high-availability-cluster-design-three-nodes]]\n==== Three-node clusters\n\nIf you have three nodes, we recommend they all be <<data-node,data nodes>> and\nevery index that is not a <<searchable-snapshots,searchable snapshot index>>\nshould have at least one replica. Nodes are data nodes by default. You may\nprefer for some indices to have two replicas so that each node has a copy of\neach shard in those indices. You should also configure each node to be\n<<master-node,master-eligible>> so that any two of them can hold a master\nelection without needing to communicate with the third node. Nodes are\nmaster-eligible by default. This cluster will be resilient to the loss of any\nsingle node.\n\nYou should avoid sending client requests to just one of your nodes. If you do,\nand this node fails, then any requests will not receive responses even if the\nremaining two nodes form a healthy cluster. Ideally, you should balance your\nclient requests across all three nodes. You can do this by specifying the\naddress of multiple nodes when configuring your client to connect to your\ncluster. Alternatively you can use a resilient load balancer to balance client\nrequests across your cluster. The {ess-trial}[Elastic Cloud]\nservice provides such a load balancer.\n\n[[high-availability-cluster-design-three-plus-nodes]]\n==== Clusters with more than three nodes\n\nOnce your cluster grows to more than three nodes, you can start to specialise\nthese nodes according to their responsibilities, allowing you to scale their\nresources independently as needed. You can have as many <<data-node,data\nnodes>>, <<ingest,ingest nodes>>, <<ml-node,{ml} nodes>>, etc. as needed to\nsupport your workload. As your cluster grows larger, we recommend using\ndedicated nodes for each role. This allows you to independently scale resources\nfor each task.\n\nHowever, it is good practice to limit the number of master-eligible nodes in\nthe cluster to three. Master nodes do not scale like other node types since\nthe cluster always elects just one of them as the master of the cluster. If\nthere are too many master-eligible nodes then master elections may take a\nlonger time to complete. In larger clusters, we recommend you\nconfigure some of your nodes as dedicated master-eligible nodes and avoid\nsending any client requests to these dedicated nodes. Your cluster may become\nunstable if the master-eligible nodes are overwhelmed with unnecessary extra\nwork that could be handled by one of the other nodes.\n\nYou may configure one of your master-eligible nodes to be a\n<<voting-only-node,voting-only node>> so that it can never be elected as the\nmaster node. For instance, you may have two dedicated master nodes and a third\nnode that is both a data node and a voting-only master-eligible node. This\nthird voting-only node will act as a tiebreaker in master elections but will\nnever become the master itself.\n\n[[high-availability-cluster-design-small-cluster-summary]]\n==== Summary\n\nThe cluster will be resilient to the loss of any node as long as:\n\n- The <<cluster-health,cluster health status>> is `green`.\n- There are at least two data nodes. \n- Every index that is not a <<searchable-snapshots,searchable snapshot index>>\n  has at least one replica of each shard, in addition to the primary.\n- The cluster has at least three master-eligible nodes, as long as at least two\n  of these nodes are not voting-only master-eligible nodes.\n- Clients are configured to send their requests to more than one node or are\n  configured to use a load balancer that balances the requests across an\n  appropriate set of nodes. The {ess-trial}[Elastic Cloud] service provides such\n  a load balancer.\n\n[[high-availability-cluster-design-large-clusters]]\n=== Resilience in larger clusters\n\nIt's not unusual for nodes to share common infrastructure, such as network\ninterconnects or a power supply. If so, you should plan for the failure of this\ninfrastructure and ensure that such a failure would not affect too many of your\nnodes. It is common practice to group all the nodes sharing some infrastructure\ninto _zones_ and to plan for the failure of any whole zone at once.\n\n{es} expects node-to-node connections to be reliable, have low latency, and\nhave adequate bandwidth. Many {es} tasks require multiple round-trips between\nnodes. A slow or unreliable interconnect may have a significant effect on the\nperformance and stability of your cluster.\n\nFor example, a few milliseconds of latency added to each round-trip can quickly\naccumulate into a noticeable performance penalty. An unreliable network may\nhave frequent network partitions. {es} will automatically recover from a\nnetwork partition as quickly as it can but your cluster may be partly\nunavailable during a partition and will need to spend time and resources to\n<<shard-recovery,resynchronize any missing data>> and <<shards-rebalancing-settings,rebalance>> \nitself once the partition heals.\nRecovering from a failure may involve copying a large amount of data between\nnodes so the recovery time is often determined by the available bandwidth.\n\nIf you've divided your cluster into zones, the network connections within each\nzone are typically of higher quality than the connections between the zones.\nEnsure the network connections between zones are of sufficiently high quality.\nYou will see the best results by locating all your zones within a single data\ncenter with each zone having its own independent power supply and other\nsupporting infrastructure. You can also _stretch_ your cluster across nearby\ndata centers as long as the network interconnection between each pair of data\ncenters is good enough.\n\n[[high-availability-cluster-design-min-network-perf]]\nThere is no specific minimum network performance required to run a healthy {es}\ncluster. In theory, a cluster will work correctly even if the round-trip\nlatency between nodes is several hundred milliseconds. In practice, if your\nnetwork is that slow then the cluster performance will be very poor. In\naddition, slow networks are often unreliable enough to cause network partitions\nthat lead to periods of unavailability.\n\nIf you want your data to be available in multiple data centers that are further\napart or not well connected, deploy a separate cluster in each data center and\nuse <<modules-cross-cluster-search,{ccs}>> or <<xpack-ccr,{ccr}>> to link the\nclusters together. These features are designed to perform well even if the\ncluster-to-cluster connections are less reliable or performant than the network\nwithin each cluster.\n\nAfter losing a whole zone's worth of nodes, a properly-designed cluster may be\nfunctional but running with significantly reduced capacity. You may need\nto provision extra nodes to restore acceptable performance in your\ncluster when handling such a failure.\n\nFor resilience against whole-zone failures, it is important that there is a copy\nof each shard in more than one zone, which can be achieved by placing data\nnodes in multiple zones and configuring <<shard-allocation-awareness,shard allocation\nawareness>>. You should also ensure that client requests are sent to nodes in\nmore than one zone.\n\nYou should consider all node roles and ensure that each role is split\nredundantly across two or more zones. For instance, if you are using\n<<ingest,ingest pipelines>> or {ml}, you should have ingest or {ml} nodes in two\nor more zones. However, the placement of master-eligible nodes requires a little\nmore care because a resilient cluster needs at least two of the three\nmaster-eligible nodes in order to function. The following sections explore the\noptions for placing master-eligible nodes across multiple zones.\n\n[[high-availability-cluster-design-two-zones]]\n==== Two-zone clusters\n\nIf you have two zones, you should have a different number of\nmaster-eligible nodes in each zone so that the zone with more nodes will\ncontain a majority of them and will be able to survive the loss of the other\nzone. For instance, if you have three master-eligible nodes then you may put\nall of them in one zone or you may put two in one zone and the third in the\nother zone. You should not place an equal number of master-eligible nodes in\neach zone. If you place the same number of master-eligible nodes in each zone,\nneither zone has a majority of its own. Therefore, the cluster may not survive\nthe loss of either zone.\n\n[[high-availability-cluster-design-two-zones-plus]]\n==== Two-zone clusters with a tiebreaker\n\nThe two-zone deployment described above is tolerant to the loss of one of its\nzones but not to the loss of the other one because master elections are\nmajority-based. You cannot configure a two-zone cluster so that it can tolerate\nthe loss of _either_ zone because this is theoretically impossible. You might\nexpect that if either zone fails then {es} can elect a node from the remaining\nzone as the master but it is impossible to tell the difference between the\nfailure of a remote zone and a mere loss of connectivity between the zones. If\nboth zones were capable of running independent elections then a loss of\nconnectivity would lead to a\n{wikipedia}/Split-brain_(computing)[split-brain problem] and\ntherefore data loss. {es} avoids this and protects your data by not electing\na node from either zone as master until that node can be sure that it has the\nlatest cluster state and that there is no other master in the cluster. This may\nmean there is no master at all until connectivity is restored.\n\nYou can solve this by placing one master-eligible node in each of your two\nzones and adding a single extra master-eligible node in an independent third\nzone. The extra master-eligible node acts as a tiebreaker in cases\nwhere the two original zones are disconnected from each other. The extra\ntiebreaker node should be a <<voting-only-node,dedicated voting-only\nmaster-eligible node>>, also known as a dedicated tiebreaker. A dedicated\ntiebreaker need not be as powerful as the other two nodes since it has no other\nroles and will not perform any searches nor coordinate any client requests nor\nbe elected as the master of the cluster.\n\nYou should use <<shard-allocation-awareness,shard allocation awareness>> to ensure\nthat there is a copy of each shard in each zone. This means either zone remains\nfully available if the other zone fails.\n\nAll master-eligible nodes, including voting-only nodes, are on the critical\npath for <<cluster-state-publishing,publishing cluster state updates>>. Cluster\nstate updates are usually independent of performance-critical workloads such as\nindexing or searches, but they are involved in management activities such as\nindex creation and rollover, mapping updates, and recovery after a failure. The\nperformance characteristics of these activities are a function of the speed of\nthe storage on each master-eligible node, as well as the reliability and\nlatency of the network interconnections between all nodes in the cluster. You\nmust therefore ensure that the storage and networking available to the\nnodes in your cluster are good enough to meet your performance goals.\n\n[[high-availability-cluster-design-three-zones]]\n==== Clusters with three or more zones\n\nIf you have three zones then you should have one master-eligible node in each\nzone. If you have more than three zones then you should choose three of the\nzones and put a master-eligible node in each of these three zones. This will\nmean that the cluster can still elect a master even if one of the zones fails.\n\nAs always, your indices should have at least one replica in case a node fails,\nunless they are <<searchable-snapshots,searchable snapshot indices>>. You\nshould also use <<shard-allocation-awareness,shard allocation awareness>> to limit\nthe number of copies of each shard in each zone. For instance, if you have an\nindex with one or two replicas configured then allocation awareness will ensure\nthat the replicas of the shard are in a different zone from the primary. This\nmeans that a copy of every shard will still be available if one zone fails. The\navailability of this shard will not be affected by such a failure.\n\n[[high-availability-cluster-design-large-cluster-summary]]\n==== Summary\n\nThe cluster will be resilient to the loss of any zone as long as:\n\n- The <<cluster-health,cluster health status>> is `green`.\n- There are at least two zones containing data nodes.\n- Every index that is not a <<searchable-snapshots,searchable snapshot index>>\n  has at least one replica of each shard, in addition to the primary.\n- <<shard-allocation-awareness,Shard allocation awareness>> is configured to \n  avoid concentrating all copies of a shard within a single zone.\n- The cluster has at least three master-eligible nodes. At least two of these \n  nodes are not <<voting-only-node,voting-only master-eligible nodes>>, \n  and they are spread evenly across at least three zones.\n- Clients are configured to send their requests to nodes in more than one zone\n  or are configured to use a load balancer that balances the requests across an\n  appropriate set of nodes. The {ess-trial}[Elastic Cloud] service provides such\n  a load balancer.\n"
}
{
    "meta": {
        "size": 7448,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/learning-to-rank-model-training.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "learning-to-rank-model-training",
        "version": "8.15"
    },
    "doc": "[[learning-to-rank-model-training]]\n=== Deploy and manage Learning To Rank models\n++++\n<titleabbrev>Deploy and manage LTR models</titleabbrev>\n++++\n\nNOTE: This feature was introduced in version 8.12.0 and is only available to certain subscription levels.\nFor more information, see {subscriptions}.\n\n[discrete]\n[[learning-to-rank-model-training-workflow]]\n==== Train and deploy a model using Eland\n\nTypically, the https://xgboost.readthedocs.io/en/stable/[XGBoost^] model training process uses standard Python data science tools like Pandas and scikit-learn.\n\n\nWe have developed an\nhttps://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/08-learning-to-rank.ipynb[example\nnotebook^] available in the `elasticsearch-labs` repo. This interactive Python notebook\ndetails an end-to-end model training and deployment workflow.\n\nWe highly recommend using https://eland.readthedocs.io/[eland^] in your workflow, because it provides important functionalities for working with LTR in {es}. Use eland to:\n\n* Configure feature extraction\n\n* Extract features for training\n\n* Deploy the model in {es}\n\n[discrete]\n[[learning-to-rank-model-training-feature-definition]]\n===== Configure feature extraction in Eland\n\nFeature extractors are defined using templated queries. https://eland.readthedocs.io/[Eland^] provides the `eland.ml.ltr.QueryFeatureExtractor` to define these feature extractors directly in Python:\n\n[source,python]\n----\nfrom eland.ml.ltr import QueryFeatureExtractor\n\nfeature_extractors=[\n    # We want to use the BM25 score of the match query for the title field as a feature:\n    QueryFeatureExtractor(\n        feature_name=\"title_bm25\",\n        query={\"match\": {\"title\": \"{{query}}\"}}\n    ),\n    # We want to use the the number of matched terms in the title field as a feature:\n    QueryFeatureExtractor(\n        feature_name=\"title_matched_term_count\",\n        query={\n            \"script_score\": {\n                \"query\": {\"match\": {\"title\": \"{{query}}\"}},\n                \"script\": {\"source\": \"return _termStats.matchedTermsCount();\"},\n            }\n        },\n    ),\n    # We can use a script_score query to get the value\n    # of the field rating directly as a feature:\n    QueryFeatureExtractor(\n        feature_name=\"popularity\",\n        query={\n            \"script_score\": {\n                \"query\": {\"exists\": {\"field\": \"popularity\"}},\n                \"script\": {\"source\": \"return doc['popularity'].value;\"},\n            }\n        },\n    ),\n    # We extract the number of terms in the query as feature.\n   QueryFeatureExtractor(\n        feature_name=\"query_term_count\",\n        query={\n            \"script_score\": {\n                \"query\": {\"match\": {\"title\": \"{{query}}\"}},\n                \"script\": {\"source\": \"return _termStats.uniqueTermsCount();\"},\n            }\n        },\n    ),\n]\n----\n// NOTCONSOLE\n\n[NOTE]\n.Tern statistics as features\n===================================================\n\nIt is very common for an LTR model to leverage raw term statistics as features.\nTo extract this information, you can use the {ref}/modules-scripting-fields.html#scripting-term-statistics[term statistics feature] provided as part of the  <<query-dsl-script-score-query,`script_score`>> query.\n\n===================================================\n\nOnce the feature extractors have been defined, they are wrapped in an `eland.ml.ltr.LTRModelConfig` object for use in later training steps:\n\n[source,python]\n----\nfrom eland.ml.ltr import LTRModelConfig\n\nltr_config = LTRModelConfig(feature_extractors)\n----\n// NOTCONSOLE\n\n[discrete]\n[[learning-to-rank-model-training-feature-extraction]]\n===== Extracting features for training\n\nBuilding your dataset is a critical step in the training process. This involves\nextracting relevant features and adding them to your judgment list. We\nrecommend using Eland's `eland.ml.ltr.FeatureLogger` helper class for this\nprocess.\n\n[source,python]\n----\nfrom eland.ml.ltr import FeatureLogger\n\n# Create a feature logger that will be used to query {es} to retrieve the features:\nfeature_logger = FeatureLogger(es_client, MOVIE_INDEX, ltr_config)\n----\n// NOTCONSOLE\n\nThe FeatureLogger provides an `extract_features` method which enables you to extract features for a list of specific documents from your judgment list. At the same time, you can pass query parameters to the feature extractors defined earlier:\n\n[source,python]\n----\nfeature_logger.extract_features(\n    query_params={\"query\": \"foo\"},\n    doc_ids=[\"doc-1\", \"doc-2\"]\n)\n----\n// NOTCONSOLE\n\nOur https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/08-learning-to-rank.ipynb[example notebook^] explains how to use the `FeatureLogger` to build a training dataset, by adding features to a judgment list.\n\n[discrete]\n[[learning-to-rank-model-training-feature-extraction-notes]]\n====== Notes on feature extraction\n\n* We strongly advise against implementing feature extraction on your own. It's crucial to maintain consistency in feature extraction between the training environment and inference in {es}. By using eland tooling, which is developed and tested in tandem with {es}, you can ensure that they function together consistently.\n\n* Feature extraction is performed by executing queries on the {es} server. This could put a lot of stress on your cluster, especially when your judgment list contains a lot of examples or you have many features. Our feature logger implementation is designed to minimize the number of search requests sent to the server and reduce load. However, it might be best to build your training dataset using an {es} cluster that is isolated from any user-facing, production traffic.\n\n[discrete]\n[[learning-to-rank-model-deployment]]\n===== Deploy your model into {es}\n\nOnce your model is trained you will be able to deploy it in your {es} cluster. You can use Eland's `MLModel.import_ltr_model method`:\n\n[source,python]\n----\nfrom eland.ml import MLModel\n\nLEARNING_TO_RANK_MODEL_ID=\"ltr-model-xgboost\"\n\nMLModel.import_ltr_model(\n    es_client=es_client,\n    model=ranker,\n    model_id=LEARNING_TO_RANK_MODEL_ID,\n    ltr_model_config=ltr_config,\n    es_if_exists=\"replace\",\n)\n----\n// NOTCONSOLE\n\nThis method will serialize the trained model and the Learning To Rank configuration (including feature extraction) in a format that {es} can understand. The model is then deployed to {es} using the <<put-trained-models, Create Trained Models API>>.\n\nThe following types of models are currently supported for LTR with {es}:\n\n* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html[`DecisionTreeRegressor`^]\n* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html[`RandomForestRegressor`^]\n* https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html[`LGBMRegressor`^]\n* https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRanker[`XGBRanker`^]\n* https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor[`XGBRegressor`^]\n\n\nMore model types will be supported in the future.\n\n[discrete]\n[[learning-to-rank-model-management]]\n==== Learning To Rank model management\n\nOnce your model is deployed in {es} you can manage it using the https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-df-trained-models-apis.html[trained model APIs].\nYou're now ready to work with your LTR model as a rescorer at <<learning-to-rank-search-usage, search time>>.\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T03:02:53.698580",
        "size": 3530,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/task-queue-backlog.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "task-queue-backlog",
        "version": "8.15"
    },
    "doc": "[[task-queue-backlog]]\n=== Task queue backlog\n\nA backlogged task queue can prevent tasks from completing and put the cluster\ninto an unhealthy state. Resource constraints, a large number of tasks being\ntriggered at once, and long running tasks can all contribute to a backlogged\ntask queue.\n\n[discrete]\n[[diagnose-task-queue-backlog]]\n==== Diagnose a task queue backlog\n\n**Check the thread pool status**\n\nA <<high-cpu-usage,depleted thread pool>> can result in\n<<rejected-requests,rejected requests>>. \n\nThread pool depletion might be restricted to a specific <<data-tiers,data tier>>. If <<hotspotting,hot spotting>> is occuring, one node might experience depletion faster than other nodes, leading to performance issues and a growing task backlog.\n\nYou can use the <<cat-thread-pool,cat thread pool API>> to see the number of\nactive threads in each thread pool and how many tasks are queued, how many\nhave been rejected, and how many have completed.\n\n[source,console]\n----\nGET /_cat/thread_pool?v&s=t,n&h=type,name,node_name,active,queue,rejected,completed\n----\n\nThe `active` and `queue` statistics are instantaneous while the `rejected` and\n`completed` statistics are cumulative from node startup.\n\n**Inspect the hot threads on each node**\n\nIf a particular thread pool queue is backed up, you can periodically poll the\n<<cluster-nodes-hot-threads,Nodes hot threads>> API to determine if the thread\nhas sufficient resources to progress and gauge how quickly it is progressing.\n\n[source,console]\n----\nGET /_nodes/hot_threads\n----\n\n**Look for long running node tasks**\n\nLong-running tasks can also cause a backlog. You can use the <<tasks,task\nmanagement>> API to get information about the node tasks that are running.\nCheck the `running_time_in_nanos` to identify tasks that are taking an\nexcessive amount of time to complete.\n\n[source,console]\n----\nGET /_tasks?pretty=true&human=true&detailed=true\n----\n\nIf a particular `action` is suspected, you can filter the tasks further. The most common long-running tasks are <<docs-bulk,bulk index>>- or search-related.\n\n* Filter for <<docs-bulk,bulk index>> actions:\n+\n[source,console]\n----\nGET /_tasks?human&detailed&actions=indices:data/write/bulk\n----\n\n* Filter for search actions:\n+\n[source,console]\n----\nGET /_tasks?human&detailed&actions=indices:data/write/search\n----\n\nThe API response may contain additional tasks columns, including `description` and `header`, which provides the task parameters, target, and requestor. You can use this information to perform further diagnosis.\n\n**Look for long running cluster tasks**\n\nA task backlog might also appear as a delay in synchronizing the cluster state. You\ncan use the <<cluster-pending,cluster pending tasks API>> to get information\nabout the pending cluster state sync tasks that are running. \n\n[source,console]\n----\nGET /_cluster/pending_tasks\n----\n\nCheck the `timeInQueue` to identify tasks that are taking an excessive amount \nof time to complete.\n\n[discrete]\n[[resolve-task-queue-backlog]]\n==== Resolve a task queue backlog\n\n**Increase available resources** \n\nIf tasks are progressing slowly and the queue is backing up, \nyou might need to take steps to <<reduce-cpu-usage>>. \n\nIn some cases, increasing the thread pool size might help.\nFor example, the `force_merge` thread pool defaults to a single thread.\nIncreasing the size to 2 might help reduce a backlog of force merge requests.\n\n**Cancel stuck tasks**\n\nIf you find the active task's hot thread isn't progressing and there's a backlog, \nconsider canceling the task. "
}
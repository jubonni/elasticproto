{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.448082",
        "size": 2829,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-simple-analyzer.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-simple-analyzer",
        "version": "8.15"
    },
    "doc": "[[analysis-simple-analyzer]]\n=== Simple analyzer\n++++\n<titleabbrev>Simple</titleabbrev>\n++++\n\nThe `simple` analyzer breaks text into tokens at any non-letter character, such\nas numbers, spaces, hyphens and apostrophes, discards non-letter characters, \nand changes uppercase to lowercase.\n\n[[analysis-simple-analyzer-ex]]\n==== Example\n\n[source,console]\n----\nPOST _analyze\n{\n  \"analyzer\": \"simple\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n----\n\n////\n[source,console-result]\n----\n{\n  \"tokens\": [\n    {\n      \"token\": \"the\",\n      \"start_offset\": 0,\n      \"end_offset\": 3,\n      \"type\": \"word\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 6,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 12,\n      \"end_offset\": 17,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"foxes\",\n      \"start_offset\": 18,\n      \"end_offset\": 23,\n      \"type\": \"word\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"jumped\",\n      \"start_offset\": 24,\n      \"end_offset\": 30,\n      \"type\": \"word\",\n      \"position\": 4\n    },\n    {\n      \"token\": \"over\",\n      \"start_offset\": 31,\n      \"end_offset\": 35,\n      \"type\": \"word\",\n      \"position\": 5\n    },\n    {\n      \"token\": \"the\",\n      \"start_offset\": 36,\n      \"end_offset\": 39,\n      \"type\": \"word\",\n      \"position\": 6\n    },\n    {\n      \"token\": \"lazy\",\n      \"start_offset\": 40,\n      \"end_offset\": 44,\n      \"type\": \"word\",\n      \"position\": 7\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 45,\n      \"end_offset\": 48,\n      \"type\": \"word\",\n      \"position\": 8\n    },\n    {\n      \"token\": \"s\",\n      \"start_offset\": 49,\n      \"end_offset\": 50,\n      \"type\": \"word\",\n      \"position\": 9\n    },\n    {\n      \"token\": \"bone\",\n      \"start_offset\": 51,\n      \"end_offset\": 55,\n      \"type\": \"word\",\n      \"position\": 10\n    }\n  ]\n}\n----\n////\n\nThe `simple` analyzer parses the sentence and produces the following \ntokens: \n\n[source,text]\n----\n[ the, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]\n----\n\n[[analysis-simple-analyzer-definition]]\n==== Definition\n\nThe `simple` analyzer is defined by one tokenizer:\n\nTokenizer::\n* <<analysis-lowercase-tokenizer, Lowercase Tokenizer>>\n\n[[analysis-simple-analyzer-customize]]\n==== Customize\n\nTo customize the `simple` analyzer, duplicate it to create the basis for \na custom analyzer. This custom analyzer can be modified as required, usually by \nadding token filters.\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_custom_simple_analyzer\": {\n          \"tokenizer\": \"lowercase\",\n          \"filter\": [                          <1>\n          ]\n        }\n      }\n    }\n  }\n}\n----\n<1> Add token filters here.\n"
}
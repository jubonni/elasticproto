{
    "meta": {
        "timestamp": "2024-11-01T03:07:09.529273",
        "size": 5125,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-keep-types-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-keep-types-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-keep-types-tokenfilter]]\n=== Keep types token filter\n++++\n<titleabbrev>Keep types</titleabbrev>\n++++\n\nKeeps or removes tokens of a specific type. For example, you can use this filter\nto change `3 quick foxes` to `quick foxes` by keeping only `<ALPHANUM>`\n(alphanumeric) tokens.\n\n[NOTE]\n.Token types\n====\nToken types are set by the <<analysis-tokenizers,tokenizer>> when converting\ncharacters to tokens. Token types can vary between tokenizers.\n\nFor example, the <<analysis-standard-tokenizer,`standard`>> tokenizer can\nproduce a variety of token types, including `<ALPHANUM>`, `<HANGUL>`, and\n`<NUM>`. Simpler analyzers, like the\n<<analysis-lowercase-tokenizer,`lowercase`>> tokenizer, only produce the `word`\ntoken type.\n\nCertain token filters can also add token types. For example, the\n<<analysis-synonym-tokenfilter,`synonym`>> filter can add the `<SYNONYM>` token\ntype.\n\nSome tokenizers don't support this token filter, for example keyword, simple_pattern, and\nsimple_pattern_split tokenizers, as they don't support setting the token type attribute.\n====\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/core/TypeTokenFilter.html[TypeTokenFilter].\n\n[[analysis-keep-types-tokenfilter-analyze-include-ex]]\n==== Include example\n\nThe following <<indices-analyze,analyze API>> request uses the `keep_types`\nfilter to keep only `<NUM>` (numeric) tokens from `1 quick fox 2 lazy dogs`.\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"keep_types\",\n      \"types\": [ \"<NUM>\" ]\n    }\n  ],\n  \"text\": \"1 quick fox 2 lazy dogs\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ 1, 2 ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"1\",\n      \"start_offset\": 0,\n      \"end_offset\": 1,\n      \"type\": \"<NUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"2\",\n      \"start_offset\": 12,\n      \"end_offset\": 13,\n      \"type\": \"<NUM>\",\n      \"position\": 3\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-keep-types-tokenfilter-analyze-exclude-ex]]\n==== Exclude example\n\nThe following <<indices-analyze,analyze API>> request uses the `keep_types`\nfilter to remove `<NUM>` tokens from `1 quick fox 2 lazy dogs`. Note the `mode`\nparameter is set to `exclude`.\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"keep_types\",\n      \"types\": [ \"<NUM>\" ],\n      \"mode\": \"exclude\"\n    }\n  ],\n  \"text\": \"1 quick fox 2 lazy dogs\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ quick, fox, lazy, dogs ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 2,\n      \"end_offset\": 7,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"fox\",\n      \"start_offset\": 8,\n      \"end_offset\": 11,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"lazy\",\n      \"start_offset\": 14,\n      \"end_offset\": 18,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 4\n    },\n    {\n      \"token\": \"dogs\",\n      \"start_offset\": 19,\n      \"end_offset\": 23,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 5\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-keep-types-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`types`::\n(Required, array of strings)\nList of token types to keep or remove.\n\n`mode`::\n(Optional, string)\nIndicates whether to keep or remove the specified token types.\nValid values are:\n\n`include`:::\n(Default) Keep only the specified token types.\n\n`exclude`:::\nRemove the specified token types.\n\n[[analysis-keep-types-tokenfilter-customize]]\n==== Customize and add to an analyzer\n\nTo customize the `keep_types` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following <<indices-create-index,create index API>> request\nuses a custom `keep_types` filter to configure a new\n<<analysis-custom-analyzer,custom analyzer>>. The custom `keep_types` filter\nkeeps only `<ALPHANUM>` (alphanumeric) tokens.\n\n[source,console]\n--------------------------------------------------\nPUT keep_types_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"extract_alpha\" ]\n        }\n      },\n      \"filter\": {\n        \"extract_alpha\": {\n          \"type\": \"keep_types\",\n          \"types\": [ \"<ALPHANUM>\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
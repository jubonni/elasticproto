{
    "meta": {
        "size": 3600,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-flush.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "indices-flush",
        "version": "8.15"
    },
    "doc": "[[indices-flush]]\n=== Flush API\n++++\n<titleabbrev>Flush</titleabbrev>\n++++\n\nFlushes one or more data streams or indices.\n\n[source,console]\n--------------------------------------------------\nPOST /my-index-000001/_flush\n--------------------------------------------------\n// TEST[setup:my_index]\n\n\n[[flush-api-request]]\n==== {api-request-title}\n\n`POST /<target>/_flush`\n\n`GET /<target>/_flush`\n\n`POST /_flush`\n\n`GET /_flush`\n\n[[flush-api-prereqs]]\n==== {api-prereq-title}\n\n* If the {es} {security-features} are enabled, you must have the `maintenance`\nor `manage` <<privileges-list-indices,index privilege>> for the target data\nstream, index, or alias.\n\n[[flush-api-desc]]\n==== {api-description-title}\n\nFlushing a data stream or index is the process of making sure that any data that is currently\nonly stored in the <<index-modules-translog,transaction log>> is also\npermanently stored in the Lucene index. When restarting, {es} replays any\nunflushed operations from the transaction log in to the Lucene index to bring it\nback into the state that it was in before the restart. {es} automatically\ntriggers flushes as needed, using heuristics that trade off the size of the\nunflushed transaction log against the cost of performing each flush.\n\nOnce each operation has been flushed it is permanently stored in the Lucene\nindex. This may mean that there is no need to maintain an additional copy of it\nin the transaction log. The transaction log is made up of multiple files,\ncalled _generations_, and {es} will delete any generation files once they are no\nlonger needed, freeing up disk space.\n\nIt is also possible to trigger a flush on one or more indices using the flush\nAPI, although it is rare for users to need to call this API directly. If you\ncall the flush API after indexing some documents then a successful response\nindicates that {es} has flushed all the documents that were indexed before the\nflush API was called.\n\n\n[[flush-api-path-params]]\n==== {api-path-parms-title}\n\n`<target>`::\n(Optional, string) Comma-separated list of data streams, indices, and aliases to\nflush. Supports wildcards (`*`). To flush all data streams and indices, omit\nthis parameter or use `*` or `_all`.\n\n[[flush-api-query-params]]\n==== {api-query-parms-title}\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=allow-no-indices]\n+\nDefaults to `true`.\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=expand-wildcards]\n+\nDefaults to `open`.\n\n`force`::\n+\n--\n(Optional, Boolean)\nIf `true`,\nthe request forces a flush\neven if there are no changes to commit to the index.\nDefaults to `false`.\n\nYou can use this parameter\nto increment the generation number of the transaction log.\n\nThis parameter is considered internal.\n--\n\n\ninclude::{es-ref-dir}/rest-api/common-parms.asciidoc[tag=index-ignore-unavailable]\n\n`wait_if_ongoing`::\n+\n--\n(Optional, Boolean)\nIf `true`,\nthe flush operation blocks until execution\nwhen another flush operation is running.\n\n\nIf `false`,\n{es} returns an error\nif you request a flush\nwhen another flush operation is running.\n\nDefaults to `true`.\n--\n\n\n[[flush-api-example]]\n==== {api-examples-title}\n\n\n[[flush-api-specific-ex]]\n===== Flush a specific data stream or index\n\n[source,console]\n----\nPOST /my-index-000001/_flush\n----\n// TEST[s/^/PUT my-index-000001\\n/]\n\n\n[[flush-multi-index]]\n===== Flush several data streams and indices\n\n[source,console]\n----\nPOST /my-index-000001,my-index-000002/_flush\n----\n// TEST[s/^/PUT my-index-000001\\nPUT my-index-000002\\n/]\n\n\n[[flush-api-all-ex]]\n===== Flush all data streams and indices in a cluster\n\n[source,console]\n----\nPOST /_flush\n----\n"
}
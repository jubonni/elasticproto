{
    "meta": {
        "timestamp": "2024-11-01T03:07:10.209271",
        "size": 4429,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-service-google-vertex-ai.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "infer-service-google-vertex-ai",
        "version": "8.15"
    },
    "doc": "[[infer-service-google-vertex-ai]]\n=== Google Vertex AI {infer} service\n\nCreates an {infer} endpoint to perform an {infer} task with the `googlevertexai` service.\n\n\n[discrete]\n[[infer-service-google-vertex-ai-api-request]]\n==== {api-request-title}\n\n`PUT /_inference/<task_type>/<inference_id>`\n\n[discrete]\n[[infer-service-google-vertex-ai-path-params]]\n==== {api-path-parms-title}\n\n`<inference_id>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=inference-id]\n\n`<task_type>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=task-type]\n+\n--\nAvailable task types:\n\n* `rerank`\n* `text_embedding`.\n--\n\n[discrete]\n[[infer-service-google-vertex-ai-api-request-body]]\n==== {api-request-body-title}\n\n`chunking_settings`::\n(Optional, object)\ninclude::inference-shared.asciidoc[tag=chunking-settings]\n\n`max_chunking_size`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-max-chunking-size]\n\n`overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-overlap]\n\n`sentence_overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-sentence-overlap]\n\n`strategy`:::\n(Optional, string)\ninclude::inference-shared.asciidoc[tag=chunking-settings-strategy]\n\n`service`::\n(Required, string)\nThe type of service supported for the specified task type. In this case,\n`googlevertexai`.\n\n`service_settings`::\n(Required, object)\ninclude::inference-shared.asciidoc[tag=service-settings]\n+\n--\nThese settings are specific to the `googlevertexai` service.\n--\n\n`service_account_json`:::\n(Required, string)\nA valid service account in json format for the Google Vertex AI API.\n\n`model_id`:::\n(Required, string)\nThe name of the model to use for the {infer} task.\nYou can find the supported models at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api[Text embeddings API].\n\n`location`:::\n(Required, string)\nThe name of the location to use for the {infer} task.\nYou find the supported locations at https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations[Generative AI on Vertex AI locations].\n\n`project_id`:::\n(Required, string)\nThe name of the project to use for the {infer} task.\n\n`rate_limit`:::\n(Optional, object)\nBy default, the `googlevertexai` service sets the number of requests allowed per minute to `30.000`.\nThis helps to minimize the number of rate limit errors returned from Google Vertex AI.\nTo modify this, set the `requests_per_minute` setting of this object in your service settings:\n+\n--\ninclude::inference-shared.asciidoc[tag=request-per-minute-example]\n\nMore information about the rate limits for Google Vertex AI can be found in the https://cloud.google.com/vertex-ai/docs/quotas[Google Vertex AI Quotas docs].\n--\n\n`task_settings`::\n(Optional, object)\ninclude::inference-shared.asciidoc[tag=task-settings]\n+\n.`task_settings` for the `rerank` task type\n[%collapsible%closed]\n=====\n`top_n`:::\n(optional, boolean)\nSpecifies the number of the top n documents, which should be returned.\n=====\n+\n.`task_settings` for the `text_embedding` task type\n[%collapsible%closed]\n=====\n`auto_truncate`:::\n(optional, boolean)\nSpecifies if the API truncates inputs longer than the maximum token length automatically.\n=====\n\n[discrete]\n[[inference-example-google-vertex-ai]]\n==== Google Vertex AI service example\n\nThe following example shows how to create an {infer} endpoint called\n`google_vertex_ai_embeddings` to perform a `text_embedding` task type.\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/text_embedding/google_vertex_ai_embeddings\n{\n    \"service\": \"googlevertexai\",\n    \"service_settings\": {\n        \"service_account_json\": \"<service_account_json>\",\n        \"model_id\": \"<model_id>\",\n        \"location\": \"<location>\",\n        \"project_id\": \"<project_id>\"\n    }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n\nThe next example shows how to create an {infer} endpoint called\n`google_vertex_ai_rerank` to perform a `rerank` task type.\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/rerank/google_vertex_ai_rerank\n{\n    \"service\": \"googlevertexai\",\n    \"service_settings\": {\n        \"service_account_json\": \"<service_account_json>\",\n        \"project_id\": \"<project_id>\"\n    }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n"
}
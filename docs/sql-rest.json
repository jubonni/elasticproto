{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.231071",
        "size": 25230,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-rest.html",
        "type": "documentation",
        "role": [
            "xpack"
        ],
        "has_code": true,
        "title": "sql-rest",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[sql-rest]]\n== SQL REST API\n\n* <<sql-rest-overview>>\n* <<sql-rest-format>>\n* <<sql-pagination>>\n* <<sql-rest-filtering>>\n* <<sql-rest-columnar>>\n* <<sql-rest-params>>\n* <<sql-runtime-fields>>\n* <<sql-async>>\n\n[[sql-rest-overview]]\n=== Overview\n\nThe <<sql-search-api,SQL search API>> accepts SQL in a JSON document, executes\nit, and returns the results. For example:\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=txt\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC LIMIT 5\"\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nWhich returns:\n\n[source,text]\n--------------------------------------------------\n     author      |        name        |  page_count   | release_date\n-----------------+--------------------+---------------+------------------------\nPeter F. Hamilton|Pandora's Star      |768            |2004-03-02T00:00:00.000Z\nVernor Vinge     |A Fire Upon the Deep|613            |1992-06-01T00:00:00.000Z\nFrank Herbert    |Dune                |604            |1965-06-01T00:00:00.000Z\nAlastair Reynolds|Revelation Space    |585            |2000-03-15T00:00:00.000Z\nJames S.A. Corey |Leviathan Wakes     |561            |2011-06-02T00:00:00.000Z\n--------------------------------------------------\n// TESTRESPONSE[s/\\|/\\\\|/ s/\\+/\\\\+/]\n// TESTRESPONSE[non_json]\n\n[[sql-kibana-console]]\n[TIP]\n.Using Kibana Console\n====\nIf you are using {kibana-ref}/console-kibana.html[Kibana Console]\n(which is highly recommended), take advantage of the\ntriple quotes `\"\"\"` when creating the query. This not only automatically escapes double\nquotes (`\"`) inside the query string but also support multi-line as shown below:\n\nimage:images/sql/rest/console-triple-quotes.png[]\n====\n\n[[sql-rest-format]]\n=== Response Data Formats\n\nWhile the textual format is nice for humans, computers prefer something\nmore structured.\n\n{es-sql} can return the data in the following formats which can be set\neither through the `format` property in the URL or by setting the `Accept` HTTP header:\n\nNOTE: The URL parameter takes precedence over the `Accept` HTTP header.\nIf neither is specified then the response is returned in the same format as the request.\n\n[cols=\"^m,^4m,^8\"]\n\n|===\ns|format\ns|`Accept` HTTP header\ns|Description\n\n3+h| Human Readable\n\n|csv\n|text/csv\n|{wikipedia}/Comma-separated_values[Comma-separated values]\n\n|json\n|application/json\n|https://www.json.org/[JSON] (JavaScript Object Notation) human-readable format\n\n|tsv\n|text/tab-separated-values\n|{wikipedia}/Tab-separated_values[Tab-separated values]\n\n|txt\n|text/plain\n|CLI-like representation\n\n|yaml\n|application/yaml\n|{wikipedia}/YAML[YAML] (YAML Ain't Markup Language) human-readable format\n\n3+h| Binary Formats\n\n|cbor\n|application/cbor\n|https://cbor.io/[Concise Binary Object Representation]\n\n|smile\n|application/smile\n|{wikipedia}/Smile_(data_interchange_format)[Smile] binary data format similar to CBOR\n\n|===\n\nThe `CSV` format accepts a formatting URL query attribute, `delimiter`, which indicates which character should be used to separate the CSV\nvalues. It defaults to comma (`,`) and cannot take any of the following values: double quote (`\"`), carriage-return (`\\r`) and new-line (`\\n`).\nThe tab (`\\t`) can also not be used, the `tsv` format needs to be used instead.\n\nHere are some examples for the human readable formats:\n\n==== CSV\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=csv\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nwhich returns:\n\n[source,text]\n--------------------------------------------------\nauthor,name,page_count,release_date\nPeter F. Hamilton,Pandora's Star,768,2004-03-02T00:00:00.000Z\nVernor Vinge,A Fire Upon the Deep,613,1992-06-01T00:00:00.000Z\nFrank Herbert,Dune,604,1965-06-01T00:00:00.000Z\nAlastair Reynolds,Revelation Space,585,2000-03-15T00:00:00.000Z\nJames S.A. Corey,Leviathan Wakes,561,2011-06-02T00:00:00.000Z\n--------------------------------------------------\n// TESTRESPONSE[non_json]\n\nor:\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=csv&delimiter=%3b\n{\n    \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n    \"fetch_size\": 5\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nwhich returns:\n\n[source,text]\n--------------------------------------------------\nauthor;name;page_count;release_date\nPeter F. Hamilton;Pandora's Star;768;2004-03-02T00:00:00.000Z\nVernor Vinge;A Fire Upon the Deep;613;1992-06-01T00:00:00.000Z\nFrank Herbert;Dune;604;1965-06-01T00:00:00.000Z\nAlastair Reynolds;Revelation Space;585;2000-03-15T00:00:00.000Z\nJames S.A. Corey;Leviathan Wakes;561;2011-06-02T00:00:00.000Z\n--------------------------------------------------\n// TESTRESPONSE[non_json]\n\n==== JSON\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=json\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nWhich returns:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"columns\": [\n    {\"name\": \"author\",       \"type\": \"text\"},\n    {\"name\": \"name\",         \"type\": \"text\"},\n    {\"name\": \"page_count\",   \"type\": \"short\"},\n    {\"name\": \"release_date\", \"type\": \"datetime\"}\n  ],\n  \"rows\": [\n    [\"Peter F. Hamilton\",  \"Pandora's Star\",       768, \"2004-03-02T00:00:00.000Z\"],\n    [\"Vernor Vinge\",       \"A Fire Upon the Deep\", 613, \"1992-06-01T00:00:00.000Z\"],\n    [\"Frank Herbert\",      \"Dune\",                 604, \"1965-06-01T00:00:00.000Z\"],\n    [\"Alastair Reynolds\",  \"Revelation Space\",     585, \"2000-03-15T00:00:00.000Z\"],\n    [\"James S.A. Corey\",   \"Leviathan Wakes\",      561, \"2011-06-02T00:00:00.000Z\"]\n  ],\n  \"cursor\": \"sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl+v///w8=\"\n}\n--------------------------------------------------\n// TESTRESPONSE[s/sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl\\+v\\/\\/\\/w8=/$body.cursor/]\n\n==== TSV\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=tsv\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nWhich returns:\n\n[source,text]\n--------------------------------------------------\nauthor\tname\tpage_count\trelease_date\nPeter F. Hamilton\tPandora's Star\t768\t2004-03-02T00:00:00.000Z\nVernor Vinge\tA Fire Upon the Deep\t613\t1992-06-01T00:00:00.000Z\nFrank Herbert\tDune\t604\t1965-06-01T00:00:00.000Z\nAlastair Reynolds\tRevelation Space\t585\t2000-03-15T00:00:00.000Z\nJames S.A. Corey\tLeviathan Wakes\t561\t2011-06-02T00:00:00.000Z\n--------------------------------------------------\n// TESTRESPONSE[s/\\t/ /]\n// TESTRESPONSE[non_json]\n\n==== TXT\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=txt\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nWhich returns:\n\n[source,text]\n--------------------------------------------------\n     author      |        name        |  page_count   |      release_date\n-----------------+--------------------+---------------+------------------------\nPeter F. Hamilton|Pandora's Star      |768            |2004-03-02T00:00:00.000Z\nVernor Vinge     |A Fire Upon the Deep|613            |1992-06-01T00:00:00.000Z\nFrank Herbert    |Dune                |604            |1965-06-01T00:00:00.000Z\nAlastair Reynolds|Revelation Space    |585            |2000-03-15T00:00:00.000Z\nJames S.A. Corey |Leviathan Wakes     |561            |2011-06-02T00:00:00.000Z\n--------------------------------------------------\n// TESTRESPONSE[s/\\|/\\\\|/ s/\\+/\\\\+/]\n// TESTRESPONSE[non_json]\n\n==== YAML\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=yaml\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nWhich returns:\n\n[source,yaml]\n--------------------------------------------------\ncolumns:\n- name: \"author\"\n  type: \"text\"\n- name: \"name\"\n  type: \"text\"\n- name: \"page_count\"\n  type: \"short\"\n- name: \"release_date\"\n  type: \"datetime\"\nrows:\n- - \"Peter F. Hamilton\"\n  - \"Pandora's Star\"\n  - 768\n  - \"2004-03-02T00:00:00.000Z\"\n- - \"Vernor Vinge\"\n  - \"A Fire Upon the Deep\"\n  - 613\n  - \"1992-06-01T00:00:00.000Z\"\n- - \"Frank Herbert\"\n  - \"Dune\"\n  - 604\n  - \"1965-06-01T00:00:00.000Z\"\n- - \"Alastair Reynolds\"\n  - \"Revelation Space\"\n  - 585\n  - \"2000-03-15T00:00:00.000Z\"\n- - \"James S.A. Corey\"\n  - \"Leviathan Wakes\"\n  - 561\n  - \"2011-06-02T00:00:00.000Z\"\ncursor: \"sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl+v///w8=\"\n--------------------------------------------------\n// TESTRESPONSE[s/sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl\\+v\\/\\/\\/w8=/$body.cursor/]\n\n[[sql-pagination]]\n=== Paginating through a large response\n\nUsing the example from the <<sql-rest-format,previous section>>, one can\ncontinue to the next page by sending back the cursor field. In the case of CSV, TSV and TXT\nformats, the cursor is returned in the `Cursor` HTTP header.\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=json\n{\n  \"cursor\": \"sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWYUpOYklQMHhRUEtld3RsNnFtYU1hQQ==:BAFmBGRhdGUBZgVsaWtlcwFzB21lc3NhZ2UBZgR1c2Vy9f///w8=\"\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[s/sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWYUpOYklQMHhRUEtld3RsNnFtYU1hQQ==:BAFmBGRhdGUBZgVsaWtlcwFzB21lc3NhZ2UBZgR1c2Vy9f\\/\\/\\/w8=/$body.cursor/]\n\nWhich looks like:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"rows\" : [\n    [\"Dan Simmons\",        \"Hyperion\",             482,  \"1989-05-26T00:00:00.000Z\"],\n    [\"Iain M. Banks\",      \"Consider Phlebas\",     471,  \"1987-04-23T00:00:00.000Z\"],\n    [\"Neal Stephenson\",    \"Snow Crash\",           470,  \"1992-06-01T00:00:00.000Z\"],\n    [\"Frank Herbert\",      \"God Emperor of Dune\",  454,  \"1981-05-28T00:00:00.000Z\"],\n    [\"Frank Herbert\",      \"Children of Dune\",     408,  \"1976-04-21T00:00:00.000Z\"]\n  ],\n  \"cursor\" : \"sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWODRMaXBUaVlRN21iTlRyWHZWYUdrdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl9f///w8=\"\n}\n--------------------------------------------------\n// TESTRESPONSE[s/sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWODRMaXBUaVlRN21iTlRyWHZWYUdrdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl9f\\/\\/\\/w8=/$body.cursor/]\n\nNote that the `columns` object is only part of the first page.\n\nYou've reached the last page when there is no `cursor` returned\nin the results. Like Elasticsearch's <<scroll-search-results,scroll>>,\nSQL may keep state in Elasticsearch to support the cursor. Unlike\nscroll, receiving the last page is enough to guarantee that the\nElasticsearch state is cleared.\n\nTo clear the state earlier, use the <<clear-sql-cursor-api,clear cursor API>>:\n\n[source,console]\n--------------------------------------------------\nPOST /_sql/close\n{\n  \"cursor\": \"sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWYUpOYklQMHhRUEtld3RsNnFtYU1hQQ==:BAFmBGRhdGUBZgVsaWtlcwFzB21lc3NhZ2UBZgR1c2Vy9f///w8=\"\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[s/sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWYUpOYklQMHhRUEtld3RsNnFtYU1hQQ==:BAFmBGRhdGUBZgVsaWtlcwFzB21lc3NhZ2UBZgR1c2Vy9f\\/\\/\\/w8=/$body.cursor/]\n\nWhich will like return the\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"succeeded\" : true\n}\n--------------------------------------------------\n\n\n[[sql-rest-filtering]]\n=== Filtering using {es} Query DSL\n\nOne can filter the results that SQL will run on using a standard\n{es} Query DSL by specifying the query in the filter\nparameter.\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=txt\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"filter\": {\n    \"range\": {\n      \"page_count\": {\n        \"gte\" : 100,\n        \"lte\" : 200\n      }\n    }\n  },\n  \"fetch_size\": 5\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nWhich returns:\n\n[source,text]\n--------------------------------------------------\n    author     |                name                |  page_count   | release_date\n---------------+------------------------------------+---------------+------------------------\nDouglas Adams  |The Hitchhiker's Guide to the Galaxy|180            |1979-10-12T00:00:00.000Z\n--------------------------------------------------\n// TESTRESPONSE[s/\\|/\\\\|/ s/\\+/\\\\+/]\n// TESTRESPONSE[non_json]\n\n[TIP]\n=================\nA useful and less obvious usage for standard Query DSL filtering is to search documents by a specific <<search-routing, routing key>>.\nBecause {es-sql} does not support a `routing` parameter, one can specify a <<mapping-routing-field, `terms` filter for the `_routing` field>> instead:\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=txt\n{\n  \"query\": \"SELECT * FROM library\",\n  \"filter\": {\n    \"terms\": {\n      \"_routing\": [\"abc\"]\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:library]\n=================\n\n[[sql-rest-columnar]]\n=== Columnar results\n\nThe most well known way of displaying the results of an SQL query result in general is the one where each\nindividual record/document represents one line/row. For certain formats, {es-sql} can return the results\nin a columnar fashion: one row represents all the values of a certain column from the current page of results.\n\nThe following formats can be returned in columnar orientation: `json`, `yaml`, `cbor` and `smile`.\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=json\n{\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5,\n  \"columnar\": true\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nWhich returns:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"columns\": [\n    {\"name\": \"author\", \"type\": \"text\"},\n    {\"name\": \"name\", \"type\": \"text\"},\n    {\"name\": \"page_count\", \"type\": \"short\"},\n    {\"name\": \"release_date\", \"type\": \"datetime\"}\n  ],\n  \"values\": [\n    [\"Peter F. Hamilton\", \"Vernor Vinge\", \"Frank Herbert\", \"Alastair Reynolds\", \"James S.A. Corey\"],\n    [\"Pandora's Star\", \"A Fire Upon the Deep\", \"Dune\", \"Revelation Space\", \"Leviathan Wakes\"],\n    [768, 613, 604, 585, 561],\n    [\"2004-03-02T00:00:00.000Z\", \"1992-06-01T00:00:00.000Z\", \"1965-06-01T00:00:00.000Z\", \"2000-03-15T00:00:00.000Z\", \"2011-06-02T00:00:00.000Z\"]\n  ],\n  \"cursor\": \"sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl+v///w8=\"\n}\n--------------------------------------------------\n// TESTRESPONSE[s/sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl\\+v\\/\\/\\/w8=/$body.cursor/]\n\nAny subsequent calls using a `cursor` still have to contain the `columnar` parameter to preserve the orientation,\nmeaning the initial query will not _remember_ the columnar option.\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=json\n{\n  \"cursor\": \"sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl+v///w8=\",\n  \"columnar\": true\n}\n--------------------------------------------------\n// TEST[continued]\n// TEST[s/sDXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAEWWWdrRlVfSS1TbDYtcW9lc1FJNmlYdw==:BAFmBmF1dGhvcgFmBG5hbWUBZgpwYWdlX2NvdW50AWYMcmVsZWFzZV9kYXRl\\+v\\/\\/\\/w8=/$body.cursor/]\n\nWhich looks like:\n\n[source,console-result]\n--------------------------------------------------\n{\n  \"values\": [\n    [\"Dan Simmons\", \"Iain M. Banks\", \"Neal Stephenson\", \"Frank Herbert\", \"Frank Herbert\"],\n    [\"Hyperion\", \"Consider Phlebas\", \"Snow Crash\", \"God Emperor of Dune\", \"Children of Dune\"],\n    [482, 471, 470, 454, 408],\n    [\"1989-05-26T00:00:00.000Z\", \"1987-04-23T00:00:00.000Z\", \"1992-06-01T00:00:00.000Z\", \"1981-05-28T00:00:00.000Z\", \"1976-04-21T00:00:00.000Z\"]\n  ],\n  \"cursor\": \"46ToAwFzQERYRjFaWEo1UVc1a1JtVjBZMmdCQUFBQUFBQUFBQUVXWjBaNlFXbzNOV0pVY21Wa1NUZDJhV2t3V2xwblp3PT3/////DwQBZgZhdXRob3IBBHRleHQAAAFmBG5hbWUBBHRleHQAAAFmCnBhZ2VfY291bnQBBGxvbmcBAAFmDHJlbGVhc2VfZGF0ZQEIZGF0ZXRpbWUBAAEP\"\n}\n--------------------------------------------------\n// TESTRESPONSE[s/46ToAwFzQERYRjFaWEo1UVc1a1JtVjBZMmdCQUFBQUFBQUFBQUVXWjBaNlFXbzNOV0pVY21Wa1NUZDJhV2t3V2xwblp3PT3\\/\\/\\/\\/\\/DwQBZgZhdXRob3IBBHRleHQAAAFmBG5hbWUBBHRleHQAAAFmCnBhZ2VfY291bnQBBGxvbmcBAAFmDHJlbGVhc2VfZGF0ZQEIZGF0ZXRpbWUBAAEP/$body.cursor/]\n\n[[sql-rest-params]]\n=== Passing parameters to a query\n\nUsing values in a query condition, for example, or in a `HAVING` statement can be done \"inline\",\nby integrating the value in the query string itself:\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=txt\n{\n\t\"query\": \"SELECT YEAR(release_date) AS year FROM library WHERE page_count > 300 AND author = 'Frank Herbert' GROUP BY year HAVING COUNT(*) > 0\"\n}\n--------------------------------------------------\n// TEST[setup:library]\n\nor it can be done by extracting the values in a separate list of parameters and using question mark placeholders (`?`) in the query string:\n\n[source,console]\n--------------------------------------------------\nPOST /_sql?format=txt\n{\n\t\"query\": \"SELECT YEAR(release_date) AS year FROM library WHERE page_count > ? AND author = ? GROUP BY year HAVING COUNT(*) > ?\",\n\t\"params\": [300, \"Frank Herbert\", 0]\n}\n--------------------------------------------------\n// TEST[setup:library]\n\n[IMPORTANT]\nThe recommended way of passing values to a query is with question mark placeholders, to avoid any attempts of hacking or SQL injection.\n\n[[sql-runtime-fields]]\n=== Use runtime fields\n\nUse the `runtime_mappings` parameter to extract and create <<runtime,runtime\nfields>>, or columns, from existing ones during a search.\n\nThe following search creates a `release_day_of_week` runtime field from\n`release_date` and returns it in the response.\n\n[source,console]\n----\nPOST _sql?format=txt\n{\n  \"runtime_mappings\": {\n    \"release_day_of_week\": {\n      \"type\": \"keyword\",\n      \"script\": \"\"\"\n        emit(doc['release_date'].value.dayOfWeekEnum.toString())\n      \"\"\"\n    }\n  },\n  \"query\": \"\"\"\n    SELECT * FROM library WHERE page_count > 300 AND author = 'Frank Herbert'\n  \"\"\"\n}\n----\n// TEST[setup:library]\n\nThe API returns:\n\n[source,txt]\n----\n    author     |     name      |  page_count   |      release_date      |release_day_of_week\n---------------+---------------+---------------+------------------------+-------------------\nFrank Herbert  |Dune           |604            |1965-06-01T00:00:00.000Z|TUESDAY\n----\n// TESTRESPONSE[non_json]\n\n[[sql-async]]\n=== Run an async SQL search\n\nBy default, SQL searches are synchronous. They wait for complete results before\nreturning a response. However, results can take longer for searches across large\ndata sets or <<data-tiers,frozen data>>.\n\nTo avoid long waits, run an async SQL search. Set `wait_for_completion_timeout`\nto a duration you\u2019d like to wait for synchronous results.\n\n[source,console]\n----\nPOST _sql?format=json\n{\n  \"wait_for_completion_timeout\": \"2s\",\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n----\n// TEST[skip:waiting on https://github.com/elastic/elasticsearch/issues/106158]\n// TEST[setup:library]\n// TEST[s/\"wait_for_completion_timeout\": \"2s\"/\"wait_for_completion_timeout\": \"0\"/]\n\nIf the search doesn\u2019t finish within this period, the search becomes async. The\nAPI returns:\n\n* An `id` for the search.\n* An `is_partial` value of `true`, indicating the search results are incomplete.\n* An `is_running` value of `true`, indicating the search is still running in the\nbackground.\n\nFor CSV, TSV, and TXT responses, the API returns these values in the respective\n`Async-ID`, `Async-partial`, and `Async-running` HTTP headers instead.\n\n[source,console-result]\n----\n{\n  \"id\": \"FnR0TDhyWUVmUmVtWXRWZER4MXZiNFEad2F5UDk2ZVdTVHV1S0xDUy00SklUdzozMTU=\",\n  \"is_partial\": true,\n  \"is_running\": true,\n  \"rows\": [ ]\n}\n----\n// TESTRESPONSE[skip:waiting on https://github.com/elastic/elasticsearch/issues/106158]\n// TESTRESPONSE[s/FnR0TDhyWUVmUmVtWXRWZER4MXZiNFEad2F5UDk2ZVdTVHV1S0xDUy00SklUdzozMTU=/$body.id/]\n// TESTRESPONSE[s/\"is_partial\": true/\"is_partial\": $body.is_partial/]\n// TESTRESPONSE[s/\"is_running\": true/\"is_running\": $body.is_running/]\n\nTo check the progress of an async search, use the search ID with the\n<<get-async-sql-search-status-api,get async SQL search status API>>.\n\n[source,console]\n----\nGET _sql/async/status/FnR0TDhyWUVmUmVtWXRWZER4MXZiNFEad2F5UDk2ZVdTVHV1S0xDUy00SklUdzozMTU=\n----\n// TEST[skip: no access to search ID]\n\nIf `is_running` and `is_partial` are `false`, the async search has finished with\ncomplete results.\n\n[source,console-result]\n----\n{\n  \"id\": \"FnR0TDhyWUVmUmVtWXRWZER4MXZiNFEad2F5UDk2ZVdTVHV1S0xDUy00SklUdzozMTU=\",\n  \"is_running\": false,\n  \"is_partial\": false,\n  \"expiration_time_in_millis\": 1611690295000,\n  \"completion_status\": 200\n}\n----\n// TESTRESPONSE[skip:waiting on https://github.com/elastic/elasticsearch/issues/106158]\n// TESTRESPONSE[s/FnR0TDhyWUVmUmVtWXRWZER4MXZiNFEad2F5UDk2ZVdTVHV1S0xDUy00SklUdzozMTU=/$body.id/]\n// TESTRESPONSE[s/\"expiration_time_in_millis\": 1611690295000/\"expiration_time_in_millis\": $body.expiration_time_in_millis/]\n\nTo get the results, use the search ID with the <<get-async-sql-search-api,get\nasync SQL search API>>. If the search is still running, specify how long you\u2019d\nlike to wait using `wait_for_completion_timeout`. You can also specify the\nresponse `format`.\n\n[source,console]\n----\nGET _sql/async/FnR0TDhyWUVmUmVtWXRWZER4MXZiNFEad2F5UDk2ZVdTVHV1S0xDUy00SklUdzozMTU=?wait_for_completion_timeout=2s&format=json\n----\n// TEST[skip: no access to search ID]\n\n[discrete]\n[[sql-async-retention]]\n==== Change the search retention period\n\nBy default, {es} stores async SQL searches for five days. After this period,\n{es} deletes the search and its results, even if the search is still running. To\nchange this retention period, use the `keep_alive` parameter.\n\n[source,console]\n----\nPOST _sql?format=json\n{\n  \"keep_alive\": \"2d\",\n  \"wait_for_completion_timeout\": \"2s\",\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n----\n// TEST[skip:waiting on https://github.com/elastic/elasticsearch/issues/106158]\n// TEST[setup:library]\n\nYou can use the get async SQL search API's `keep_alive` parameter to later\nchange the retention period. The new period starts after the request runs.\n\n[source,console]\n----\nGET _sql/async/FmdMX2pIang3UWhLRU5QS0lqdlppYncaMUpYQ05oSkpTc3kwZ21EdC1tbFJXQToxOTI=?keep_alive=5d&wait_for_completion_timeout=2s&format=json\n----\n// TEST[skip: no access to search ID]\n\nUse the <<delete-async-sql-search-api,delete async SQL search API>> to delete an\nasync search before the `keep_alive` period ends. If the search is still\nrunning, {es} cancels it.\n\n[source,console]\n----\nDELETE _sql/async/delete/FmdMX2pIang3UWhLRU5QS0lqdlppYncaMUpYQ05oSkpTc3kwZ21EdC1tbFJXQToxOTI=\n----\n// TEST[skip: no access to search ID]\n\n[discrete]\n[[sql-store-searches]]\n==== Store synchronous SQL searches\n\nBy default, {es} only stores async SQL searches. To save a synchronous search,\nspecify `wait_for_completion_timeout` and set `keep_on_completion` to `true`.\n\n[source,console]\n----\nPOST _sql?format=json\n{\n  \"keep_on_completion\": true,\n  \"wait_for_completion_timeout\": \"2s\",\n  \"query\": \"SELECT * FROM library ORDER BY page_count DESC\",\n  \"fetch_size\": 5\n}\n----\n// TEST[skip:waiting on https://github.com/elastic/elasticsearch/issues/106158]\n// TEST[setup:library]\n\nIf `is_partial` and `is_running` are `false`, the search was synchronous and\nreturned complete results.\n\n[source,console-result]\n----\n{\n  \"id\": \"Fnc5UllQdUVWU0NxRFNMbWxNYXplaFEaMUpYQ05oSkpTc3kwZ21EdC1tbFJXQTo0NzA=\",\n  \"is_partial\": false,\n  \"is_running\": false,\n  \"rows\": ...,\n  \"columns\": ...,\n  \"cursor\": ...\n}\n----\n// TESTRESPONSE[skip:waiting on https://github.com/elastic/elasticsearch/issues/106158]\n// TESTRESPONSE[s/Fnc5UllQdUVWU0NxRFNMbWxNYXplaFEaMUpYQ05oSkpTc3kwZ21EdC1tbFJXQTo0NzA=/$body.id/]\n// TESTRESPONSE[s/\"rows\": \\.\\.\\./\"rows\": $body.rows/]\n// TESTRESPONSE[s/\"columns\": \\.\\.\\./\"columns\": $body.columns/]\n// TESTRESPONSE[s/\"cursor\": \\.\\.\\./\"cursor\": $body.cursor/]\n\nYou can get the same results later using the search ID with the\n<<get-async-sql-search-api,get async SQL search API>>.\n\nSaved synchronous searches are still subject to the `keep_alive` retention\nperiod. When this period ends, {es} deletes the search results. You can also\ndelete saved searches using the <<delete-async-sql-search-api,delete async SQL\nsearch API>>.\n"
}
{
    "meta": {
        "timestamp": "2024-11-01T02:49:25.156068",
        "size": 22224,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-function-score-query.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "query-dsl-function-score-query",
        "version": "8.15"
    },
    "doc": "[[query-dsl-function-score-query]]\n=== Function score query\n++++\n<titleabbrev>Function score</titleabbrev>\n++++\n\nThe `function_score` allows you to modify the score of documents that are\nretrieved by a query. This can be useful if, for example, a score\nfunction is computationally expensive and it is sufficient to compute\nthe score on a filtered set of documents.\n\nTo use `function_score`, the user has to define a query and one or\nmore functions, that compute a new score for each document returned\nby the query.\n\n`function_score` can be used with only one function like this:\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": { \"match_all\": {} },\n      \"boost\": \"5\",\n      \"random_score\": {}, <1>\n      \"boost_mode\": \"multiply\"\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\n<1> See <<score-functions>> for a list of supported functions.\n\nFurthermore, several functions can be combined. In this case one can\noptionally choose to apply the function only if a document matches a\ngiven filtering query\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": { \"match_all\": {} },\n      \"boost\": \"5\", <1>\n      \"functions\": [\n        {\n          \"filter\": { \"match\": { \"test\": \"bar\" } },\n          \"random_score\": {}, <2>\n          \"weight\": 23\n        },\n        {\n          \"filter\": { \"match\": { \"test\": \"cat\" } },\n          \"weight\": 42\n        }\n      ],\n      \"max_boost\": 42,\n      \"score_mode\": \"max\",\n      \"boost_mode\": \"multiply\",\n      \"min_score\": 42\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\n<1> Boost for the whole query.\n<2> See <<score-functions>> for a list of supported functions.\n\nNOTE: The scores produced by the filtering query of each function do not matter.\n\nIf no filter is given with a function this is equivalent to specifying\n`\"match_all\": {}`\n\nFirst, each document is scored by the defined functions. The parameter\n`score_mode` specifies how the computed scores are combined:\n\n[horizontal]\n`multiply`::    scores are multiplied (default)\n`sum`::         scores are summed\n`avg`::         scores are averaged\n`first`::       the first function that has a matching filter\n                is applied\n`max`::         maximum score is used\n`min`::         minimum score is used\n\nBecause scores can be on different scales (for example, between 0 and 1 for decay functions but arbitrary for `field_value_factor`) and also\nbecause sometimes a different impact of functions on the score is desirable, the score of each function can be adjusted with a user defined\n`weight`. The `weight` can be defined per function in the `functions` array (example above) and is multiplied with the score computed by\nthe respective function.\nIf weight is given without any other function declaration, `weight` acts as a function that simply returns the `weight`.\n\nIn case `score_mode` is set to `avg` the individual scores will be combined by a **weighted** average.\nFor example, if two functions return score 1 and 2 and their respective weights are 3 and 4, then their scores will be combined as\n`(1*3+2*4)/(3+4)` and **not** `(1*3+2*4)/2`.\n\nThe new score can be restricted to not exceed a certain limit by setting\nthe `max_boost` parameter. The default for `max_boost` is FLT_MAX.\n\nThe newly computed score is combined with the score of the\nquery. The parameter `boost_mode` defines how:\n\n[horizontal]\n`multiply`::    query score and function score is multiplied (default)\n`replace`::     only function score is used, the query score is ignored\n`sum`::         query score and function score are added\n`avg`::         average\n`max`::         max of query score and function score\n`min`::         min of query score and function score\n\nBy default, modifying the score does not change which documents match. To exclude\ndocuments that do not meet a certain score threshold the `min_score` parameter can be set to the desired score threshold.\n\nNOTE: For `min_score` to work, **all** documents returned by the query need to be scored and then filtered out one by one.\n\n[[score-functions]]\n\nThe `function_score` query provides several types of score functions.\n\n* <<function-script-score,`script_score`>>\n* <<function-weight,`weight`>>\n* <<function-random,`random_score`>>\n* <<function-field-value-factor,`field_value_factor`>>\n* <<function-decay,decay functions>>: `gauss`, `linear`, `exp`\n\n[[function-script-score]]\n==== Script score\n\nThe `script_score` function allows you to wrap another query and customize\nthe scoring of it optionally with a computation derived from other numeric\nfield values in the doc using a script expression. Here is a\nsimple sample:\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": { \"message\": \"elasticsearch\" }\n      },\n      \"script_score\": {\n        \"script\": {\n          \"source\": \"Math.log(2 + doc['my-int'].value)\"\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\n[IMPORTANT]\n====\nIn {es}, all document scores are positive 32-bit floating point numbers.\n\nIf the `script_score` function produces a score with greater precision, it is\nconverted to the nearest 32-bit float. \n\nSimilarly, scores must be non-negative. Otherwise, {es} returns an error.\n====\n\nOn top of the different scripting field values and expression, the\n`_score` script parameter can be used to retrieve the score based on the\nwrapped query.\n\nScripts compilation is cached for faster execution. If the script has\nparameters that it needs to take into account, it is preferable to reuse the\nsame script, and provide parameters to it:\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": { \"message\": \"elasticsearch\" }\n      },\n      \"script_score\": {\n        \"script\": {\n          \"params\": {\n            \"a\": 5,\n            \"b\": 1.2\n          },\n          \"source\": \"params.a / Math.pow(params.b, doc['my-int'].value)\"\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\nNote that unlike the `custom_score` query, the\nscore of the query is multiplied with the result of the script scoring. If\nyou wish to inhibit this, set `\"boost_mode\": \"replace\"`\n\n[[function-weight]]\n==== Weight\n\nThe `weight` score allows you to multiply the score by the provided\n`weight`. This can sometimes be desired since boost value set on\nspecific queries gets normalized, while for this score function it does\nnot. The number value is of type float.\n\n[source,js]\n--------------------------------------------------\n\"weight\" : number\n--------------------------------------------------\n// NOTCONSOLE\n// I couldn't come up with a good example for this one.\n\n[[function-random]]\n==== Random\n\nThe `random_score` generates scores that are uniformly distributed from 0 up to\nbut not including 1. By default, it uses the internal Lucene doc ids as a\nsource of randomness, which is very efficient but unfortunately not\nreproducible since documents might be renumbered by merges.\n\nIn case you want scores to be reproducible, it is possible to provide a `seed`\nand `field`. The final score will then be computed based on this seed, the\nminimum value of `field` for the considered document and a salt that is computed\nbased on the index name and shard id so that documents that have the same\nvalue but are stored in different indexes get different scores. Note that\ndocuments that are within the same shard and have the same value for `field`\nwill however get the same score, so it is usually desirable to use a field that\nhas unique values for all documents. A good default choice might be to use the\n`_seq_no` field, whose only drawback is that scores will change if the document\nis updated since update operations also update the value of the `_seq_no` field.\n\nNOTE: It was possible to set a seed without setting a field, but this has been\ndeprecated as this requires loading fielddata on the `_id` field which consumes\na lot of memory.\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"random_score\": {\n        \"seed\": 10,\n        \"field\": \"_seq_no\"\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\n[[function-field-value-factor]]\n==== Field Value factor\n\nThe `field_value_factor` function allows you to use a field from a document to\ninfluence the score. It's similar to using the `script_score` function, however,\nit avoids the overhead of scripting. If used on a multi-valued field, only the\nfirst value of the field is used in calculations.\n\nAs an example, imagine you have a document indexed with a numeric `my-int`\nfield and wish to influence the score of a document with this field, an example\ndoing so would look like:\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"field_value_factor\": {\n        \"field\": \"my-int\",\n        \"factor\": 1.2,\n        \"modifier\": \"sqrt\",\n        \"missing\": 1\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\nWhich will translate into the following formula for scoring:\n\n`sqrt(1.2 * doc['my-int'].value)`\n\nThere are a number of options for the `field_value_factor` function:\n\n[horizontal]\n`field`::\n\n    Field to be extracted from the document.\n\n`factor`::\n\n    Optional factor to multiply the field value with, defaults to `1`.\n\n`modifier`::\n\n    Modifier to apply to the field value, can be one of: `none`, `log`,\n    `log1p`, `log2p`, `ln`, `ln1p`, `ln2p`, `square`, `sqrt`, or `reciprocal`.\n    Defaults to `none`.\n\n[cols=\"<,<\",options=\"header\",]\n|=======================================================================\n| Modifier | Meaning\n\n| `none` | Do not apply any multiplier to the field value\n| `log` | Take the {wikipedia}/Common_logarithm[common logarithm] of the field value.\n          Because this function will return a negative value and cause an error if used on values\n          between 0 and 1, it is recommended to use `log1p` instead.\n| `log1p` | Add 1 to the field value and take the common logarithm\n| `log2p` | Add 2 to the field value and take the common logarithm\n| `ln` | Take the {wikipedia}/Natural_logarithm[natural logarithm] of the field value.\n         Because this function will return a negative value and cause an error if used on values\n         between 0 and 1, it is recommended to use `ln1p` instead.\n| `ln1p` | Add 1 to the field value and take the natural logarithm\n| `ln2p` | Add 2 to the field value and take the natural logarithm\n| `square` | Square the field value (multiply it by itself)\n| `sqrt` | Take the {wikipedia}/Square_root[square root] of the field value\n| `reciprocal` | {wikipedia}/Multiplicative_inverse[Reciprocate] the field value, same as `1/x` where `x` is the field's value\n|=======================================================================\n\n`missing`::\n\n    Value used if the document doesn't have that field. The modifier\n    and factor are still applied to it as though it were read from the document.\n\nNOTE: Scores produced by the `field_value_score` function must be\nnon-negative, otherwise an error will be thrown. The `log` and `ln` modifiers\nwill produce negative values if used on values between 0 and 1. Be sure to limit\nthe values of the field with a range filter to avoid this, or use `log1p` and\n`ln1p`.\n\nNOTE: Keep in mind that taking the log() of 0, or the square root of a\nnegative number is an illegal operation, and an exception will be thrown. Be\nsure to limit the values of the field with a range filter to avoid this, or use\n`log1p` and `ln1p`.\n\n\n[[function-decay]]\n==== Decay functions\n\nDecay functions score a document with a function that decays depending\non the distance of a numeric field value of the document from a user\ngiven origin. This is similar to a range query, but with smooth edges\ninstead of boxes.\n\nTo use distance scoring on a query that has numerical fields, the user\nhas to define an `origin` and a `scale` for each field. The `origin`\nis needed to define the ``central point'' from which the distance\nis calculated, and the `scale` to define the rate of decay. The\ndecay function is specified as\n\n[source,js]\n--------------------------------------------------\n\"DECAY_FUNCTION\": { <1>\n    \"FIELD_NAME\": { <2>\n          \"origin\": \"11, 12\",\n          \"scale\": \"2km\",\n          \"offset\": \"0km\",\n          \"decay\": 0.33\n    }\n}\n--------------------------------------------------\n// NOTCONSOLE\n<1> The `DECAY_FUNCTION` should be one of `linear`, `exp`, or `gauss`.\n<2> The specified field must be a numeric, date, or geopoint field.\n\nIn the above example, the field is a <<geo-point,`geo_point`>> and origin can\nbe provided in geo format. `scale` and `offset` must be given with a unit in\nthis case. If your field is a date field, you can set `scale` and `offset` as\ndays, weeks, and so on. Example:\n\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"gauss\": {\n        \"@timestamp\": {\n          \"origin\": \"2013-09-17\", <1>\n          \"scale\": \"10d\",\n          \"offset\": \"5d\",         <2>\n          \"decay\": 0.5            <2>\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:my_index]\n\n<1> The date format of the origin depends on the <<mapping-date-format,`format`>> defined in\n    your mapping. If you do not define the origin, the current time is used.\n<2> The `offset` and `decay` parameters are optional.\n\n[horizontal]\n`origin`::\n    The point of origin used for calculating distance. Must be given as a\n    number for numeric field, date for date fields and geo point for geo fields.\n    Required for geo and numeric field. For date fields the default is `now`. Date\n    math (for example `now-1h`) is supported for origin.\n\n`scale`::\n    Required for all types. Defines the distance from origin + offset at which the computed\n    score will equal `decay` parameter. For geo fields: Can be defined as number+unit (1km, 12m,...).\n    Default unit is meters. For date fields: Can to be defined as a number+unit (\"1h\", \"10d\",...).\n    Default unit is milliseconds. For numeric field: Any number.\n\n`offset`::\n    If an `offset` is defined, the decay function will only compute the\n    decay function for documents with a distance greater than the defined\n    `offset`. The default is 0.\n\n`decay`::\n    The `decay` parameter defines how documents are scored at the distance\n    given at `scale`. If no `decay` is defined, documents at the distance\n    `scale` will be scored 0.5.\n\nIn the first example, your documents might represents hotels and contain a geo\nlocation field. You want to compute a decay function depending on how\nfar the hotel is from a given location. You might not immediately see\nwhat scale to choose for the gauss function, but you can say something\nlike: \"At a distance of 2km from the desired location, the score should\nbe reduced to one third.\"\nThe parameter \"scale\" will then be adjusted automatically to assure that\nthe score function computes a score of 0.33 for hotels that are 2km away\nfrom the desired location.\n\n\nIn the second example, documents with a field value between 2013-09-12 and 2013-09-22 would get a weight of 1.0 and documents which are 15 days from that date a weight of 0.5.\n\n===== Supported decay functions\n\nThe `DECAY_FUNCTION` determines the shape of the decay:\n\n`gauss`::\n+\n--\nNormal decay, computed as:\n\nimage:images/Gaussian.png[]\n\nwhere image:images/sigma.png[] is computed to assure that the score takes the value `decay` at distance `scale` from `origin`+-`offset`\n\n// \\sigma^2 = -scale^2/(2 \\cdot ln(decay))\nimage:images/sigma_calc.png[]\n\nSee <<gauss-decay>> for graphs demonstrating the curve generated by the `gauss` function.\n\n--\n\n`exp`::\n+\n--\nExponential decay, computed as:\n\nimage:images/Exponential.png[]\n\nwhere again the parameter image:images/lambda.png[] is computed to assure that the score takes the value `decay` at distance `scale` from `origin`+-`offset`\n\n// \\lambda = ln(decay)/scale\nimage:images/lambda_calc.png[]\n\nSee <<exp-decay>> for graphs demonstrating the curve generated by the `exp` function.\n\n--\n\n`linear`::\n+\n--\nLinear decay, computed as:\n\nimage:images/Linear.png[].\n\n\nwhere again the parameter `s` is computed to assure that the score takes the value `decay` at distance `scale` from `origin`+-`offset`\n\nimage:images/s_calc.png[]\n\nIn contrast to the normal and exponential decay, this function actually\nsets the score to 0 if the field value exceeds twice the user given\nscale value.\n--\n\nFor single functions the three decay functions together with their parameters can be visualized like this (the field in this example called \"age\"):\n\nimage:images/decay_2d.png[width=600]\n\n===== Multi-values fields\n\nIf a field used for computing the decay contains multiple values, per default the value closest to the origin is chosen for determining the distance.\nThis can be changed by setting `multi_value_mode`.\n\n[horizontal]\n`min`:: Distance is the minimum distance\n`max`:: Distance is the maximum distance\n`avg`:: Distance is the average distance\n`sum`:: Distance is the sum of all distances\n\nExample:\n\n[source,js]\n--------------------------------------------------\n    \"DECAY_FUNCTION\": {\n        \"FIELD_NAME\": {\n              \"origin\": ...,\n              \"scale\": ...\n        },\n        \"multi_value_mode\": \"avg\"\n    }\n--------------------------------------------------\n// NOTCONSOLE\n\n\n==== Detailed example\n\nSuppose you are searching for a hotel in a certain town. Your budget is\nlimited. Also, you would like the hotel to be close to the town center,\nso the farther the hotel is from the desired location the less likely\nyou are to check in.\n\nYou would like the query results that match your criterion (for\nexample, \"hotel, Nancy, non-smoker\") to be scored with respect to\ndistance to the town center and also the price.\n\nIntuitively, you would like to define the town center as the origin and\nmaybe you are willing to walk 2km to the town center from the hotel. +\nIn this case your *origin* for the location field is the town center\nand the *scale* is ~2km.\n\nIf your budget is low, you would probably prefer something cheap above\nsomething expensive. For the price field, the *origin* would be 0 Euros\nand the *scale* depends on how much you are willing to pay, for example 20 Euros.\n\nIn this example, the fields might be called \"price\" for the price of the\nhotel and \"location\" for the coordinates of this hotel.\n\nThe function for `price` in this case would be\n\n[source,js]\n--------------------------------------------------\n\"gauss\": { <1>\n    \"price\": {\n          \"origin\": \"0\",\n          \"scale\": \"20\"\n    }\n}\n--------------------------------------------------\n// NOTCONSOLE\n<1> This decay function could also be `linear` or `exp`.\n\nand for `location`:\n\n[source,js]\n--------------------------------------------------\n\n\"gauss\": { <1>\n    \"location\": {\n          \"origin\": \"11, 12\",\n          \"scale\": \"2km\"\n    }\n}\n--------------------------------------------------\n// NOTCONSOLE\n<1> This decay function could also be `linear` or `exp`.\n\nSuppose you want to multiply these two functions on the original score,\nthe request would look like this:\n\n[source,console]\n--------------------------------------------------\nGET /_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"functions\": [\n        {\n          \"gauss\": {\n            \"price\": {\n              \"origin\": \"0\",\n              \"scale\": \"20\"\n            }\n          }\n        },\n        {\n          \"gauss\": {\n            \"location\": {\n              \"origin\": \"11, 12\",\n              \"scale\": \"2km\"\n            }\n          }\n        }\n      ],\n      \"query\": {\n        \"match\": {\n          \"properties\": \"balcony\"\n        }\n      },\n      \"score_mode\": \"multiply\"\n    }\n  }\n}\n--------------------------------------------------\n\nNext, we show how the computed score looks like for each of the three\npossible decay functions.\n\n[[gauss-decay]]\n===== Normal decay, keyword `gauss`\n\nWhen choosing `gauss` as the decay function in the above example, the\ncontour and surface plot of the multiplier looks like this:\n\nimage::https://f.cloud.github.com/assets/4320215/768157/cd0e18a6-e898-11e2-9b3c-f0145078bd6f.png[width=\"700px\"]\n\nimage::https://f.cloud.github.com/assets/4320215/768160/ec43c928-e898-11e2-8e0d-f3c4519dbd89.png[width=\"700px\"]\n\nSuppose your original search results matches three hotels :\n\n* \"Backback Nap\"\n* \"Drink n Drive\"\n* \"BnB Bellevue\".\n\n\"Drink n Drive\" is pretty far from your defined location (nearly 2 km)\nand is not too cheap (about 13 Euros) so it gets a low factor a factor\nof 0.56. \"BnB Bellevue\" and \"Backback Nap\" are both pretty close to the\ndefined location but \"BnB Bellevue\" is cheaper, so it gets a multiplier\nof 0.86 whereas \"Backpack Nap\" gets a value of 0.66.\n\n[[exp-decay]]\n===== Exponential decay, keyword `exp`\n\nWhen choosing `exp` as the decay function in the above example, the\ncontour and surface plot of the multiplier looks like this:\n\nimage::https://f.cloud.github.com/assets/4320215/768161/082975c0-e899-11e2-86f7-174c3a729d64.png[width=\"700px\"]\n\nimage::https://f.cloud.github.com/assets/4320215/768162/0b606884-e899-11e2-907b-aefc77eefef6.png[width=\"700px\"]\n\n[[linear-decay]]\n===== Linear decay, keyword `linear`\n\nWhen choosing `linear` as the decay function in the above example, the\ncontour and surface plot of the multiplier looks like this:\n\nimage::https://f.cloud.github.com/assets/4320215/768164/1775b0ca-e899-11e2-9f4a-776b406305c6.png[width=\"700px\"]\n\nimage::https://f.cloud.github.com/assets/4320215/768165/19d8b1aa-e899-11e2-91bc-6b0553e8d722.png[width=\"700px\"]\n\n==== Supported fields for decay functions\n\nOnly numeric, date, and geopoint fields are supported.\n\n==== What if a field is missing?\n\nIf the numeric field is missing in the document, the function will\nreturn 1.\n"
}
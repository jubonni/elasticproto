{
    "meta": {
        "timestamp": "2024-11-01T03:02:52.966588",
        "size": 14638,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-configuring-transform.html",
        "type": "documentation",
        "role": [
            "xpack",
            "screenshot"
        ],
        "has_code": true,
        "title": "ml-configuring-transform",
        "version": "8.15"
    },
    "doc": "[role=\"xpack\"]\n[[ml-configuring-transform]]\n= Altering data in your {dfeed} with runtime fields\n\nIf you use {dfeeds}, you can use runtime fields to alter your data before it \nis analyzed. You can add an optional `runtime_mappings` property to your \n{dfeeds}, where you can specify field types and scripts that evaluate custom \nexpressions without affecting the indices that you're retrieving the data from.\n\nIf your {dfeed} defines runtime fields, you can use those fields in your\n{anomaly-job}. For example, you can use the runtime fields in the analysis\nfunctions in one or more detectors. Runtime fields can impact search performance \nbased on the computation defined in the runtime script.\n\n[NOTE]\n===============================\nSome of these examples use regular expressions. By default, regular\nexpressions are disabled because they circumvent the protection that Painless\nprovides against long running and memory hungry scripts. For more information,\nsee {ref}/modules-scripting-painless.html[Painless scripting language].\n\n{ml-cap} analysis is case sensitive. For example, \"John\" is considered to be \ndifferent than \"john\". This is one reason you might consider using scripts that \nconvert your strings to upper or lowercase letters.\n===============================\n\n* <<ml-configuring-transform1>>\n* <<ml-configuring-transform2>>\n* <<ml-configuring-transform3>>\n* <<ml-configuring-transform4>>\n* <<ml-configuring-transform5>>\n* <<ml-configuring-transform6>>\n* <<ml-configuring-transform7>>\n* <<ml-configuring-transform8>>\n// * <<ml-configuring-transform9>>\n\nThe following index APIs create and add content to an index that is used in\nsubsequent examples:\n\n[source,console]\n----------------------------------\nPUT /my-index-000001\n{\n  \"mappings\":{\n    \"properties\": {\n      \"@timestamp\": { \"type\": \"date\" },\n      \"aborted_count\": { \"type\": \"long\" },\n      \"another_field\": { \"type\": \"keyword\" }, <1>\n      \"clientip\": { \"type\": \"keyword\" },\n      \"coords\": {\n        \"properties\": {\n          \"lat\": { \"type\": \"keyword\" },\n          \"lon\": { \"type\": \"keyword\" }\n        }\n      },\n      \"error_count\": { \"type\": \"long\" },\n      \"query\": { \"type\": \"keyword\" },\n      \"some_field\": { \"type\": \"keyword\" },\n      \"tokenstring1\":{ \"type\":\"keyword\" },\n      \"tokenstring2\":{ \"type\":\"keyword\" },\n      \"tokenstring3\":{ \"type\":\"keyword\" }\n    }\n  }\n}\n\nPUT /my-index-000001/_doc/1\n{\n  \"@timestamp\":\"2017-03-23T13:00:00\",\n  \"error_count\":36320,\n  \"aborted_count\":4156,\n  \"some_field\":\"JOE\",\n  \"another_field\":\"SMITH  \",\n  \"tokenstring1\":\"foo-bar-baz\",\n  \"tokenstring2\":\"foo bar baz\",\n  \"tokenstring3\":\"foo-bar-19\",\n  \"query\":\"www.ml.elastic.co\",\n  \"clientip\":\"123.456.78.900\",\n  \"coords\": {\n    \"lat\" : 41.44,\n    \"lon\":90.5\n  }\n}\n----------------------------------\n// TEST[skip:SETUP]\n\n<1> In this example, string fields are mapped as `keyword` fields to support\naggregation. If you want both a full text (`text`) and a keyword (`keyword`)\nversion of the same field, use multi-fields. For more information, see\n{ref}/multi-fields.html[fields].\n\n\n[[ml-configuring-transform1]]\n.Example 1: Adding two numerical fields\n\n[source,console]\n----------------------------------\nPUT _ml/anomaly_detectors/test1\n{\n  \"analysis_config\":{\n    \"bucket_span\": \"10m\",\n    \"detectors\":[\n      {\n        \"function\":\"mean\",\n        \"field_name\": \"total_error_count\" <1>\n      }\n    ]\n  },\n  \"data_description\": {\n    \"time_field\":\"@timestamp\"\n  },\n  \"datafeed_config\":{\n    \"datafeed_id\": \"datafeed-test1\",\n    \"indices\": [\"my-index-000001\"],\n    \"runtime_mappings\": {\n      \"total_error_count\": { <2>\n        \"type\": \"long\",\n        \"script\": {\n          \"source\": \"emit(doc['error_count'].value + doc['aborted_count'].value)\"\n        }\n      }\n    }\n  }\n}\n----------------------------------\n// TEST[skip:needs-licence]\n\n<1> A runtime field named `total_error_count` is referenced in the detector\nwithin the job.\n<2> The runtime field is defined in the {dfeed}.\n\nThis `test1` {anomaly-job} contains a detector that uses a runtime field in a\nmean analysis function. The `datafeed-test1` {dfeed} defines the runtime field.\nIt contains a script that adds two fields in the document to produce a \"total\"\nerror count.\n\nThe syntax for the `runtime_mappings` property is identical to that used by \n{es}. For more information, see {ref}/runtime.html[Runtime fields].\n\nYou can preview the contents of the {dfeed} by using the following API:\n\n[source,console]\n----------------------------------\nGET _ml/datafeeds/datafeed-test1/_preview\n----------------------------------\n// TEST[skip:continued]\n\nIn this example, the API returns the following results, which contain a sum of\nthe `error_count` and `aborted_count` values:\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"total_error_count\": 40476\n  }\n]\n----------------------------------\n\nNOTE: This example demonstrates how to use runtime fields, but it contains\ninsufficient data to generate meaningful results.\n\n//For a full demonstration of\n//how to create jobs with sample data, see <<ml-getting-started>>.\n\nYou can alternatively use {kib} to create an advanced {anomaly-job} that uses\nruntime fields. To add the `runtime_mappings` property to your {dfeed}, you must \nuse the **Edit JSON** tab. For example:\n\n[role=\"screenshot\"]\nimage::images/ml-runtimefields.jpg[Using runtime_mappings in {dfeed} config via {kib}]\n\n\n[[ml-configuring-transform2]]\n.Example 2: Concatenating strings\n\n[source,console]\n--------------------------------------------------\nPUT _ml/anomaly_detectors/test2\n{\n  \"analysis_config\":{\n    \"bucket_span\": \"10m\",\n    \"detectors\":[\n      {\n        \"function\":\"low_info_content\",\n        \"field_name\":\"my_runtime_field\" <1>\n      }\n    ]\n  },\n  \"data_description\": {\n    \"time_field\":\"@timestamp\"\n  },\n  \"datafeed_config\":{\n    \"datafeed_id\": \"datafeed-test2\",\n    \"indices\": [\"my-index-000001\"],\n    \"runtime_mappings\": {\n      \"my_runtime_field\": {\n        \"type\": \"keyword\",\n        \"script\": {\n          \"source\": \"emit(doc['some_field'].value + '_' + doc['another_field'].value)\" <2>\n        }\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test2/_preview\n--------------------------------------------------\n// TEST[skip:needs-licence]\n\n<1> The runtime field has a generic name in this case, since it is used for \nvarious tests in the examples.\n<2> The runtime field uses the plus (+) operator to concatenate strings.\n\nThe preview {dfeed} API returns the following results, which show that \"JOE\"\nand \"SMITH  \" have been concatenated and an underscore was added:\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"my_runtime_field\": \"JOE_SMITH  \"\n  }\n]\n----------------------------------\n\n[[ml-configuring-transform3]]\n.Example 3: Trimming strings\n\n[source,console]\n--------------------------------------------------\nPOST _ml/datafeeds/datafeed-test2/_update\n{\n  \"runtime_mappings\": {\n    \"my_runtime_field\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\": \"emit(doc['another_field'].value.trim())\" <1>\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test2/_preview\n--------------------------------------------------\n// TEST[skip:continued]\n\n<1> This runtime field uses the `trim()` function to trim extra white space from \na string.\n\nThe preview {dfeed} API returns the following results, which show that \"SMITH  \"\nhas been trimmed to \"SMITH\":\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"my_script_field\": \"SMITH\"\n  }\n]\n----------------------------------\n\n[[ml-configuring-transform4]]\n.Example 4: Converting strings to lowercase\n\n[source,console]\n--------------------------------------------------\nPOST _ml/datafeeds/datafeed-test2/_update\n{\n  \"runtime_mappings\": {\n    \"my_runtime_field\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\": \"emit(doc['some_field'].value.toLowerCase())\" <1>\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test2/_preview\n--------------------------------------------------\n// TEST[skip:continued]\n\n<1> This runtime field uses the `toLowerCase` function to convert a string to \nall lowercase letters. Likewise, you can use the `toUpperCase` function to \nconvert a string to uppercase letters.\n\nThe preview {dfeed} API returns the following results, which show that \"JOE\"\nhas been converted to \"joe\":\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"my_script_field\": \"joe\"\n  }\n]\n----------------------------------\n\n[[ml-configuring-transform5]]\n.Example 5: Converting strings to mixed case formats\n\n[source,console]\n--------------------------------------------------\nPOST _ml/datafeeds/datafeed-test2/_update\n{\n  \"runtime_mappings\": {\n    \"my_runtime_field\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\": \"emit(doc['some_field'].value.substring(0, 1).toUpperCase() + doc['some_field'].value.substring(1).toLowerCase())\" <1>\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test2/_preview\n--------------------------------------------------\n// TEST[skip:continued]\n\n<1> This runtime field is a more complicated example of case manipulation. It \nuses the `subString()` function to capitalize the first letter of a string and\nconverts the remaining characters to lowercase.\n\nThe preview {dfeed} API returns the following results, which show that \"JOE\" has \nbeen converted to \"Joe\":\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"my_script_field\": \"Joe\"\n  }\n]\n----------------------------------\n\n[[ml-configuring-transform6]]\n.Example 6: Replacing tokens\n\n[source,console]\n--------------------------------------------------\nPOST _ml/datafeeds/datafeed-test2/_update\n{\n  \"runtime_mappings\": {\n    \"my_runtime_field\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\": \"emit(/\\\\s/.matcher(doc['tokenstring2'].value).replaceAll('_'))\" <1>\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test2/_preview\n--------------------------------------------------\n// TEST[skip:continued]\n\n<1> This script uses regular expressions to replace white space with \nunderscores.\n\nThe preview {dfeed} API returns the following results, which show that \"foo bar \nbaz\" has been converted to \"foo_bar_baz\":\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"my_script_field\": \"foo_bar_baz\"\n  }\n]\n----------------------------------\n\n[[ml-configuring-transform7]]\n.Example 7: Regular expression matching and concatenation\n\n[source,console]\n--------------------------------------------------\nPOST _ml/datafeeds/datafeed-test2/_update\n{\n  \"runtime_mappings\": {\n    \"my_runtime_field\": {\n      \"type\": \"keyword\",\n      \"script\": {\n        \"source\": \"def m = /(.*)-bar-([0-9][0-9])/.matcher(doc['tokenstring3'].value); emit(m.find() ? m.group(1) + '_' + m.group(2) : '');\" <1>\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test2/_preview\n--------------------------------------------------\n// TEST[skip:continued]\n\n<1> This script looks for a specific regular expression pattern and emits the\nmatched groups as a concatenated string. If no match is found, it emits an empty\nstring.\n\nThe preview {dfeed} API returns the following results, which show that\n\"foo-bar-19\" has been converted to \"foo_19\":\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"my_script_field\": \"foo_19\"\n  }\n]\n----------------------------------\n\n\n[[ml-configuring-transform8]]\n.Example 8: Transforming geopoint data\n\n[source,console]\n--------------------------------------------------\nPUT _ml/anomaly_detectors/test3\n{\n  \"analysis_config\":{\n    \"bucket_span\": \"10m\",\n    \"detectors\":[\n      {\n        \"function\":\"lat_long\",\n        \"field_name\": \"my_coordinates\"\n      }\n    ]\n  },\n  \"data_description\": {\n    \"time_field\":\"@timestamp\"\n  },\n  \"datafeed_config\":{\n    \"datafeed_id\": \"datafeed-test3\",\n    \"indices\": [\"my-index-000001\"],\n    \"runtime_mappings\": {\n      \"my_coordinates\": {\n        \"type\": \"keyword\",\n        \"script\": {\n          \"source\": \"emit(doc['coords.lat'].value + ',' + doc['coords.lon'].value)\"\n        }\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test3/_preview\n--------------------------------------------------\n// TEST[skip:needs-licence]\n\nIn {es}, location data can be stored in `geo_point` fields but this data type is\nnot supported natively in {ml} analytics. This example of a runtime field\ntransforms the data into an appropriate format. For more information,\nsee <<ml-geo-functions>>.\n\nThe preview {dfeed} API returns the following results, which show that\n`41.44` and `90.5` have been combined into \"41.44,90.5\":\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"my_coordinates\": \"41.44,90.5\"\n  }\n]\n----------------------------------\n\n////\n\n[[ml-configuring-transform9]]\n.Example 9: Splitting strings by domain name\n\n[source,console]\n--------------------------------------------------\nPUT _ml/anomaly_detectors/test4\n{\n  \"description\":\"DNS tunneling\",\n  \"analysis_config\":{\n    \"bucket_span\": \"30m\",\n    \"influencers\": [\"clientip\",\"hrd\"],\n    \"detectors\":[\n      {\n        \"function\":\"high_info_content\",\n        \"field_name\": \"sub\",\n        \"over_field_name\": \"hrd\",\n        \"exclude_frequent\":\"all\"\n      }\n    ]\n  },\n  \"data_description\": {\n    \"time_field\":\"@timestamp\"\n  },\n  \"datafeed_config\":{\n    \"datafeed_id\": \"datafeed-test4\",\n    \"indices\": [\"my-index-000001\"],\n    \"script_fields\":{\n      \"sub\":{\n        \"script\":\"return domainSplit(doc['query'].value).get(0);\"\n      },\n      \"hrd\":{\n        \"script\":\"return domainSplit(doc['query'].value).get(1);\"\n      }\n    }\n  }\n}\n\nGET _ml/datafeeds/datafeed-test4/_preview\n--------------------------------------------------\n// TEST[skip:needs-licence]\n\nIf you have a single field that contains a well-formed DNS domain name, you can\nuse the `domainSplit()` function to split the string into its highest registered\ndomain and the sub-domain, which is everything to the left of the highest\nregistered domain. For example, the highest registered domain of\n`www.ml.elastic.co` is `elastic.co` and the sub-domain is `www.ml`. The\n`domainSplit()` function returns an array of two values: the first value is the\nsubdomain; the second value is the highest registered domain.\n\nThe preview {dfeed} API returns the following results, which show that\n\"www.ml.elastic.co\" has been split into \"elastic.co\" and \"www.ml\":\n\n[source,js]\n----------------------------------\n[\n  {\n    \"@timestamp\": 1490274000000,\n    \"clientip.keyword\": \"123.456.78.900\",\n    \"hrd\": \"elastic.co\",\n    \"sub\": \"www.ml\"\n  }\n]\n----------------------------------\n\n////"
}
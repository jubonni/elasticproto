{
    "meta": {
        "timestamp": "2024-11-01T02:49:26.384066",
        "size": 5748,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-service-azure-openai.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "infer-service-azure-openai",
        "version": "8.15"
    },
    "doc": "[[infer-service-azure-openai]]\n=== Azure OpenAI {infer} service\n\nCreates an {infer} endpoint to perform an {infer} task with the `azureopenai` service.\n\n\n[discrete]\n[[infer-service-azure-openai-api-request]]\n==== {api-request-title}\n\n`PUT /_inference/<task_type>/<inference_id>`\n\n[discrete]\n[[infer-service-azure-openai-api-path-params]]\n==== {api-path-parms-title}\n\n`<inference_id>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=inference-id]\n\n`<task_type>`::\n(Required, string)\ninclude::inference-shared.asciidoc[tag=task-type]\n+\n--\nAvailable task types:\n\n* `completion`,\n* `text_embedding`.\n--\n\n[discrete]\n[[infer-service-azure-openai-api-request-body]]\n==== {api-request-body-title}\n\n`chunking_settings`::\n(Optional, object)\ninclude::inference-shared.asciidoc[tag=chunking-settings]\n\n`max_chunking_size`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-max-chunking-size]\n\n`overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-overlap]\n\n`sentence_overlap`:::\n(Optional, integer)\ninclude::inference-shared.asciidoc[tag=chunking-settings-sentence-overlap]\n\n`strategy`:::\n(Optional, string)\ninclude::inference-shared.asciidoc[tag=chunking-settings-strategy]\n\n`service`::\n(Required, string)\nThe type of service supported for the specified task type. In this case, \n`azureopenai`.\n\n`service_settings`::\n(Required, object)\ninclude::inference-shared.asciidoc[tag=service-settings]\n+\n--\nThese settings are specific to the `azureopenai` service.\n--\n\n`api_key` or `entra_id`:::\n(Required, string)\nYou must provide _either_ an API key or an Entra ID.\nIf you do not provide either, or provide both, you will receive an error when trying to create your model.\nSee the https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#authentication[Azure OpenAI Authentication documentation] for more details on these authentication types.\n+\n--\ninclude::inference-shared.asciidoc[tag=api-key-admonition]\n--\n\n`resource_name`:::\n(Required, string)\nThe name of your Azure OpenAI resource.\nYou can find this from the https://portal.azure.com/#view/HubsExtension/BrowseAll[list of resources] in the Azure Portal for your subscription.\n\n`deployment_id`:::\n(Required, string)\nThe deployment name of your deployed models.\nYour Azure OpenAI deployments can be found though the https://oai.azure.com/[Azure OpenAI Studio] portal that is linked to your subscription.\n\n`api_version`:::\n(Required, string)\nThe Azure API version ID to use.\nWe recommend using the https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#embeddings[latest supported non-preview version].\n\n`rate_limit`:::\n(Optional, object)\nThe `azureopenai` service sets a default number of requests allowed per minute depending on the task type.\nFor `text_embedding` it is set to `1440`.\nFor `completion` it is set to `120`.\nThis helps to minimize the number of rate limit errors returned from Azure.\nTo modify this, set the `requests_per_minute` setting of this object in your service settings:\n+\n--\ninclude::inference-shared.asciidoc[tag=request-per-minute-example]\n\nMore information about the rate limits for Azure can be found in the https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits[Quota limits docs] and https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota?tabs=rest[How to change the quotas].\n--\n\n`task_settings`::\n(Optional, object)\ninclude::inference-shared.asciidoc[tag=task-settings]\n+\n.`task_settings` for the `completion` task type\n[%collapsible%closed]\n=====\n`user`:::\n(optional, string)\nSpecifies the user issuing the request, which can be used for abuse detection.\n=====\n+\n.`task_settings` for the `text_embedding` task type\n[%collapsible%closed]\n=====\n`user`:::\n(optional, string)\nSpecifies the user issuing the request, which can be used for abuse detection.\n=====\n\n\n\n[discrete]\n[[inference-example-azure-openai]]\n==== Azure OpenAI service example\n\nThe following example shows how to create an {infer} endpoint called\n`azure_openai_embeddings` to perform a `text_embedding` task type.\nNote that we do not specify a model here, as it is defined already via our Azure OpenAI deployment.\n\nThe list of embeddings models that you can choose from in your deployment can be found in the https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#embeddings[Azure models documentation].\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/text_embedding/azure_openai_embeddings\n{\n    \"service\": \"azureopenai\",\n    \"service_settings\": {\n        \"api_key\": \"<api_key>\",\n        \"resource_name\": \"<resource_name>\",\n        \"deployment_id\": \"<deployment_id>\",\n        \"api_version\": \"2024-02-01\"\n    }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n\nThe next example shows how to create an {infer} endpoint called\n`azure_openai_completion` to perform a `completion` task type.\n\n[source,console]\n------------------------------------------------------------\nPUT _inference/completion/azure_openai_completion\n{\n    \"service\": \"azureopenai\",\n    \"service_settings\": {\n        \"api_key\": \"<api_key>\",\n        \"resource_name\": \"<resource_name>\",\n        \"deployment_id\": \"<deployment_id>\",\n        \"api_version\": \"2024-02-01\"\n    }\n}\n------------------------------------------------------------\n// TEST[skip:TBD]\n\nThe list of chat completion models that you can choose from in your Azure OpenAI deployment can be found at the following places:\n\n* https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models[GPT-4 and GPT-4 Turbo models]\n* https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35[GPT-3.5]"
}
{
    "meta": {
        "timestamp": "2024-11-01T03:02:53.632584",
        "size": 5602,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-stop-analyzer.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-stop-analyzer",
        "version": "8.15"
    },
    "doc": "[[analysis-stop-analyzer]]\n=== Stop analyzer\n++++\n<titleabbrev>Stop</titleabbrev>\n++++\n\nThe `stop` analyzer is the same as the <<analysis-simple-analyzer,`simple` analyzer>>\nbut adds support for removing stop words. It defaults to using the\n`_english_` stop words.\n\n[discrete]\n=== Example output\n\n[source,console]\n---------------------------\nPOST _analyze\n{\n  \"analyzer\": \"stop\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n---------------------------\n\n/////////////////////\n\n[source,console-result]\n----------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 6,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 12,\n      \"end_offset\": 17,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"foxes\",\n      \"start_offset\": 18,\n      \"end_offset\": 23,\n      \"type\": \"word\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"jumped\",\n      \"start_offset\": 24,\n      \"end_offset\": 30,\n      \"type\": \"word\",\n      \"position\": 4\n    },\n    {\n      \"token\": \"over\",\n      \"start_offset\": 31,\n      \"end_offset\": 35,\n      \"type\": \"word\",\n      \"position\": 5\n    },\n    {\n      \"token\": \"lazy\",\n      \"start_offset\": 40,\n      \"end_offset\": 44,\n      \"type\": \"word\",\n      \"position\": 7\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 45,\n      \"end_offset\": 48,\n      \"type\": \"word\",\n      \"position\": 8\n    },\n    {\n      \"token\": \"s\",\n      \"start_offset\": 49,\n      \"end_offset\": 50,\n      \"type\": \"word\",\n      \"position\": 9\n    },\n    {\n      \"token\": \"bone\",\n      \"start_offset\": 51,\n      \"end_offset\": 55,\n      \"type\": \"word\",\n      \"position\": 10\n    }\n  ]\n}\n----------------------------\n\n/////////////////////\n\n\nThe above sentence would produce the following terms:\n\n[source,text]\n---------------------------\n[ quick, brown, foxes, jumped, over, lazy, dog, s, bone ]\n---------------------------\n\n[discrete]\n=== Configuration\n\nThe `stop` analyzer accepts the following parameters:\n\n[horizontal]\n`stopwords`::\n\n    A pre-defined stop words list like `_english_` or an array containing a\n    list of stop words. Defaults to `_english_`.\n\n`stopwords_path`::\n\n    The path to a file containing stop words. This path is relative to the\n    Elasticsearch `config` directory.\n\n\nSee the <<analysis-stop-tokenfilter,Stop Token Filter>> for more information\nabout stop word configuration.\n\n[discrete]\n=== Example configuration\n\nIn this example, we configure the `stop` analyzer to use a specified list of\nwords as stop words:\n\n[source,console]\n----------------------------\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_stop_analyzer\": {\n          \"type\": \"stop\",\n          \"stopwords\": [\"the\", \"over\"]\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_stop_analyzer\",\n  \"text\": \"The 2 QUICK Brown-Foxes jumped over the lazy dog's bone.\"\n}\n----------------------------\n\n/////////////////////\n\n[source,console-result]\n----------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"quick\",\n      \"start_offset\": 6,\n      \"end_offset\": 11,\n      \"type\": \"word\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"brown\",\n      \"start_offset\": 12,\n      \"end_offset\": 17,\n      \"type\": \"word\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"foxes\",\n      \"start_offset\": 18,\n      \"end_offset\": 23,\n      \"type\": \"word\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"jumped\",\n      \"start_offset\": 24,\n      \"end_offset\": 30,\n      \"type\": \"word\",\n      \"position\": 4\n    },\n    {\n      \"token\": \"lazy\",\n      \"start_offset\": 40,\n      \"end_offset\": 44,\n      \"type\": \"word\",\n      \"position\": 7\n    },\n    {\n      \"token\": \"dog\",\n      \"start_offset\": 45,\n      \"end_offset\": 48,\n      \"type\": \"word\",\n      \"position\": 8\n    },\n    {\n      \"token\": \"s\",\n      \"start_offset\": 49,\n      \"end_offset\": 50,\n      \"type\": \"word\",\n      \"position\": 9\n    },\n    {\n      \"token\": \"bone\",\n      \"start_offset\": 51,\n      \"end_offset\": 55,\n      \"type\": \"word\",\n      \"position\": 10\n    }\n  ]\n}\n----------------------------\n\n/////////////////////\n\n\nThe above example produces the following terms:\n\n[source,text]\n---------------------------\n[ quick, brown, foxes, jumped, lazy, dog, s, bone ]\n---------------------------\n\n[discrete]\n=== Definition\n\nIt consists of:\n\nTokenizer::\n* <<analysis-lowercase-tokenizer,Lower Case Tokenizer>>\n\nToken filters::\n* <<analysis-stop-tokenfilter,Stop Token Filter>>\n\nIf you need to customize the `stop` analyzer beyond the configuration\nparameters then you need to recreate it as a `custom` analyzer and modify\nit, usually by adding token filters. This would recreate the built-in\n`stop` analyzer and you can use it as a starting point for further\ncustomization:\n\n[source,console]\n----------------------------------------------------\nPUT /stop_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"english_stop\": {\n          \"type\":       \"stop\",\n          \"stopwords\":  \"_english_\" <1>\n        }\n      },\n      \"analyzer\": {\n        \"rebuilt_stop\": {\n          \"tokenizer\": \"lowercase\",\n          \"filter\": [\n            \"english_stop\"          <2>\n          ]\n        }\n      }\n    }\n  }\n}\n----------------------------------------------------\n// TEST[s/\\n$/\\nstartyaml\\n  - compare_analyzers: {index: stop_example, first: stop, second: rebuilt_stop}\\nendyaml\\n/]\n\n<1> The default stopwords can be overridden with the `stopwords`\n    or `stopwords_path` parameters.\n<2> You'd add any token filters after `english_stop`.\n"
}
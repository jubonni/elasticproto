{
    "meta": {
        "timestamp": "2024-11-01T03:02:52.433585",
        "size": 26670,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "docker",
        "version": "8.15"
    },
    "doc": "[[docker]]\n=== Install {es} with Docker\n\nDocker images for {es} are available from the Elastic Docker registry. A list of\nall published Docker images and tags is available at\nhttps://www.docker.elastic.co[www.docker.elastic.co]. The source code is in\nhttps://github.com/elastic/elasticsearch/blob/{branch}/distribution/docker[GitHub].\n\ninclude::license.asciidoc[]\n\n[TIP]\n====\nIf you just want to test {es} in local development, refer to <<run-elasticsearch-locally>>.\nPlease note that this setup is not suitable for production environments.\n====\n\n[[docker-cli-run-dev-mode]]\n==== Run {es} in Docker\n\nUse Docker commands to start a single-node {es} cluster for development or\ntesting. You can then run additional Docker commands to add nodes to the test\ncluster or run {kib}.\n\nTIP: This setup doesn't run multiple {es} nodes or {kib} by default. To create a\nmulti-node cluster with {kib}, use Docker Compose instead. See\n<<docker-compose-file>>.\n\n===== Start a single-node cluster\n\n. Install Docker. Visit https://docs.docker.com/get-docker/[Get Docker] to\ninstall Docker for your environment.\n+\nIf using Docker Desktop, make sure to allocate at least 4GB of memory. You can\nadjust memory usage in Docker Desktop by going to **Settings > Resources**.\n\n. Create a new docker network.\n+\n[source,sh]\n----\ndocker network create elastic\n----\n\n. Pull the {es} Docker image.\n+\n--\nifeval::[\"{release-state}\"==\"unreleased\"]\nWARNING: Version {version} has not yet been released.\nNo Docker image is currently available for {es} {version}.\nendif::[]\n\n[source,sh,subs=\"attributes\"]\n----\ndocker pull {docker-image}\n----\n--\n\n. Optional: Install\nhttps://docs.sigstore.dev/system_config/installation/[Cosign] for your\nenvironment. Then use Cosign to verify the {es} image's signature.\n+\n[[docker-verify-signature]]\n[source,sh,subs=\"attributes\"]\n----\nwget https://artifacts.elastic.co/cosign.pub\ncosign verify --key cosign.pub {docker-image}\n----\n+\nThe `cosign` command prints the check results and the signature payload in JSON format:\n+\n[source,sh,subs=\"attributes\"]\n----\nVerification for {docker-image} --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - The signatures were verified against the specified public key\n----\n\n. Start an {es} container.\n+\n[source,sh,subs=\"attributes\"]\n----\ndocker run --name es01 --net elastic -p 9200:9200 -it -m 1GB {docker-image}\n----\n+\nTIP: Use the `-m` flag to set a memory limit for the container. This removes the\nneed to <<docker-set-heap-size,manually set the JVM size>>.\n+\nThe command prints the `elastic` user password and an enrollment token for {kib}.\n\n. Copy the generated `elastic` password and enrollment token. These credentials\nare only shown when you start {es} for the first time. You can regenerate the\ncredentials using the following commands.\n+\n[source,sh,subs=\"attributes\"]\n----\ndocker exec -it es01 /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\ndocker exec -it es01 /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\n----\n+\nWe recommend storing the `elastic` password as an environment variable in your shell. Example:\n+\n[source,sh]\n----\nexport ELASTIC_PASSWORD=\"your_password\"\n----\n\n. Copy the `http_ca.crt` SSL certificate from the container to your local machine.\n+\n[source,sh]\n----\ndocker cp es01:/usr/share/elasticsearch/config/certs/http_ca.crt .\n----\n\n. Make a REST API call to {es} to ensure the {es} container is running.\n+\n[source,sh]\n----\ncurl --cacert http_ca.crt -u elastic:$ELASTIC_PASSWORD https://localhost:9200\n----\n// NOTCONSOLE\n\n===== Add more nodes\n\n. Use an existing node to generate a enrollment token for the new node.\n+\n[source,sh]\n----\ndocker exec -it es01 /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node\n----\n+\nThe enrollment token is valid for 30 minutes.\n\n. Start a new {es} container. Include the enrollment token as an environment variable.\n+\n[source,sh,subs=\"attributes\"]\n----\ndocker run -e ENROLLMENT_TOKEN=\"<token>\" --name es02 --net elastic -it -m 1GB {docker-image}\n----\n\n. Call the <<cat-nodes,cat nodes API>> to verify the node was added to the cluster.\n+\n[source,sh]\n----\ncurl --cacert http_ca.crt -u elastic:$ELASTIC_PASSWORD https://localhost:9200/_cat/nodes\n----\n// NOTCONSOLE\n\n[[run-kibana-docker]]\n===== Run {kib}\n\n. Pull the {kib} Docker image.\n+\n--\nifeval::[\"{release-state}\"==\"unreleased\"]\nWARNING: Version {version} has not yet been released.\nNo Docker image is currently available for {kib} {version}.\nendif::[]\n\n[source,sh,subs=\"attributes\"]\n----\ndocker pull {kib-docker-image}\n----\n--\n\n. Optional: Verify the {kib} image's signature.\n+\n[source,sh,subs=\"attributes\"]\n----\nwget https://artifacts.elastic.co/cosign.pub\ncosign verify --key cosign.pub {kib-docker-image}\n----\n\n. Start a {kib} container.\n+\n[source,sh,subs=\"attributes\"]\n----\ndocker run --name kib01 --net elastic -p 5601:5601 {kib-docker-image}\n----\n\n. When {kib} starts, it outputs a unique generated link to the terminal. To\naccess {kib}, open this link in a web browser.\n\n. In your browser, enter the enrollment token that was generated when you started {es}.\n+\nTo regenerate the token, run:\n+\n[source,sh]\n----\ndocker exec -it es01 /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\n----\n\n. Log in to {kib} as the `elastic` user with the password that was generated\nwhen you started {es}.\n+\nTo regenerate the password, run:\n+\n[source,sh]\n----\ndocker exec -it es01 /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\n----\n\n[[remove-containers-docker]]\n===== Remove containers\n\nTo remove the containers and their network, run:\n\n[source,sh,subs=\"attributes\"]\n----\n# Remove the Elastic network\ndocker network rm elastic\n\n# Remove {es} containers\ndocker rm es01\ndocker rm es02\n\n# Remove the {kib} container\ndocker rm kib01\n----\n\n===== Next steps\n\nYou now have a test {es} environment set up. Before you start\nserious development or go into production with {es}, review the\n<<docker-prod-prerequisites,requirements and recommendations>> to apply when running {es} in Docker in production.\n\n\n[[docker-compose-file]]\n==== Start a multi-node cluster with Docker Compose\n\nUse Docker Compose to start a three-node {es} cluster with {kib}. Docker Compose\nlets you start multiple containers with a single command.\n\n===== Configure and start the cluster\n\n. Install Docker Compose. Visit the\nhttps://docs.docker.com/compose/install/[Docker Compose docs] to install Docker\nCompose for your environment.\n+\nIf you're using Docker Desktop, Docker Compose is installed automatically. Make\nsure to allocate at least 4GB of memory to Docker Desktop. You can adjust memory\nusage in Docker Desktop by going to **Settings > Resources**.\n\n. Create or navigate to an empty directory for the project.\n\n. Download and save the following files in the project directory:\n+\n- https://github.com/elastic/elasticsearch/blob/{branch}/docs/reference/setup/install/docker/.env[`.env`]\n- https://github.com/elastic/elasticsearch/blob/{branch}/docs/reference/setup/install/docker/docker-compose.yml[`docker-compose.yml`]\n\n\n. In the `.env` file, specify a password for the `ELASTIC_PASSWORD` and\n`KIBANA_PASSWORD` variables.\n+\nThe passwords must be alphanumeric and can't contain special characters, such as\n`!` or `@`. The bash script included in the `docker-compose.yml` file only\nworks with alphanumeric characters. Example:\n+\n[source,txt]\n----\n# Password for the 'elastic' user (at least 6 characters)\nELASTIC_PASSWORD=changeme\n\n# Password for the 'kibana_system' user (at least 6 characters)\nKIBANA_PASSWORD=changeme\n...\n----\n\n. In the `.env` file, set `STACK_VERSION` to the current {stack} version.\n+\n[source,txt,subs=\"attributes\"]\n----\n...\n# Version of Elastic products\nSTACK_VERSION={version}\n...\n----\n\n. By default, the Docker Compose configuration exposes port `9200` on all network interfaces.\n+\nTo avoid exposing port `9200` to external hosts, set `ES_PORT` to `127.0.0.1:9200`\nin the `.env` file. This ensures {es} is only accessible from the host\nmachine.\n+\n[source,txt]\n----\n...\n# Port to expose Elasticsearch HTTP API to the host\n#ES_PORT=9200\nES_PORT=127.0.0.1:9200\n...\n----\n\n. To start the cluster, run the following command from the project directory.\n+\n[source,sh]\n----\ndocker-compose up -d\n----\n\n. After the cluster has started, open http://localhost:5601 in a web browser to\naccess {kib}.\n\n. Log in to {kib} as the `elastic` user using the `ELASTIC_PASSWORD` you set\nearlier.\n\n===== Stop and remove the cluster\nTo stop the cluster, run `docker-compose down`. The data in the Docker volumes\nis preserved and loaded when you restart the cluster with `docker-compose up`.\n\n[source,sh]\n----\ndocker-compose down\n----\n\nTo delete the network, containers, and volumes when you stop the cluster,\nspecify the `-v` option:\n\n[source,sh]\n----\ndocker-compose down -v\n----\n\n===== Next steps\n\nYou now have a test {es} environment set up. Before you start\nserious development or go into production with {es}, review the\n<<docker-prod-prerequisites,requirements and recommendations>> to apply when running {es} in Docker in production.\n\n[[docker-prod-prerequisites]]\n==== Using the Docker images in production\n\nThe following requirements and recommendations apply when running {es} in Docker in production.\n\n===== Set `vm.max_map_count` to at least `262144`\n\nThe `vm.max_map_count` kernel setting must be set to at least `262144` for production use.\n\nHow you set `vm.max_map_count` depends on your platform.\n\n====== Linux\n\nTo view the current value for the `vm.max_map_count` setting, run:\n\n[source,sh]\n--------------------------------------------\ngrep vm.max_map_count /etc/sysctl.conf\nvm.max_map_count=262144\n--------------------------------------------\n\nTo apply the setting on a live system, run:\n\n[source,sh]\n--------------------------------------------\nsysctl -w vm.max_map_count=262144\n--------------------------------------------\n\nTo permanently change the value for the `vm.max_map_count` setting, update the\nvalue in `/etc/sysctl.conf`.\n\n====== macOS with https://docs.docker.com/docker-for-mac[Docker for Mac]\n\nThe `vm.max_map_count` setting must be set within the xhyve virtual machine:\n\n. From the command line, run:\n+\n[source,sh]\n--------------------------------------------\nscreen ~/Library/Containers/com.docker.docker/Data/vms/0/tty\n--------------------------------------------\n\n. Press enter and use `sysctl` to configure `vm.max_map_count`:\n+\n[source,sh]\n--------------------------------------------\nsysctl -w vm.max_map_count=262144\n--------------------------------------------\n\n. To exit the `screen` session, type `Ctrl a d`.\n\n====== Windows and macOS with https://www.docker.com/products/docker-desktop[Docker Desktop]\n\nThe `vm.max_map_count` setting must be set via docker-machine:\n\n[source,sh]\n--------------------------------------------\ndocker-machine ssh\nsudo sysctl -w vm.max_map_count=262144\n--------------------------------------------\n\n====== Windows with https://docs.docker.com/docker-for-windows/wsl[Docker Desktop WSL 2 backend]\n\nThe `vm.max_map_count` setting must be set in the \"docker-desktop\" WSL instance before the\n{es} container will properly start. There are several ways to do this, depending\non your version of Windows and your version of WSL.\n\nIf you are on Windows 10 before version 22H2, or if you are on Windows 10 version 22H2 using the\nbuilt-in version of WSL, you must either manually set it every time you restart Docker before starting\nyour {es} container, or (if you do not wish to do so on every restart) you must globally set\nevery WSL2 instance to have the `vm.max_map_count` changed. This is because these versions of WSL\ndo not properly process the /etc/sysctl.conf file.\n\nTo manually set it every time you reboot, you must run the following commands in a command prompt\nor PowerShell window every time you restart Docker:\n\n[source,sh]\n--------------------------------------------\nwsl -d docker-desktop -u root\nsysctl -w vm.max_map_count=262144\n--------------------------------------------\n\nIf you are on these versions of WSL and you do not want to have to run those commands every\ntime you restart Docker, you can globally change every WSL distribution with this setting\nby modifying your %USERPROFILE%\\.wslconfig as follows:\n\n[source,text]\n--------------------------------------------\n[wsl2]\nkernelCommandLine = \"sysctl.vm.max_map_count=262144\"\n--------------------------------------------\n\nThis will cause all WSL2 VMs to have that setting assigned when they start.\n\nIf you are on Windows 11, or Windows 10 version 22H2 and have installed the Microsoft Store\nversion of WSL, you can modify the /etc/sysctl.conf within the \"docker-desktop\" WSL\ndistribution, perhaps with commands like this:\n\n[source,sh]\n--------------------------------------------\nwsl -d docker-desktop -u root\nvi /etc/sysctl.conf\n--------------------------------------------\n\nand appending a line which reads:\n[source,text]\n--------------------------------------------\nvm.max_map_count = 262144\n--------------------------------------------\n\n===== Configuration files must be readable by the `elasticsearch` user\n\nBy default, {es} runs inside the container as user `elasticsearch` using\nuid:gid `1000:0`.\n\nIMPORTANT: One exception is https://docs.openshift.com/container-platform/3.6/creating_images/guidelines.html#openshift-specific-guidelines[Openshift],\nwhich runs containers using an arbitrarily assigned user ID.\nOpenshift presents persistent volumes with the gid set to `0`, which works without any adjustments.\n\nIf you are bind-mounting a local directory or file, it must be readable by the `elasticsearch` user.\nIn addition, this user must have write access to the <<path-settings,config, data and log dirs>>\n({es} needs write access to the `config` directory so that it can generate a keystore).\nA good strategy is to grant group access to gid `0` for the local directory.\n\nFor example, to prepare a local directory for storing data through a bind-mount:\n\n[source,sh]\n--------------------------------------------\nmkdir esdatadir\nchmod g+rwx esdatadir\nchgrp 0 esdatadir\n--------------------------------------------\n\nYou can also run an {es} container using both a custom UID and GID. You\nmust ensure that file permissions will not prevent {es} from executing. You\ncan use one of two options:\n\n* Bind-mount the `config`, `data` and `logs`\n  directories. If you intend to install plugins and prefer not to\n  <<_c_customized_image, create a custom Docker image>>, you must also\n  bind-mount the `plugins` directory.\n* Pass the `--group-add 0` command line option to `docker run`. This\n  ensures that the user under which {es} is running is also a member of the\n  `root` (GID 0) group inside the container.\n\n===== Increase ulimits for nofile and nproc\n\nIncreased ulimits for <<setting-system-settings,nofile>> and <<max-number-threads-check,nproc>>\nmust be available for the {es} containers.\nVerify the https://github.com/moby/moby/tree/ea4d1243953e6b652082305a9c3cda8656edab26/contrib/init[init system]\nfor the Docker daemon sets them to acceptable values.\n\nTo check the Docker daemon defaults for ulimits, run:\n\n[source,sh,subs=\"attributes\"]\n--------------------------------------------\ndocker run --rm {docker-image} /bin/bash -c 'ulimit -Hn && ulimit -Sn && ulimit -Hu && ulimit -Su'\n--------------------------------------------\n\nIf needed, adjust them in the Daemon or override them per container.\nFor example, when using `docker run`, set:\n\n[source,sh]\n--------------------------------------------\n--ulimit nofile=65535:65535\n--------------------------------------------\n\n===== Disable swapping\n\nSwapping needs to be disabled for performance and node stability.\nFor information about ways to do this, see <<setup-configuration-memory>>.\n\nIf you opt for the `bootstrap.memory_lock: true` approach,\nyou also need to define the `memlock: true` ulimit in the\nhttps://docs.docker.com/engine/reference/commandline/dockerd/#default-ulimits[Docker Daemon],\nor explicitly set for the container as shown in the  <<docker-compose-file, sample compose file>>.\nWhen using `docker run`, you can specify:\n\n[source,sh]\n----\n-e \"bootstrap.memory_lock=true\" --ulimit memlock=-1:-1\n----\n\n===== Randomize published ports\n\nThe image https://docs.docker.com/engine/reference/builder/#/expose[exposes]\nTCP ports 9200 and 9300. For production clusters, randomizing the\npublished ports with `--publish-all` is recommended,\nunless you are pinning one container per host.\n\n[[docker-set-heap-size]]\n===== Manually set the heap size\n\nBy default, {es} automatically sizes JVM heap based on a nodes's\n<<node-roles,roles>> and the total memory available to the node's container. We\nrecommend this default sizing for most production environments. If needed, you\ncan override default sizing by manually setting JVM heap size.\n\nTo manually set the heap size in production, bind mount a <<set-jvm-options,JVM\noptions>> file under `/usr/share/elasticsearch/config/jvm.options.d` that\nincludes your desired <<set-jvm-heap-size,heap size>> settings.\n\nFor testing, you can also manually set the heap size using the `ES_JAVA_OPTS`\nenvironment variable. For example, to use 1GB, use the following command.\n\n[source,sh,subs=\"attributes\"]\n----\ndocker run -e ES_JAVA_OPTS=\"-Xms1g -Xmx1g\" -e ENROLLMENT_TOKEN=\"<token>\" --name es01 -p 9200:9200 --net elastic -it {docker-image}\n----\n\nThe `ES_JAVA_OPTS` variable overrides all other JVM options.\nWe do not recommend using `ES_JAVA_OPTS` in production.\n\n===== Pin deployments to a specific image version\n\nPin your deployments to a specific version of the {es} Docker image. For\nexample +{docker-image}+.\n\n===== Always bind data volumes\n\nYou should use a volume bound on `/usr/share/elasticsearch/data` for the following reasons:\n\n. The data of your {es} node won't be lost if the container is killed\n\n. {es} is I/O sensitive and the Docker storage driver is not ideal for fast I/O\n\n. It allows the use of advanced\nhttps://docs.docker.com/engine/extend/plugins/#volume-plugins[Docker volume plugins]\n\n===== Avoid using `loop-lvm` mode\n\nIf you are using the devicemapper storage driver, do not use the default `loop-lvm` mode.\nConfigure docker-engine to use\nhttps://docs.docker.com/engine/userguide/storagedriver/device-mapper-driver/#configure-docker-with-devicemapper[direct-lvm].\n\n===== Centralize your logs\n\nConsider centralizing your logs by using a different\nhttps://docs.docker.com/engine/admin/logging/overview/[logging driver]. Also\nnote that the default json-file logging driver is not ideally suited for\nproduction use.\n\n[[docker-configuration-methods]]\n==== Configuring {es} with Docker\n\nWhen you run in Docker, the <<config-files-location,{es} configuration files>> are loaded from\n`/usr/share/elasticsearch/config/`.\n\nTo use custom configuration files, you <<docker-config-bind-mount, bind-mount the files>>\nover the configuration files in the image.\n\nYou can set individual {es} configuration parameters using Docker environment variables.\nThe <<docker-compose-file, sample compose file>> and the\n<<docker-cli-run-dev-mode, single-node example>> use this method. You can\nuse the setting name directly as the environment variable name. If\nyou cannot do this, for example because your orchestration platform forbids\nperiods in environment variable names, then you can use an alternative\nstyle by converting the setting name as follows.\n\n. Change the setting name to uppercase\n. Prefix it with `ES_SETTING_`\n. Escape any underscores (`_`) by duplicating them\n. Convert all periods (`.`) to underscores (`_`)\n\nFor example, `-e bootstrap.memory_lock=true` becomes\n`-e ES_SETTING_BOOTSTRAP_MEMORY__LOCK=true`.\n\nYou can use the contents of a file to set the value of the\n`ELASTIC_PASSWORD` or `KEYSTORE_PASSWORD` environment variables, by\nsuffixing the environment variable name with `_FILE`. This is useful for\npassing secrets such as passwords to {es} without specifying them directly.\n\nFor example, to set the {es} bootstrap password from a file, you can bind mount the\nfile and set the `ELASTIC_PASSWORD_FILE` environment variable to the mount location.\nIf you mount the password file to `/run/secrets/bootstrapPassword.txt`, specify:\n\n[source,sh]\n--------------------------------------------\n-e ELASTIC_PASSWORD_FILE=/run/secrets/bootstrapPassword.txt\n--------------------------------------------\n\nYou can override the default command for the image to pass {es} configuration\nparameters as command line options. For example:\n\n[source,sh]\n--------------------------------------------\ndocker run <various parameters> bin/elasticsearch -Ecluster.name=mynewclustername\n--------------------------------------------\n\nWhile bind-mounting your configuration files is usually the preferred method in production,\nyou can also <<_c_customized_image, create a custom Docker image>>\nthat contains your configuration.\n\n[[docker-config-bind-mount]]\n===== Mounting {es} configuration files\n\nCreate custom config files and bind-mount them over the corresponding files in the Docker image.\nFor example, to bind-mount `custom_elasticsearch.yml` with `docker run`, specify:\n\n[source,sh]\n--------------------------------------------\n-v full_path_to/custom_elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml\n--------------------------------------------\n\nIf you bind-mount a custom `elasticsearch.yml` file, ensure it includes the\n`network.host: 0.0.0.0` setting. This setting ensures the node is reachable for\nHTTP and transport traffic, provided its ports are exposed. The Docker image's\nbuilt-in `elasticsearch.yml` file includes this setting by default.\n\nIMPORTANT: The container **runs {es} as user `elasticsearch` using\nuid:gid `1000:0`**. Bind mounted host directories and files must be accessible by this user,\nand the data and log directories must be writable by this user.\n\n[[docker-keystore-bind-mount]]\n===== Create an encrypted {es} keystore\n\nBy default, {es} will auto-generate a keystore file for <<secure-settings,secure\nsettings>>. This file is obfuscated but not encrypted.\n\nTo encrypt your secure settings with a password and have them persist outside\nthe container, use a `docker run` command to manually create the keystore\ninstead. The command must:\n\n* Bind-mount the `config` directory. The command will create an\n  `elasticsearch.keystore` file in this directory. To avoid errors, do\n  not directly bind-mount the `elasticsearch.keystore` file.\n* Use the `elasticsearch-keystore` tool with the `create -p` option. You'll be\n  prompted to enter a password for the keystore.\n\nFor example:\n\n[source,sh,subs=\"attributes\"]\n----\ndocker run -it --rm \\\n-v full_path_to/config:/usr/share/elasticsearch/config \\\n{docker-image} \\\nbin/elasticsearch-keystore create -p\n----\n\nYou can also use a `docker run` command to add or update secure settings in the\nkeystore. You'll be prompted to enter the setting values. If the keystore is\nencrypted, you'll also be prompted to enter the keystore password.\n\n[source,sh,subs=\"attributes\"]\n----\ndocker run -it --rm \\\n-v full_path_to/config:/usr/share/elasticsearch/config \\\n{docker-image} \\\nbin/elasticsearch-keystore \\\nadd my.secure.setting \\\nmy.other.secure.setting\n----\n\nIf you've already created the keystore and don't need to update it, you can\nbind-mount the `elasticsearch.keystore` file directly. You can use the\n`KEYSTORE_PASSWORD` environment variable to provide the keystore password to the\ncontainer at startup. For example, a `docker run` command might have the\nfollowing options:\n\n[source,sh]\n----\n-v full_path_to/config/elasticsearch.keystore:/usr/share/elasticsearch/config/elasticsearch.keystore\n-e KEYSTORE_PASSWORD=mypassword\n----\n\n[[_c_customized_image]]\n===== Using custom Docker images\nIn some environments, it might make more sense to prepare a custom image that contains\nyour configuration. A `Dockerfile` to achieve this might be as simple as:\n\n[source,sh,subs=\"attributes\"]\n--------------------------------------------\nFROM {docker-image}\nCOPY --chown=elasticsearch:elasticsearch elasticsearch.yml /usr/share/elasticsearch/config/\n--------------------------------------------\n\nYou could then build and run the image with:\n\n[source,sh]\n--------------------------------------------\ndocker build --tag=elasticsearch-custom .\ndocker run -ti -v /usr/share/elasticsearch/data elasticsearch-custom\n--------------------------------------------\n\nSome plugins require additional security permissions.\nYou must explicitly accept them either by:\n\n* Attaching a `tty` when you run the Docker image and allowing the permissions when prompted.\n* Inspecting the security permissions and accepting them (if appropriate) by adding the `--batch` flag to the plugin install command.\n\nSee {plugins}/_other_command_line_parameters.html[Plugin management]\nfor more information.\n\n[discrete]\n[[troubleshoot-docker-errors]]\n==== Troubleshoot Docker errors for {es}\n\nHere\u2019s how to resolve common errors when running {es} with Docker.\n\n===== elasticsearch.keystore is a directory\n\n[source,txt]\n----\nException in thread \"main\" org.elasticsearch.bootstrap.BootstrapException: java.io.IOException: Is a directory: SimpleFSIndexInput(path=\"/usr/share/elasticsearch/config/elasticsearch.keystore\") Likely root cause: java.io.IOException: Is a directory\n----\n\nA <<docker-keystore-bind-mount,keystore-related>> `docker run` command attempted\nto directly bind-mount an `elasticsearch.keystore` file that doesn't exist. If\nyou use the `-v` or `--volume` flag to mount a file that doesn't exist, Docker\ninstead creates a directory with the same name.\n\nTo resolve this error:\n\n. Delete the `elasticsearch.keystore` directory in the `config` directory.\n. Update the `-v` or `--volume` flag to point to the `config` directory path\n  rather than the keystore file's path. For an example, see\n  <<docker-keystore-bind-mount>>.\n. Retry the command.\n\n===== elasticsearch.keystore: Device or resource busy\n\n[source,txt]\n----\nException in thread \"main\" java.nio.file.FileSystemException: /usr/share/elasticsearch/config/elasticsearch.keystore.tmp -> /usr/share/elasticsearch/config/elasticsearch.keystore: Device or resource busy\n----\n\nA `docker run` command attempted to <<docker-keystore-bind-mount,update the\nkeystore>> while directly bind-mounting the `elasticsearch.keystore` file. To\nupdate the keystore, the container requires access to other files in the\n`config` directory, such as `keystore.tmp`.\n\nTo resolve this error:\n\n. Update the `-v` or `--volume` flag to point to the `config` directory\n  path rather than the keystore file's path. For an example, see\n  <<docker-keystore-bind-mount>>.\n. Retry the command.\n"
}
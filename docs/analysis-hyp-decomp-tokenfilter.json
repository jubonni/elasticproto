{
    "meta": {
        "size": 5238,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-hyp-decomp-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-hyp-decomp-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-hyp-decomp-tokenfilter]]\n=== Hyphenation decompounder token filter\n++++\n<titleabbrev>Hyphenation decompounder</titleabbrev>\n++++\n\nUses XML-based hyphenation patterns to find potential subwords in compound\nwords. These subwords are then checked against the specified word list. Subwords not\nin the list are excluded from the token output.\n\nThis filter uses Lucene's\n{lucene-analysis-docs}/compound/HyphenationCompoundWordTokenFilter.html[HyphenationCompoundWordTokenFilter],\nwhich was built for Germanic languages.\n\n[[analysis-hyp-decomp-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the\n`hyphenation_decompounder` filter to find subwords in `Kaffeetasse` based on\nGerman hyphenation patterns in the `analysis/hyphenation_patterns.xml` file. The\nfilter then checks these subwords against a list of specified words: `kaffee`,\n`zucker`, and `tasse`.\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"hyphenation_decompounder\",\n      \"hyphenation_patterns_path\": \"analysis/hyphenation_patterns.xml\",\n      \"word_list\": [\"Kaffee\", \"zucker\", \"tasse\"]\n    }\n  ],\n  \"text\": \"Kaffeetasse\"\n}\n--------------------------------------------------\n// TEST[skip: requires a valid hyphenation_patterns.xml file for DE-DR]\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ Kaffeetasse, Kaffee, tasse ]\n--------------------------------------------------\n\n[[analysis-hyp-decomp-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`hyphenation_patterns_path`::\n+\n--\n(Required, string)\nPath to an Apache FOP (Formatting Objects Processor) XML hyphenation pattern file.\n\nThis path must be absolute or relative to the `config` location. Only FOP v1.2\ncompatible files are supported.\n\nFor example FOP XML hyphenation pattern files, refer to:\n\n* http://offo.sourceforge.net/#FOP+XML+Hyphenation+Patterns[Objects For Formatting Objects (OFFO) Sourceforge project]\n* https://sourceforge.net/projects/offo/files/offo-hyphenation/1.2/offo-hyphenation_v1.2.zip/download[offo-hyphenation_v1.2.zip direct download] (v2.0 and above hyphenation pattern files are not supported)\n--\n\n`word_list`::\n+\n--\n(Required+++*+++, array of strings)\nA list of subwords. Subwords found using the hyphenation pattern but not in this\nlist are excluded from the token output.\n\nYou can use the <<analysis-dict-decomp-tokenfilter,`dictionary_decompounder`>>\nfilter to test the quality of word lists before implementing them.\n\nEither this parameter or `word_list_path` must be specified.\n--\n\n`word_list_path`::\n+\n--\n(Required+++*+++, string)\nPath to a file containing a list of subwords. Subwords found using the\nhyphenation pattern but not in this list are excluded from the token output.\n\nThis path must be absolute or relative to the `config` location, and the file\nmust be UTF-8 encoded. Each token in the file must be separated by a line break.\n\nYou can use the <<analysis-dict-decomp-tokenfilter,`dictionary_decompounder`>>\nfilter to test the quality of word lists before implementing them.\n\nEither this parameter or `word_list` must be specified.\n--\n\n`max_subword_size`::\n(Optional, integer)\nMaximum subword character length. Longer subword tokens are excluded from the\noutput. Defaults to `15`.\n\n`min_subword_size`::\n(Optional, integer)\nMinimum subword character length. Shorter subword tokens are excluded from the\noutput. Defaults to `2`.\n\n`min_word_size`::\n(Optional, integer)\nMinimum word character length. Shorter word tokens are excluded from the\noutput. Defaults to `5`.\n\n`only_longest_match`::\n(Optional, Boolean)\nIf `true`, only include the longest matching subword. Defaults to `false`.\n\n[[analysis-hyp-decomp-tokenfilter-customize]]\n==== Customize and add to an analyzer\n\nTo customize the `hyphenation_decompounder` filter, duplicate it to create the\nbasis for a new custom token filter. You can modify the filter using its\nconfigurable parameters.\n\nFor example, the following <<indices-create-index,create index API>> request\nuses a custom `hyphenation_decompounder` filter to configure a new\n<<analysis-custom-analyzer,custom analyzer>>.\n\nThe custom `hyphenation_decompounder` filter find subwords based on hyphenation\npatterns in the `analysis/hyphenation_patterns.xml` file. The filter then checks\nthese subwords against the list of words specified in the\n`analysis/example_word_list.txt` file. Subwords longer than 22 characters are\nexcluded from the token output.\n\n[source,console]\n--------------------------------------------------\nPUT hyphenation_decompound_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"standard_hyphenation_decompound\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [ \"22_char_hyphenation_decompound\" ]\n        }\n      },\n      \"filter\": {\n        \"22_char_hyphenation_decompound\": {\n          \"type\": \"hyphenation_decompounder\",\n          \"word_list_path\": \"analysis/example_word_list.txt\",\n          \"hyphenation_patterns_path\": \"analysis/hyphenation_patterns.xml\",\n          \"max_subword_size\": 22\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
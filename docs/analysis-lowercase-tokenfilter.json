{
    "meta": {
        "timestamp": "2024-11-01T03:07:09.577273",
        "size": 3748,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lowercase-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "analysis-lowercase-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-lowercase-tokenfilter]]\n=== Lowercase token filter\n++++\n<titleabbrev>Lowercase</titleabbrev>\n++++\n\nChanges token text to lowercase. For example, you can use the `lowercase` filter\nto change `THE Lazy DoG` to `the lazy dog`.\n\nIn addition to a default filter, the `lowercase` token filter provides access to\nLucene's language-specific lowercase filters for Greek, Irish, and Turkish.\n  \n[[analysis-lowercase-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the default\n`lowercase` filter to change the `THE Quick FoX JUMPs` to lowercase:\n\n[source,console]\n--------------------------------------------------\nGET _analyze\n{\n  \"tokenizer\" : \"standard\",\n  \"filter\" : [\"lowercase\"],\n  \"text\" : \"THE Quick FoX JUMPs\"\n}\n--------------------------------------------------\n\nThe filter produces the following tokens:\n\n[source,text]\n--------------------------------------------------\n[ the, quick, fox, jumps ]\n--------------------------------------------------\n\n/////////////////////\n[source,console-result]\n--------------------------------------------------\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"the\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 3,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"quick\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 9,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"fox\",\n      \"start_offset\" : 10,\n      \"end_offset\" : 13,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"jumps\",\n      \"start_offset\" : 14,\n      \"end_offset\" : 19,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 3\n    }\n  ]\n}\n--------------------------------------------------\n/////////////////////\n\n[[analysis-lowercase-tokenfilter-analyzer-ex]]\n==== Add to an analyzer\n\nThe following <<indices-create-index,create index API>> request uses the\n`lowercase` filter to configure a new \n<<analysis-custom-analyzer,custom analyzer>>.\n\n[source,console]\n--------------------------------------------------\nPUT lowercase_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"whitespace_lowercase\": {\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [ \"lowercase\" ]\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n\n[[analysis-lowercase-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`language`::\n+\n--\n(Optional, string)\nLanguage-specific lowercase token filter to use. Valid values include:\n\n`greek`::: Uses Lucene's\n{lucene-analysis-docs}/el/GreekLowerCaseFilter.html[GreekLowerCaseFilter]\n\n`irish`::: Uses Lucene's\n{lucene-analysis-docs}/ga/IrishLowerCaseFilter.html[IrishLowerCaseFilter]\n\n`turkish`::: Uses Lucene's\n{lucene-analysis-docs}/tr/TurkishLowerCaseFilter.html[TurkishLowerCaseFilter]\n\nIf not specified, defaults to Lucene's\n{lucene-analysis-docs}/core/LowerCaseFilter.html[LowerCaseFilter].\n--\n\n[[analysis-lowercase-tokenfilter-customize]]\n==== Customize\n\nTo customize the `lowercase` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nFor example, the following request creates a custom `lowercase` filter for the\nGreek language:\n\n[source,console]\n--------------------------------------------------\nPUT custom_lowercase_example\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"greek_lowercase_example\": {\n          \"type\": \"custom\",\n          \"tokenizer\": \"standard\",\n          \"filter\": [\"greek_lowercase\"]\n        }\n      },\n      \"filter\": {\n        \"greek_lowercase\": {\n          \"type\": \"lowercase\",\n          \"language\": \"greek\"\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n"
}
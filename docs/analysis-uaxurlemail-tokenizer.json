{
    "meta": {
        "timestamp": "2024-11-01T03:07:10.481288",
        "size": 3879,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-uaxurlemail-tokenizer.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-uaxurlemail-tokenizer",
        "version": "8.15"
    },
    "doc": "[[analysis-uaxurlemail-tokenizer]]\n=== UAX URL email tokenizer\n++++\n<titleabbrev>UAX URL email</titleabbrev>\n++++\n\nThe `uax_url_email` tokenizer is like the <<analysis-standard-tokenizer,`standard` tokenizer>> except that it\nrecognises URLs and email addresses as single tokens.\n\n[discrete]\n=== Example output\n\n[source,console]\n---------------------------\nPOST _analyze\n{\n  \"tokenizer\": \"uax_url_email\",\n  \"text\": \"Email me at john.smith@global-international.com\"\n}\n---------------------------\n\n/////////////////////\n\n[source,console-result]\n----------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"Email\",\n      \"start_offset\": 0,\n      \"end_offset\": 5,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"me\",\n      \"start_offset\": 6,\n      \"end_offset\": 8,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"at\",\n      \"start_offset\": 9,\n      \"end_offset\": 11,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"john.smith@global-international.com\",\n      \"start_offset\": 12,\n      \"end_offset\": 47,\n      \"type\": \"<EMAIL>\",\n      \"position\": 3\n    }\n  ]\n}\n----------------------------\n\n/////////////////////\n\n\nThe above sentence would produce the following terms:\n\n[source,text]\n---------------------------\n[ Email, me, at, john.smith@global-international.com ]\n---------------------------\n\nwhile the `standard` tokenizer would produce:\n\n[source,text]\n---------------------------\n[ Email, me, at, john.smith, global, international.com ]\n---------------------------\n\n[discrete]\n=== Configuration\n\nThe `uax_url_email` tokenizer accepts the following parameters:\n\n[horizontal]\n`max_token_length`::\n\n    The maximum token length. If a token is seen that exceeds this length then\n    it is split at `max_token_length` intervals. Defaults to `255`.\n\n[discrete]\n=== Example configuration\n\nIn this example, we configure the `uax_url_email` tokenizer to have a\n`max_token_length` of 5 (for demonstration purposes):\n\n[source,console]\n----------------------------\nPUT my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"my_tokenizer\"\n        }\n      },\n      \"tokenizer\": {\n        \"my_tokenizer\": {\n          \"type\": \"uax_url_email\",\n          \"max_token_length\": 5\n        }\n      }\n    }\n  }\n}\n\nPOST my-index-000001/_analyze\n{\n  \"analyzer\": \"my_analyzer\",\n  \"text\": \"john.smith@global-international.com\"\n}\n----------------------------\n\n/////////////////////\n\n[source,console-result]\n----------------------------\n{\n  \"tokens\": [\n    {\n      \"token\": \"john\",\n      \"start_offset\": 0,\n      \"end_offset\": 4,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"smith\",\n      \"start_offset\": 5,\n      \"end_offset\": 10,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    },\n    {\n      \"token\": \"globa\",\n      \"start_offset\": 11,\n      \"end_offset\": 16,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 2\n    },\n    {\n      \"token\": \"l\",\n      \"start_offset\": 16,\n      \"end_offset\": 17,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 3\n    },\n    {\n      \"token\": \"inter\",\n      \"start_offset\": 18,\n      \"end_offset\": 23,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 4\n    },\n    {\n      \"token\": \"natio\",\n      \"start_offset\": 23,\n      \"end_offset\": 28,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 5\n    },\n    {\n      \"token\": \"nal.c\",\n      \"start_offset\": 28,\n      \"end_offset\": 33,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 6\n    },\n    {\n      \"token\": \"om\",\n      \"start_offset\": 33,\n      \"end_offset\": 35,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 7\n    }\n  ]\n}\n----------------------------\n\n/////////////////////\n\n\nThe above example produces the following terms:\n\n[source,text]\n---------------------------\n[ john, smith, globa, l, inter, natio, nal.c, om ]\n---------------------------\n"
}
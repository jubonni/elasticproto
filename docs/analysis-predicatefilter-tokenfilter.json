{
    "meta": {
        "timestamp": "2024-11-01T03:02:53.199579",
        "size": 3028,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-predicatefilter-tokenfilter.html",
        "type": "documentation",
        "role": [],
        "has_code": false,
        "title": "analysis-predicatefilter-tokenfilter",
        "version": "8.15"
    },
    "doc": "[[analysis-predicatefilter-tokenfilter]]\n=== Predicate script token filter\n++++\n<titleabbrev>Predicate script</titleabbrev>\n++++\n\nRemoves tokens that don't match a provided predicate script. The filter supports\ninline {painless}/index.html[Painless] scripts only. Scripts are evaluated in\nthe {painless}/painless-analysis-predicate-context.html[analysis predicate\ncontext].\n\n[[analysis-predicatefilter-tokenfilter-analyze-ex]]\n==== Example\n\nThe following <<indices-analyze,analyze API>> request uses the\n`predicate_token_filter` filter to only output tokens longer than three\ncharacters from `the fox jumps the lazy dog`.\n\n[source,console]\n----\nGET /_analyze\n{\n  \"tokenizer\": \"whitespace\",\n  \"filter\": [\n    {\n      \"type\": \"predicate_token_filter\",\n      \"script\": {\n        \"source\": \"\"\"\n          token.term.length() > 3\n        \"\"\"\n      }\n    }\n  ],\n  \"text\": \"the fox jumps the lazy dog\"\n}\n----\n\nThe filter produces the following tokens.\n\n[source,text]\n----\n[ jumps, lazy ]\n----\n\nThe API response contains the position and offsets of each output token. Note\nthe `predicate_token_filter` filter does not change the tokens' original\npositions or offsets.\n\n.*Response*\n[%collapsible]\n====\n[source,console-result]\n----\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"jumps\",\n      \"start_offset\" : 8,\n      \"end_offset\" : 13,\n      \"type\" : \"word\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"lazy\",\n      \"start_offset\" : 18,\n      \"end_offset\" : 22,\n      \"type\" : \"word\",\n      \"position\" : 4\n    }\n  ]\n}\n----\n====\n\n[[analysis-predicatefilter-tokenfilter-configure-parms]]\n==== Configurable parameters\n\n`script`::\n(Required, <<modules-scripting-using,script object>>)\nScript containing a condition used to filter incoming tokens. Only tokens that\nmatch this script are included in the output.\n+\nThis parameter supports inline {painless}/index.html[Painless] scripts only. The\nscript is evaluated in the\n{painless}/painless-analysis-predicate-context.html[analysis predicate context].\n\n[[analysis-predicatefilter-tokenfilter-customize]]\n==== Customize and add to an analyzer\n\nTo customize the `predicate_token_filter` filter, duplicate it to create the basis\nfor a new custom token filter. You can modify the filter using its configurable\nparameters.\n\nThe following <<indices-create-index,create index API>> request\nconfigures a new <<analysis-custom-analyzer,custom analyzer>> using a custom\n`predicate_token_filter` filter, `my_script_filter`.\n\nThe `my_script_filter` filter removes tokens with of any type other than\n`ALPHANUM`.\n\n[source,console]\n----\nPUT /my-index-000001\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"my_script_filter\"\n          ]\n        }\n      },\n      \"filter\": {\n        \"my_script_filter\": {\n          \"type\": \"predicate_token_filter\",\n          \"script\": {\n            \"source\": \"\"\"\n              token.type.contains(\"ALPHANUM\")\n            \"\"\"\n          }\n        }\n      }\n    }\n  }\n}\n----\n"
}
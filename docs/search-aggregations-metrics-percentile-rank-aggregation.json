{
    "meta": {
        "timestamp": "2024-11-01T02:49:25.917067",
        "size": 6953,
        "url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-percentile-rank-aggregation.html",
        "type": "documentation",
        "role": [],
        "has_code": true,
        "title": "search-aggregations-metrics-percentile-rank-aggregation",
        "version": "8.15"
    },
    "doc": "[[search-aggregations-metrics-percentile-rank-aggregation]]\n=== Percentile ranks aggregation\n++++\n<titleabbrev>Percentile ranks</titleabbrev>\n++++\n\nA `multi-value` metrics aggregation that calculates one or more percentile ranks\nover numeric values extracted from the aggregated documents. These values can be\nextracted from specific numeric or <<histogram,histogram fields>> in the documents.\n\n[NOTE]\n==================================================\nPlease see <<search-aggregations-metrics-percentile-aggregation-approximation>>,\n<<search-aggregations-metrics-percentile-aggregation-compression>> and\n<<search-aggregations-metrics-percentile-aggregation-execution-hint>> for advice\nregarding approximation, performance and memory use of the percentile ranks aggregation\n==================================================\n\nPercentile rank show the percentage of observed values which are below certain\nvalue. For example, if a value is greater than or equal to 95% of the observed values\nit is said to be at the 95th percentile rank.\n\nAssume your data consists of website load times. You may have a service agreement that\n95% of page loads complete within 500ms and 99% of page loads complete within 600ms.\n\nLet's look at a range of percentiles representing load time:\n\n[source,console]\n--------------------------------------------------\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",   <1>\n        \"values\": [ 500, 600 ]\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:latency]\n\n<1> The field `load_time` must be a numeric field\n\nThe response will look like this:\n\n[source,console-result]\n--------------------------------------------------\n{\n  ...\n\n \"aggregations\": {\n    \"load_time_ranks\": {\n      \"values\": {\n        \"500.0\": 55.0,\n        \"600.0\": 64.0\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\\.\\.\\./\"took\": $body.took,\"timed_out\": false,\"_shards\": $body._shards,\"hits\": $body.hits,/]\n// TESTRESPONSE[s/\"500.0\": 55.0/\"500.0\": 55.00000000000001/]\n// TESTRESPONSE[s/\"600.0\": 64.0/\"600.0\": 64.0/]\n\nFrom this information you can determine you are hitting the 99% load time target but not quite\nhitting the 95% load time target\n\n==== Keyed Response\n\nBy default the `keyed` flag is set to `true` associates a unique string key with each bucket and returns the ranges as a hash rather than an array. Setting the `keyed` flag to `false` will disable this behavior:\n\n[source,console]\n--------------------------------------------------\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",\n        \"values\": [ 500, 600 ],\n        \"keyed\": false\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:latency]\n\nResponse:\n\n[source,console-result]\n--------------------------------------------------\n{\n  ...\n\n  \"aggregations\": {\n    \"load_time_ranks\": {\n      \"values\": [\n        {\n          \"key\": 500.0,\n          \"value\": 55.0\n        },\n        {\n          \"key\": 600.0,\n          \"value\": 64.0\n        }\n      ]\n    }\n  }\n}\n--------------------------------------------------\n// TESTRESPONSE[s/\\.\\.\\./\"took\": $body.took,\"timed_out\": false,\"_shards\": $body._shards,\"hits\": $body.hits,/]\n// TESTRESPONSE[s/\"value\": 55.0/\"value\": 55.00000000000001/]\n// TESTRESPONSE[s/\"value\": 64.0/\"value\": 64.0/]\n\n\n==== Script\n\nIf you need to run the aggregation against values that aren't indexed, use\na <<runtime,runtime field>>. For example, if our load times\nare in milliseconds but we want percentiles calculated in seconds:\n\n[source,console]\n----\nGET latency/_search\n{\n  \"size\": 0,\n  \"runtime_mappings\": {\n    \"load_time.seconds\": {\n      \"type\": \"long\",\n      \"script\": {\n        \"source\": \"emit(doc['load_time'].value / params.timeUnit)\",\n        \"params\": {\n          \"timeUnit\": 1000\n        }\n      }\n    }\n  },\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"values\": [ 500, 600 ],\n        \"field\": \"load_time.seconds\"\n      }\n    }\n  }\n}\n----\n// TEST[setup:latency]\n// TEST[s/_search/_search?filter_path=aggregations/]\n\n////\n[source,console-result]\n--------------------------------------------------\n{\n  \"aggregations\": {\n    \"load_time_ranks\": {\n      \"values\": {\n        \"500.0\": 100.0,\n        \"600.0\": 100.0\n      }\n    }\n  }\n}\n--------------------------------------------------\n////\n\n==== HDR Histogram\n\nhttps://github.com/HdrHistogram/HdrHistogram[HDR Histogram] (High Dynamic Range Histogram) is an alternative implementation\nthat can be useful when calculating percentile ranks for latency measurements as it can be faster than the t-digest implementation\nwith the trade-off of a larger memory footprint. This implementation maintains a fixed worse-case percentage error (specified as a\nnumber of significant digits). This means that if data is recorded with values from 1 microsecond up to 1 hour (3,600,000,000\nmicroseconds) in a histogram set to 3 significant digits, it will maintain a value resolution of 1 microsecond for values up to\n1 millisecond and 3.6 seconds (or better) for the maximum tracked value (1 hour).\n\nThe HDR Histogram can be used by specifying the `hdr` object in the request:\n\n[source,console]\n--------------------------------------------------\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",\n        \"values\": [ 500, 600 ],\n        \"hdr\": {                                  <1>\n          \"number_of_significant_value_digits\": 3 <2>\n        }\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:latency]\n\n<1> `hdr` object indicates that HDR Histogram should be used to calculate the percentiles and specific settings for this algorithm can be specified inside the object\n<2> `number_of_significant_value_digits` specifies the resolution of values for the histogram in number of significant digits\n\nThe HDRHistogram only supports positive values and will error if it is passed a negative value. It is also not a good idea to use\nthe HDRHistogram if the range of values is unknown as this could lead to high memory usage.\n\n==== Missing value\n\nThe `missing` parameter defines how documents that are missing a value should be treated.\nBy default they will be ignored but it is also possible to treat them as if they\nhad a value.\n\n[source,console]\n--------------------------------------------------\nGET latency/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"load_time_ranks\": {\n      \"percentile_ranks\": {\n        \"field\": \"load_time\",\n        \"values\": [ 500, 600 ],\n        \"missing\": 10           <1>\n      }\n    }\n  }\n}\n--------------------------------------------------\n// TEST[setup:latency]\n\n<1> Documents without a value in the `load_time` field will fall into the same bucket as documents that have the value `10`.\n"
}